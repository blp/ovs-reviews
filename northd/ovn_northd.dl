import OVN_Northbound as nb
import OVN_Southbound as sb
import ovsdb
import allocate
import ovn
import lswitch
import lrouter
import multicast
import helpers
import ipam

output relation Warning[string]

/* Meter_Band table */
for (mb in nb.Meter_Band) {
    sb.Out_Meter_Band(._uuid = mb._uuid,
                      .action = mb.action,
                      .rate = mb.rate,
                      .burst_size = mb.burst_size)
}

/* Meter table */
for (meter in nb.Meter) {
    sb.Out_Meter(._uuid = meter._uuid,
                 .name = meter.name,
                 .unit = meter.unit,
                 .bands = meter.bands)
}

/* Proxy table for Out_Datapath_Binding: contains all Datapath_Binding fields,
 * except tunnel id, which is allocated separately (see TunKeyAllocation). */
relation OutProxy_Datapath_Binding (
    _uuid: uuid,
    external_ids: Map<string,string>
)

/* Datapath_Binding table */
OutProxy_Datapath_Binding(uuid, external_ids) :-
    nb.Logical_Switch(._uuid = uuid, .name = name, .external_ids = ids,
                      .other_config = other_config),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids: Map<string, string> = map_empty();
        map_insert(eids, "logical-switch", uuid_str);
        map_insert(eids, "name", name);
        match (map_get(ids, "neutron:network_name")) {
            None -> (),
            Some{nnn} -> map_insert(eids, "name2", nnn)
        };
        match (map_get(other_config, "interconn-ts")) {
            None -> (),
            Some{value} -> map_insert(eids, "interconn-ts", value)
        };
        eids
    }.

OutProxy_Datapath_Binding(uuid, external_ids) :-
    nb.Logical_Router(._uuid = uuid, .name = name, .external_ids = ids, .enabled = enabled),
    is_enabled(enabled),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids: Map<string, string> = map_empty();
        map_insert(eids, "logical-router", uuid_str);
        map_insert(eids, "name", name);
        match (map_get(ids, "neutron:router_name")) {
            None -> (),
            Some{nnn} -> map_insert(eids, "name2", nnn)
        };
        eids
    }.

sb.Out_Datapath_Binding(uuid, tunkey, external_ids) :-
    OutProxy_Datapath_Binding(uuid, external_ids),
    TunKeyAllocation(uuid, tunkey).


/* Proxy table for Out_Datapath_Binding: contains all Datapath_Binding fields,
 * except tunnel id, which is allocated separately (see PortTunKeyAllocation). */
relation OutProxy_Port_Binding (
    _uuid: uuid,
    logical_port: string,
    __type: string,
    gateway_chassis: Set<uuid>,
    ha_chassis_group: Option<uuid>,
    options: Map<string,string>,
    datapath: uuid,
    parent_port: Option<string>,
    tag: Option<integer>,
    mac: Set<string>,
    nat_addresses: Set<string>,
    external_ids: Map<string,string>
)

/* Case 1: Create a Port_Binding per logical switch port that is not of type "router" */
OutProxy_Port_Binding(._uuid              = lsp._uuid,
                      .logical_port       = lsp.name,
                      .__type             = lsp.__type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = sp.ha_chassis_group_uuid,
                      .options            = lsp.options,
                      .datapath           = sw.ls._uuid,
                      .parent_port        = lsp.parent_name,
                      .tag                = tag,
                      .mac                = lsp.addresses,
                      .nat_addresses      = set_empty(),
                      .external_ids       = eids) :-
    sp in &SwitchPort(.lsp = lsp, .sw = &sw),
    SwitchPortNewDynamicTag(lsp._uuid, opt_tag),
    var tag: Option<integer> = match (opt_tag) {
        None -> lsp.tag,
        Some{t} -> Some{t}
    },
    lsp.__type != "router",
    var eids = {
        var eids = lsp.external_ids;
        match (map_get(lsp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    }.


/* Case 2: Create a Port_Binding per logical switch port of type "router" */
OutProxy_Port_Binding(._uuid              = lsp._uuid,
                      .logical_port       = lsp.name,
                      .__type             = __type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = None,
                      .options            = options,
                      .datapath           = sw.ls._uuid,
                      .parent_port        = lsp.parent_name,
                      .tag                = None,
                      .mac                = lsp.addresses,
                      .nat_addresses      = nat_addresses,
                      .external_ids       = eids) :-
    &SwitchPort(.lsp = lsp, .sw = &sw, .peer = peer),
    var eids = {
        var eids = lsp.external_ids;
        match (map_get(lsp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    },
    Some{var router_port} = map_get(lsp.options, "router-port"),
    var opt_chassis: Option<string> = match (peer) {
        Some{rport} -> map_get(rport.router.lr.options, "chassis"),
        None -> None
    },
    var l3dgw_port: Option<nb.Logical_Router_Port> = match (peer) {
        Some{rport} -> rport.router.l3dgw_port,
        None -> None
    },
    (var __type, var options) = {
        var options: Map<string, string> = map_singleton("peer", router_port);
        match (opt_chassis) {
            None -> {
                ("patch", options)
            },
            Some{chassis} -> {
                map_insert(options, "l3gateway-chassis", chassis);
                ("l3gateway", options)
            }
        }
    },
    var base_nat_addresses: Set<string> = {
        match (map_get(lsp.options, "nat-addresses")) {
            None -> { set_empty() },
            Some{"router"} -> match ((l3dgw_port, opt_chassis, peer)) {
                                 (None, None, _) -> set_empty(),
                                 (_, _, None) -> set_empty(),
                                 (_, _, Some{rport}) -> get_nat_addresses(deref(rport))
                              },
            Some{nat_addresses} -> {
                /* Only accept manual specification of ethernet address
                 * followed by IPv4 addresses on type "l3gateway" ports. */
                if (is_some(opt_chassis)) {
                    match (extract_lsp_addresses(nat_addresses)) {
                        None -> {
                            warn("Error extracting nat-addresses.");
                            set_empty()
                        },
                        Some{_} -> { set_singleton(nat_addresses) }
                    }
                } else { set_empty() }
            }
        }
    },
    /* Add the router mac and IPv4 addresses to
     * Port_Binding.nat_addresses so that GARP is sent for these
     * IPs by the ovn-controller on which the distributed gateway
     * router port resides if:
     *
     * 1. The peer has 'reside-on-gateway-chassis' set and the
     *    the logical router datapath has distributed router port.
     *
     * 2. The peer is distributed gateway router port.
     *
     * 3. The peer's router is a gateway router and the port has a localnet
     *    port.
     *
     * Note: Port_Binding.nat_addresses column is also used for
     * sending the GARPs for the router port IPs.
     * */
    var garp_nat_addresses: Set<string> = match (peer) {
        Some{rport} -> match (
            (map_get_bool_def(rport.lrp.options, "reside-on-redirect-chassis",
                              false)
             and is_some(l3dgw_port)) or
            Some{rport.lrp} == l3dgw_port or
            (is_some(map_get(rport.router.lr.options, "chassis")) and
             sw.has_localnet_port)) {
            false -> set_empty(),
            true -> set_singleton(get_garp_nat_addresses(deref(rport)))
        },
        None -> set_empty()
    },
    var nat_addresses = set_union(base_nat_addresses, garp_nat_addresses).

/* Case 3: Port_Binding per logical router port */
OutProxy_Port_Binding(._uuid              = lrp._uuid,
                      .logical_port       = lrp.name,
                      .__type             = __type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = None,
                      .options            = options,
                      .datapath           = router.lr._uuid,
                      .parent_port        = None,
                      .tag                = None, // always empty for router ports
                      .mac                = set_singleton("${lrp.mac} ${set_space_sep(lrp.networks)}"),
                      .nat_addresses      = set_empty(),
                      .external_ids       = lrp.external_ids) :-
    rp in &RouterPort(.lrp = lrp, .router = &router, .peer = peer),
    RouterPortRAOptionsComplete(lrp._uuid, options0),
    (var __type, var options1) = match (map_get(router.lr.options, "chassis")) {
        /* TODO: derived ports */
        None -> ("patch", map_empty(): Map<string, string>),
        Some{lrchassis} -> ("l3gateway", map_singleton("l3gateway-chassis", lrchassis))
    },
    var options2 = match (router_peer_name(peer)) {
        None -> map_empty(): Map<string, string>,
        Some{peer_name} -> map_singleton("peer", peer_name)
    },
    var options3 = match ((peer, vec_is_empty(rp.networks.ipv6_addrs))) {
        (PeerSwitch{_, _}, false) -> {
            var enabled = is_enabled(lrp.enabled);
            var pd = map_get_bool_def(lrp.options, "prefix_delegation", false);
            var p = map_get_bool_def(lrp.options, "prefix", false);
            map_union(
                map_singleton("ipv6_prefix_delegation", "${pd and enabled}"),
                map_singleton("ipv6_prefix", "${p and enabled}"))
        },
        _ -> map_empty(): Map<string,string>
    },
    PreserveIPv6RAPDList(lrp._uuid, ipv6_ra_pd_list),
    var options4: Map<string,string> = match (ipv6_ra_pd_list) {
        None -> map_empty(),
        Some{value} -> map_singleton("ipv6_ra_pd_list", value)
    },
    var options = map_union(options0,
                      map_union(options1,
                          map_union(options2,
                              map_union(options3, options4)))),
    var eids = {
        var eids = lrp.external_ids;
        match (map_get(lrp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    }.
/*
*/
function get_router_load_balancer_ips(router: Router) :
    (Set<string>, Set<string>) =
{
    var all_ips_v4: Set<string> = set_empty();
    var all_ips_v6: Set<string> = set_empty();
    for (lb in router.lbs) {
        for (kv in deref(lb).vips) {
            (var vip, _) = kv;
            /* node->key contains IP:port or just IP. */
            match (ip_address_and_port_from_lb_key(vip)) {
                None -> (),
                Some{(ip_address, _, addr_family)}
                    -> if (addr_family == aF_INET()) {
                           set_insert(all_ips_v4, ip_address)
                       } else {
                           set_insert(all_ips_v6, ip_address)
                       }
            }
        }
    };
    (all_ips_v4, all_ips_v6)
}

/* Returns an array of strings, each consisting of a MAC address followed
 * by one or more IP addresses, and if the port is a distributed gateway
 * port, followed by 'is_chassis_resident("LPORT_NAME")', where the
 * LPORT_NAME is the name of the L3 redirect port or the name of the
 * logical_port specified in a NAT rule.  These strings include the
 * external IP addresses of all NAT rules defined on that router, and all
 * of the IP addresses used in load balancer VIPs defined on that router.
 */
function get_nat_addresses(rport: RouterPort): Set<string> =
{
    var addresses: Set<string> = set_empty();
    var router = deref(rport.router);
    var has_redirect = is_some(router.l3dgw_port);
    match (eth_addr_from_string(rport.lrp.mac)) {
        None -> addresses,
        Some{mac} -> {
            var c_addresses = "${mac}";
            var central_ip_address = false;

            /* Get NAT IP addresses. */
            for (natref in router.nats) {
                var nat = deref(natref);
                match (ip_parse_masked(nat.external_ip)) {
                    Left{_} -> (),
                    Right{(ip, mask)} -> {
                        if (mask == oVS_BE32_MAX()) {
                            /* Determine whether this NAT rule satisfies the conditions for
                             * distributed NAT processing. */
                            if (has_redirect and nat.__type == "dnat_and_snat" and
                                is_some(nat.logical_port) and is_some(nat.external_mac)) {
                                /* Distributed NAT rule. */
                                match (eth_addr_from_string(option_unwrap_or_default(nat.external_mac))) {
                                    Some{emac} -> {
                                        set_insert(addresses,
                                                   "${emac} ${nat.external_ip} is_chassis_resident(${json_string_escape(option_unwrap_or_default(nat.logical_port))})")
                                    },
                                    None -> ()
                                }
                            } else {
                                /* Centralized NAT rule, either on gateway router or distributed
                                 * router.
                                 * Check if external_ip is same as router ip. If so, then there
                                 * is no need to add this to the nat_addresses. The router IPs
                                 * will be added separately. */
                                var is_router_ip = false;
                                for (ipv4 in rport.networks.ipv4_addrs) {
                                    if (nat.external_ip == ipv4.addr_s) {
                                        is_router_ip = true;
                                        break
                                    }
                                };
                                if (not is_router_ip) {
                                    for (ipv6 in rport.networks.ipv6_addrs) {
                                        if (nat.external_ip == ipv6.addr_s) {
                                            is_router_ip = true;
                                            break
                                        }
                                    }
                                };
                                if (not is_router_ip) {
                                    c_addresses = c_addresses ++ " ${nat.external_ip}";
                                    central_ip_address = true
                                }
                            }
                        } else ()
                    }
                }
            };

            /* A set to hold all load-balancer vips. */
            (var all_ips_v4, var all_ips_v6) = get_router_load_balancer_ips(router);

            for (ip_address in set_union(all_ips_v4, all_ips_v6)) {
                c_addresses = c_addresses ++ " ${ip_address}";
                central_ip_address = true
            };

            if (central_ip_address) {
                /* Gratuitous ARP for centralized NAT rules on distributed gateway
                 * ports should be restricted to the gateway chassis. */
                if (has_redirect) {
                    c_addresses = c_addresses ++ " is_chassis_resident(${router.redirect_port_name})"
                } else ();

                set_insert(addresses, c_addresses)
            } else ();
            addresses
        }
    }
}

function get_garp_nat_addresses(rport: RouterPort): string = {
    var garp_info: Vec<string> = vec_empty();
    vec_push(garp_info, rport.networks.ea_s);
    for (ipv4_addr in rport.networks.ipv4_addrs) {
        vec_push(garp_info, ipv4_addr.addr_s)
    };
    if (rport.router.redirect_port_name != "") {
        vec_push(garp_info,
                 "is_chassis_resident(${rport.router.redirect_port_name})")
    };
    string_join(garp_info, " ")
}

/* Extra options computed for router ports by the logical flow generation code */
relation RouterPortRAOptions(lrp: uuid, options: Map<string, string>)

relation RouterPortRAOptionsComplete(lrp: uuid, options: Map<string, string>)

RouterPortRAOptionsComplete(lrp, options) :-
    RouterPortRAOptions(lrp, options).
RouterPortRAOptionsComplete(lrp, map_empty()) :-
    nb.Logical_Router_Port(._uuid = lrp),
    not RouterPortRAOptions(lrp, _).


/*
 * Create derived port for Logical_Router_Ports with non-empty 'gateway_chassis' column.
 */

/* Create derived ports */
OutProxy_Port_Binding(// lrp._uuid is already in use; generate a new UUID by
                      // hashing it.
                      ._uuid              = hash128(lrp._uuid),
                      .logical_port       = chassis_redirect_name(lrp.name),
                      .__type             = "chassisredirect",
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = Some{hacg_uuid},
                      .options            = options,
                      .datapath           = lr_uuid,
                      .parent_port        = None,
                      .tag                = None,  //always empty for router ports
                      .mac                = set_singleton("${lrp.mac} ${set_space_sep(lrp.networks)}"),
                      .nat_addresses      = set_empty(),
                      .external_ids       = lrp.external_ids) :-
    DistributedGatewayPort(lrp, lr_uuid),
    LogicalRouterHAChassisGroup(lr_uuid, hacg_uuid),
    var redirect_type: Map<string,string> = match (map_get(lrp.options, "redirect-type")) {
        Some{var value} -> map_singleton("redirect-type", value),
        _ -> map_empty()
    },
    var options = map_insert_imm(redirect_type, "distributed-port", lrp.name).


/* Add allocated qdisc_queue_id and tunnel key to Port_Binding.
 */
sb.Out_Port_Binding(._uuid              = pbinding._uuid,
                    .logical_port       = pbinding.logical_port,
                    .__type             = pbinding.__type,
                    .gateway_chassis    = pbinding.gateway_chassis,
                    .ha_chassis_group   = pbinding.ha_chassis_group,
                    .options            = options0,
                    .datapath           = pbinding.datapath,
                    .tunnel_key         = tunkey,
                    .parent_port        = pbinding.parent_port,
                    .tag                = pbinding.tag,
                    .mac                = pbinding.mac,
                    .nat_addresses      = pbinding.nat_addresses,
                    .external_ids       = pbinding.external_ids) :-
    pbinding in OutProxy_Port_Binding(),
    PortTunKeyAllocation(pbinding._uuid, tunkey),
    QueueIDAllocation(pbinding._uuid, qid),
    var options0 = match (qid) {
        None -> pbinding.options,
        Some{id} -> map_insert_imm(pbinding.options, "qdisc_queue_id", "${id}")
    }.

/* Referenced chassis.
 *
 * These tables track the sb.Chassis that a packet that traverses logical
 * router 'lr_uuid' can end up at (or start from).  This is used for
 * sb.Out_HA_Chassis_Group's ref_chassis column.
 *
 * RefChassisSet0 has a row for each logical router that actually references a
 * chassis.  RefChassisSet has a row for every logical router. */
relation RefChassis(lr_uuid: uuid, chassis_uuid: uuid)
RefChassis(lr_uuid, chassis_uuid) :-
    ReachableLogicalRouter(lr_uuid, lr2_uuid),
    FirstHopLogicalRouter(lr2_uuid, ls_uuid),
    LogicalSwitchPort(lsp_uuid, ls_uuid),
    nb.Logical_Switch_Port(._uuid = lsp_uuid, .name = lsp_name),
    sb.Port_Binding(.logical_port = lsp_name, .chassis = chassis_uuids),
    Some{var chassis_uuid} = chassis_uuids.
relation RefChassisSet0(lr_uuid: uuid, chassis_uuids: Set<uuid>)
RefChassisSet0(lr_uuid, chassis_uuids) :-
    RefChassis(lr_uuid, chassis_uuid),
    var chassis_uuids = Aggregate((lr_uuid), group2set(chassis_uuid)).
relation RefChassisSet(lr_uuid: uuid, chassis_uuids: Set<uuid>)
RefChassisSet(lr_uuid, chassis_uuids) :-
    RefChassisSet0(lr_uuid, chassis_uuids).
RefChassisSet(lr_uuid, set_empty()) :-
    nb.Logical_Router(._uuid = lr_uuid),
    not RefChassisSet0(lr_uuid, _).

/* Referenced chassis for an HA chassis group.
 *
 * Multiple logical routers can reference an HA chassis group so we merge the
 * referenced chassis across all of them.
 */
relation HAChassisGroupRefChassisSet(hacg_uuid: uuid,
                                     chassis_uuids: Set<uuid>)
HAChassisGroupRefChassisSet(hacg_uuid, chassis_uuids) :-
    LogicalRouterHAChassisGroup(lr_uuid, hacg_uuid),
    RefChassisSet(lr_uuid, chassis_uuids),
    var chassis_uuids = Aggregate((hacg_uuid), group_set_unions(chassis_uuids)).

/* HA_Chassis_Group and HA_Chassis. */
sb.Out_HA_Chassis_Group(hacg_uuid, hacg_name, ha_chassis, ref_chassis, eids) :-
    HAChassis(hacg_uuid, chassis_name, _, _),
    var ha_chassis_uuid = ha_chassis_uuid(chassis_name),
    var ha_chassis = Aggregate((hacg_uuid), group2set(ha_chassis_uuid)),
    HAChassisGroup(hacg_uuid, hacg_name, eids),
    HAChassisGroupRefChassisSet(hacg_uuid, ref_chassis).

sb.Out_HA_Chassis(ha_chassis_uuid(chassis_name), chassis, priority, eids) :-
    HAChassis(_, chassis_name, priority, eids),
    chassis_rec in sb.Chassis(.name = chassis_name),
    var chassis = Some{chassis_rec._uuid}.
sb.Out_HA_Chassis(ha_chassis_uuid(chassis_name), None, priority, eids) :-
    HAChassis(_, chassis_name, priority, eids),
    not chassis_rec in sb.Chassis(.name = chassis_name).

relation HAChassisToChassis(name: string, chassis: Option<uuid>)
HAChassisToChassis(name, Some{chassis}) :-
    sb.Chassis(._uuid = chassis, .name = name).
HAChassisToChassis(name, None) :-
    nb.HA_Chassis(.chassis_name = name),
    not sb.Chassis(.name = name).
sb.Out_HA_Chassis(ha_chassis_uuid(ha_chassis.chassis_name), chassis, priority, eids) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    Some{var ha_chassis_group_uuid} = sp.lsp.ha_chassis_group,
    ha_chassis_group in nb.HA_Chassis_Group(._uuid = ha_chassis_group_uuid),
    var ha_chassis_uuid = FlatMap(ha_chassis_group.ha_chassis),
    ha_chassis in nb.HA_Chassis(._uuid = ha_chassis_uuid, .priority = priority, .external_ids = eids),
    HAChassisToChassis(ha_chassis.chassis_name, chassis).
sb.Out_HA_Chassis_Group(_uuid, name, ha_chassis, set_empty() /* XXX? */, eids) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    var ls_uuid = sp.sw.ls._uuid,
    Some{var ha_chassis_group_uuid} = sp.lsp.ha_chassis_group,
    ha_chassis_group in nb.HA_Chassis_Group(._uuid = ha_chassis_group_uuid, .name = name,
                                            .external_ids = eids),
    var ha_chassis_uuid = FlatMap(ha_chassis_group.ha_chassis),
    ha_chassis in nb.HA_Chassis(._uuid = ha_chassis_uuid),
    var ha_chassis_uuid_name = ha_chassis_uuid(ha_chassis.chassis_name),
    var ha_chassis = Aggregate((ls_uuid, name, eids), group2set(ha_chassis_uuid_name)),
    var _uuid = ha_chassis_group_uuid(ls_uuid).

/*
 * SB_Global: copy nb_cfg and options from NB.
 * If NB_Global does not exist yet, just keep the current value of SB_Global,
 * if any.
 */
for (nb_global in nb.NB_Global) {
    sb.Out_SB_Global(._uuid          = nb_global._uuid,
                     .nb_cfg         = nb_global.nb_cfg,
                     .options        = nb_global.options,
                     .ipsec          = nb_global.ipsec)
}

sb.Out_SB_Global(._uuid          = sb_global._uuid,
                 .nb_cfg         = sb_global.nb_cfg,
                 .options        = sb_global.options,
                 .ipsec          = sb_global.ipsec) :-
    sb_global in sb.SB_Global(),
    not nb.NB_Global().


/* Track minimum hv_cfg across all the (non-remote) chassis. */
relation HvCfg0(hv_cfg: integer)
HvCfg0(hv_cfg) :-
    sb.Chassis(.nb_cfg = chassis_cfg, .external_ids = eids),
    not map_get_bool_def(eids, "is-remote", false),
    var hv_cfg = Aggregate((), group_min(chassis_cfg)).
relation HvCfg(hv_cfg: integer)
HvCfg(hv_cfg) :- HvCfg0(hv_cfg).
HvCfg(hv_cfg) :- Unit(), not HvCfg0(), nb.NB_Global(.nb_cfg = hv_cfg).

/*
 * NB_Global:
 * - set `sb_cfg` to the value of `SB_Global.nb_cfg`.
 * - set `hv_cfg` to the smallest value of `nb_cfg` across all `Chassis`
 * - FIXME: we use ipsec as unique key to make sure that we don't create multiple `NB_Global`
 *   instance.  There is a potential race condition if this field is modified at the same
 *   time northd is updating `sb_cfg` or `hv_cfg`.
 */
nb.Out_NB_Global(._uuid         = _uuid,
                 .sb_cfg        = sb_cfg,
                 .hv_cfg        = hv_cfg,
                 .ipsec         = ipsec,
                 .options       = options) :-
    nbg in nb.NB_Global(._uuid = _uuid, .ipsec = ipsec),
    sb.SB_Global(.nb_cfg = sb_cfg),
    HvCfg(hv_cfg),
    MacPrefix(mac_prefix),
    SvcMonitorMac(svc_monitor_mac),
    var options0 = put_mac_prefix(nbg.options, mac_prefix),
    var options = put_svc_monitor_mac(options0, svc_monitor_mac).

/* SB_Global does not exist yet -- just keep the old value of NB_Global */
nb.Out_NB_Global(._uuid         = nbg._uuid,
                 .sb_cfg        = nbg.sb_cfg,
                 .hv_cfg        = nbg.hv_cfg,
                 .ipsec         = nbg.ipsec,
                 .options       = nbg.options) :-
    nbg in nb.NB_Global(),
    not sb.SB_Global().

output relation Northd_Probe_Interval[integer]
Northd_Probe_Interval[interval] :-
    nb in nb.NB_Global(),
    var interval = map_get_int_def(nb.options, "northd_probe_interval", 0).

/*
 * Address_Set: copy from NB + additional records generated from NB Port_Group (two records for each
 * Port_Group for IPv4 and IPv6 addresses).
 *
 * There can be name collisions between the two types of Address_Set records.  User-defined records
 * take precedence.
 */
for (nb_as in nb.Address_Set) {
    sb.Out_Address_Set(._uuid     = nb_as._uuid,
                       .name      = nb_as.name,
                       .addresses = nb_as.addresses)
}

sb.Out_Address_Set(._uuid = hash128("svc_monitor_mac"),
                   .name = "svc_monitor_mac",
                   .addresses = set_singleton("${svc_monitor_mac}")) :-
    SvcMonitorMac(svc_monitor_mac).

sb.Out_Address_Set(hash128(as_name), as_name, set_unions(pg_ip4addrs)) :-
    nb.Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip4addrs = stat),
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = nb.Logical_Switch_Port{._uuid = port_uuid}},
                                dyn_addr),
    var dynamic: Set<string> = match (dyn_addr) {
        None -> set_empty(),
        Some{lpaddress} -> match (vec_nth(lpaddress.ipv4_addrs, 0)) {
            None -> set_empty(),
            Some{addr} -> set_singleton(addr.addr_s)
        }
    },
    //PortDynamicAddresses(.lsport = port_uuid, .ip4addrs = dynamic),
    var port_ip4addrs: Set<string> = set_union(stat, dynamic),
    var pg_ip4addrs = Aggregate((as_name), group2vec(port_ip4addrs)).

sb.Out_Address_Set(hash128(as_name), as_name, set_empty()) :-
    nb.Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name).

sb.Out_Address_Set(hash128(as_name), as_name, set_unions(pg_ip6addrs)) :-
    nb.Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip6addrs = stat),
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = nb.Logical_Switch_Port{._uuid = port_uuid}},
                                dyn_addr),
    var dynamic: Set<string> = match (dyn_addr) {
        None -> set_empty(),
        Some{lpaddress} -> match (vec_nth(lpaddress.ipv6_addrs, 0)) {
            None -> set_empty(),
            Some{addr} -> set_singleton(addr.addr_s)
        }
    },
    //PortDynamicAddresses(.lsport = port_uuid, .ip6addrs = dynamic),
    var port_ip6addrs = set_union(stat, dynamic),
    var pg_ip6addrs = Aggregate((as_name), group2vec(port_ip6addrs)).

sb.Out_Address_Set(hash128(as_name), as_name, set_empty()) :-
    nb.Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name).

/*
 * Port_Group: copy from NB, but replace UUIDs with logical port names
 */
sb.Out_Port_Group(._uuid = _uuid, .name = pg_name, .ports = port_names) :-
    nb.Port_Group(._uuid = _uuid, .name = pg_name, .ports = pg_ports),
    var port_uuid = FlatMap(pg_ports),
    nb.Logical_Switch_Port(._uuid = port_uuid, .name = port_name),
    var port_names = Aggregate((_uuid, pg_name), group2set(port_name)).

sb.Out_Port_Group(._uuid = _uuid, .name = pg_name, .ports = set_empty()) :-
    nb.Port_Group(._uuid = _uuid, .name = pg_name, .ports = set_empty()).

/*
 * Multicast_Group:
 * - three static rows per logical switch: one for flooding, one for packets
 *   with unknown destinations, one for flooding IP multicast known traffic to
 *   mrouters.
 * - dynamically created rows based on IGMP groups learned by controllers.
 */

function mC_FLOOD():         (string, integer) =
    ("_MC_flood", 64'd32768)

function mC_UNKNOWN():       (string, integer) =
    ("_MC_unknown", 64'd32769)

function mC_MROUTER_FLOOD(): (string, integer) =
    ("_MC_mrouter_flood", 64'd32770)

function mC_MROUTER_STATIC(): (string, integer) =
    ("_MC_mrouter_static", 64'd32771)

function mC_STATIC(): (string, integer) =
    ("_MC_static", 64'd32772)

function mC_IP_MCAST_MIN():  (string, integer) =
    ("_MC_ip_mcast_min", 64'd32773)

function mC_IP_MCAST_MAX():  (string, integer) =
    ("_MC_ip_mcast_max", 64'd65535)


// TODO: check that Multicast_Group.ports should not include derived ports

/* Proxy table for Out_Multicast_Group: contains all Multicast_Group fields,
 * except `_uuid`, which will be computed by hashing the remaining fields,
 * and tunnel key, which case it is allocated separately (see
 * MulticastGroupTunKeyAllocation). */
relation OutProxy_Multicast_Group (
    datapath: uuid,
    name: string,
    ports: Set<uuid>
)

/* Only create flood group if the switch has enabled ports */
sb.Out_Multicast_Group (._uuid      = hash128((datapath,name)),
                        .datapath   = datapath,
                        .name       = name,
                        .tunnel_key = tunnel_key,
                        .ports      = port_ids) :-
    &SwitchPort(.lsp = lsp, .sw = &Switch{.ls = ls}),
    is_enabled(lsp.enabled),
    var datapath = ls._uuid,
    var port_ids = Aggregate((datapath), group2set(lsp._uuid)),
    (var name, var tunnel_key) = mC_FLOOD().

/* Only create unknown group if the switch has ports with "unknown" address */
sb.Out_Multicast_Group (._uuid      = hash128((ls,name)),
                        .datapath   = ls,
                        .name       = name,
                        .tunnel_key = tunnel_key,
                        .ports      = port_ids) :-
    LogicalSwitchUnknownPorts(ls, port_ids),
    (var name, var tunnel_key) = mC_UNKNOWN().

/* Create a multicast group to flood multicast traffic to routers with
 * multicast relay enabled.
 */
sb.Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodRelayPorts(&sw, port_ids), not set_is_empty(port_ids),
    (var name, var tunnel_key) = mC_MROUTER_FLOOD().

/* Create a multicast group to flood traffic (no reports) to ports with
 * multicast flood enabled.
 */
sb.Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodPorts(&sw, port_ids), not set_is_empty(port_ids),
    (var name, var tunnel_key) = mC_STATIC().

/* Create a multicast group to flood reports to ports with
 * multicast flood_reports enabled.
 */
sb.Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodReportPorts(&sw, port_ids), not set_is_empty(port_ids),
    (var name, var tunnel_key) = mC_MROUTER_STATIC().

/* Create a multicast group to flood traffic and reports to router ports with
 * multicast flood enabled.
 */
sb.Out_Multicast_Group (._uuid    = hash128((rtr.lr._uuid,name)),
                        .datapath = rtr.lr._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    RouterMcastFloodPorts(&rtr, port_ids), not set_is_empty(port_ids),
    (var name, var tunnel_key) = mC_STATIC().

/* Create a multicast group for each IGMP group learned by a Switch.
 * 'tunnel_key' == 0 triggers an ID allocation later.
 */
OutProxy_Multicast_Group (.datapath   = switch.ls._uuid,
                          .name       = address,
                          .ports      = port_ids) :-
    IgmpSwitchMulticastGroup(address, &switch, port_ids).

/* Create a multicast group for each IGMP group learned by a Router.
 * 'tunnel_key' == 0 triggers an ID allocation later.
 */
OutProxy_Multicast_Group (.datapath   = router.lr._uuid,
                          .name       = address,
                          .ports      = port_ids) :-
    IgmpRouterMulticastGroup(address, &router, port_ids).

/* Allocate a 'tunnel_key' for dynamic multicast groups. */
sb.Out_Multicast_Group(._uuid    = hash128((mcgroup.datapath,mcgroup.name)),
                       .datapath = mcgroup.datapath,
                       .name = mcgroup.name,
                       .tunnel_key = tunnel_key,
                       .ports = mcgroup.ports) :-
    mcgroup in OutProxy_Multicast_Group(),
    MulticastGroupTunKeyAllocation(mcgroup.datapath, mcgroup.name, tunnel_key).

/*
 * MAC binding: records inserted by hypervisors; northd removes records for deleted logical ports and datapaths.
 */
sb.Out_MAC_Binding (._uuid        = mb._uuid,
                    .logical_port = mb.logical_port,
                    .ip           = mb.ip,
                    .mac          = mb.mac,
                    .datapath     = mb.datapath) :-
    sb.MAC_Binding[mb],
    sb.Out_Port_Binding(.logical_port = mb.logical_port),
    sb.Out_Datapath_Binding(._uuid = mb.datapath).

/*
 * DHCP options: fixed table
 */
sb.Out_DHCP_Options (
    ._uuid  = 128'h7d9d898a_179b_4898_8382_b73bec391f23,
    .name   = "offerip",
    .code   = 0,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hea5e7d14_fd97_491c_8004_a120bdbc4306,
    .name   = "netmask",
    .code   = 1,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hdab5e39b_6702_4245_9573_6c142aa3724c,
    .name   = "router",
    .code   = 3,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h340b4bc5_c5c3_43d1_ae77_564da69c8fcc,
    .name   = "dns_server",
    .code   = 6,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hcd1ab302_cbb2_4eab_9ec5_ec1c8541bd82,
    .name   = "log_server",
    .code   = 7,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h1c7ea6a0_fe6b_48c1_a920_302583c1ff08,
    .name   = "lpr_server",
    .code   = 9,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hae35e575_226a_4ab5_a1c4_166f426dd999,
    .name   = "domain_name",
    .code   = 15,
    .__type = "str"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'had0ec3e0_8be9_4c77_bceb_f8954a34c7ba,
    .name   = "swap_server",
    .code   = 16,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h884c2e02_6e99_4d12_aef7_8454ebf8a3b7,
    .name   = "policy_filter",
    .code   = 21,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h57cc2c61_fd2a_41c6_b6b1_6ce9a8901f86,
    .name   = "router_solicitation",
    .code   = 32,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h48249097_03f0_46c1_a32a_2dd57cd4d0f8,
    .name   = "nis_server",
    .code   = 41,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h333fe07e_bdd1_4371_aa4f_a412bc60f3a2,
    .name   = "ntp_server",
    .code   = 42,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h6207109c_49d0_4348_8238_dd92afb69bf0,
    .name   = "server_id",
    .code   = 54,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h2090b783_26d3_4c1d_830c_54c1b6c5d846,
    .name   = "tftp_server",
    .code   = 66,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'ha18ff399_caea_406e_af7e_321c6f74e581,
    .name   = "classless_static_route",
    .code   = 121,
    .__type = "static_routes"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hb81ad7b4_62f0_40c7_a9a3_f96677628767,
    .name   = "ms_classless_static_route",
    .code   = 249,
    .__type = "static_routes"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h0c2e144e_4b5f_4e21_8978_0e20bac9a6ea,
    .name   = "ip_forward_enable",
    .code   = 19,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h6feb1926_9469_4b40_bfbf_478b9888cd3a,
    .name   = "router_discovery",
    .code   = 31,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hcb776249_e8b1_4502_b33b_fa294d44077d,
    .name   = "ethernet_encap",
    .code   = 36,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'ha2df9eaa_aea9_497f_b339_0c8ec3e39a07,
    .name   = "default_ttl",
    .code   = 23,
    .__type = "uint8"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hb44b45a9_5004_4ef5_8e6a_aa8629e1afb1,
    .name   = "tcp_ttl",
    .code   = 37,
    .__type = "uint8"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h50f01ca7_c650_46f0_8f50_39a67ec657da,
    .name   = "mtu",
    .code   = 26,
    .__type = "uint16"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h9d31c057_6085_4810_96af_eeac7d3c5308,
    .name   = "lease_time",
    .code   = 51,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hea1e2e7a_9585_46ee_ad49_adfdefc0c4ef,
    .name   = "T1",
    .code   = 58,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hbc83a233_554b_453a_afca_1eadf76810d2,
    .name   = "T2",
    .code   = 59,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h1ab3eeca_0523_4101_9076_eea77d0232f4,
    .name   = "bootfile_name",
    .code   = 67,
    .__type = "str"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'ha5c20b69_f7f3_4fa8_b550_8697aec6cbb7,
    .name   = "wpad",
    .code   = 252,
    .__type = "str"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h1516bcb6_cc93_4233_a63f_bd29c8601831,
    .name   = "path_prefix",
    .code   = 210,
    .__type = "str"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hc98e13cd_f653_473c_85c1_850dcad685fc,
    .name   = "tftp_server_address",
    .code   = 150,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'hfbe06e70_b43d_4dd9_9b21_2f27eb5da5df,
    .name   = "arp_cache_timeout",
    .code   = 35,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    ._uuid  = 128'h2af54a3c_545c_4104_ae1c_432caa3e085e,
    .name   = "tcp_keepalive_interval",
    .code   = 38,
    .__type = "uint32"
).


/*
 * DHCPv6 options: fixed table
 */
sb.Out_DHCPv6_Options (
    ._uuid  = 128'h100b2659_0ec0_4da7_9ec3_25997f92dc00,
    .name   = "server_id",
    .code   = 2,
    .__type = "mac"
).

sb.Out_DHCPv6_Options (
    ._uuid  = 128'h53f49b50_db75_4b0d_83df_50d31009ca9c,
    .name   = "ia_addr",
    .code   = 5,
    .__type = "ipv6"
).

sb.Out_DHCPv6_Options (
    ._uuid  = 128'he3619685_d4f7_42ad_936b_4f4440b7eeb4,
    .name   = "dns_server",
    .code   = 23,
    .__type = "ipv6"
).

sb.Out_DHCPv6_Options (
    ._uuid  = 128'hcb8a4e7f_a312_4cb1_a846_e474d9f0c531,
    .name   = "domain_search",
    .code   = 24,
    .__type = "str"
).


/*
 * DNS: copied from NB + datapaths column pointer to LS datapaths that use the record
 */

function map_to_lowercase(m_in: Map<string,string>): Map<string,string> {
    var m_out: Map<string,string> = map_empty();
    for (node in m_in) {
        (var k, var v) = node;
        map_insert(m_out, string_to_lowercase(k), string_to_lowercase(v))
    };
    m_out
}

sb.Out_DNS(._uuid        = nbdns._uuid,
           .records      = map_to_lowercase(nbdns.records),
           .datapaths    = datapaths,
           .external_ids = map_insert_imm(nbdns.external_ids, "dns_id", uuid2str(nbdns._uuid))) :-
    nb.DNS[nbdns],
    LogicalSwitchDNS(ls_uuid, nbdns._uuid),
    var datapaths = Aggregate((nbdns), group2set(ls_uuid)).

/*
 * RBAC_Permission: fixed
 */

sb.Out_RBAC_Permission (
    ._uuid          = 128'h7df3749a_1754_4a78_afa4_3abf526fe510,
    .table          = "Chassis",
    .authorization  = set_singleton("name"),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "nb_cfg");
            set_insert(s, "external_ids");
            set_insert(s, "encaps");
            set_insert(s, "vtep_logical_switches");
            s
        }
).

sb.Out_RBAC_Permission (
    ._uuid          = 128'h94bec860_431e_4d95_82e7_3b75d8997241,
    .table          = "Encap",
    .authorization  = set_singleton("chassis_name"),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "type");
            set_insert(s, "options");
            set_insert(s, "ip");
            s
        }
).

sb.Out_RBAC_Permission (
    ._uuid          = 128'hd8ceff1a_2b11_48bd_802f_4a991aa4e908,
    .table          = "Port_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = false,
    .update         = set_singleton("chassis")
).

sb.Out_RBAC_Permission (
    ._uuid          = 128'h6ffdc696_8bfb_4d82_b620_a00d39270b2f,
    .table          = "MAC_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "logical_port");
            set_insert(s, "ip");
            set_insert(s, "mac");
            set_insert(s, "datapath");
            s
        }
).

sb.Out_RBAC_Permission (
    ._uuid          = 128'h39231c7e_4bf1_41d0_ada4_1d8a319c0da3,
    .table          = "Service_Monitor",
    .authorization  = set_singleton(""),
    .insert_delete  = false,
    .update         = set_singleton("status")
).

/*
 * RBAC_Role: fixed
 */
sb.Out_RBAC_Role (
    ._uuid       = 128'ha406b472_5de8_4456_9f38_bf344c911b22,
    .name        = "ovn-controller",
    .permissions = {
            var m: Map<string, uuid> = map_empty();
            map_insert(m, "Chassis"     , 128'h7df3749a_1754_4a78_afa4_3abf526fe510);
            map_insert(m, "Encap"       , 128'h94bec860_431e_4d95_82e7_3b75d8997241);
            map_insert(m, "Port_Binding", 128'hd8ceff1a_2b11_48bd_802f_4a991aa4e908);
            map_insert(m, "MAC_Binding" , 128'h6ffdc696_8bfb_4d82_b620_a00d39270b2f);
            map_insert(m, "Service_Monitor" , 128'h39231c7e_4bf1_41d0_ada4_1d8a319c0da3);
            m
        }
).

/* Output modified Logical_Switch_Port table with dynamic address updated */
nb.Out_Logical_Switch_Port(._uuid                  = lsp._uuid,
                           .tag                    = tag,
                           .dynamic_addresses      = dynamic_addresses,
                           .up                     = Some{up}) :-
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = lsp, .up = up}, opt_dyn_addr),
    var dynamic_addresses: Option<string> = match (opt_dyn_addr) {
        None -> None,
        Some{dyn_addr} -> Some{"${dyn_addr}"}
    },
    SwitchPortNewDynamicTag(lsp._uuid, opt_tag),
    var tag: Option<integer> = match (opt_tag) {
        None -> lsp.tag,
        Some{t} -> Some{t}
    }.

relation LRPIPv6Prefix0(lrp_uuid: uuid, ipv6_prefix: string)
LRPIPv6Prefix0(lrp._uuid, ipv6_prefix) :-
    lrp in nb.Logical_Router_Port(),
    map_get_bool_def(lrp.options, "prefix", false),
    sb.Port_Binding(.logical_port = lrp.name, .options = options),
    Some{var ipv6_ra_pd_list} = map_get(options, "ipv6_ra_pd_list"),
    var parts = string_split(ipv6_ra_pd_list, ","),
    Some{var ipv6_prefix} = vec_nth(parts, 1).

relation LRPIPv6Prefix(lrp_uuid: uuid, ipv6_prefix: Option<string>)
LRPIPv6Prefix(lrp_uuid, Some{ipv6_prefix}) :-
    LRPIPv6Prefix0(lrp_uuid, ipv6_prefix).
LRPIPv6Prefix(lrp_uuid, None) :-
    nb.Logical_Router_Port(._uuid = lrp_uuid),
    not LRPIPv6Prefix0(lrp_uuid, _).

nb.Out_Logical_Router_Port(._uuid = _uuid,
                           .ipv6_prefix = option2set(ipv6_prefix)) :-
    nb.Logical_Router_Port(._uuid = _uuid, .name = name),
    LRPIPv6Prefix(_uuid, ipv6_prefix).

typedef Direction = IN | OUT

typedef PipelineStage = PORT_SEC_L2
                      | PORT_SEC_IP
                      | PORT_SEC_ND
                      | PRE_ACL
                      | PRE_LB
                      | PRE_STATEFUL
                      | ACL
                      | QOS_MARK
                      | QOS_METER
                      | LB
                      | STATEFUL
                      | PRE_HAIRPIN
                      | HAIRPIN
                      | ARP_ND_RSP
                      | DHCP_OPTIONS
                      | DHCP_RESPONSE
                      | DNS_LOOKUP
                      | DNS_RESPONSE
              | EXTERNAL_PORT
                      | L2_LKUP
                      | ADMISSION
                      | LOOKUP_NEIGHBOR
                      | LEARN_NEIGHBOR
                      | IP_INPUT
                      | DEFRAG
                      | UNSNAT
                      | DNAT
                      | ND_RA_OPTIONS
                      | ND_RA_RESPONSE
                     | IP_ROUTING
                     | IP_ROUTING_ECMP
                     | POLICY
                     | ARP_RESOLVE
                     | CHK_PKT_LEN
                     | LARGER_PKTS
                     | GW_REDIRECT
                     | ARP_REQUEST
                     | UNDNAT
                      | SNAT
                      | EGR_LOOP
                      | DELIVERY

typedef DatapathType = LSwitch | LRouter

typedef Stage = Stage{
    datapath    : DatapathType,
    direction   : Direction,
    stage       : PipelineStage
}

function switch_stage(direction: Direction, stage: PipelineStage): Stage = {
    Stage{LSwitch, direction, stage}
}

function router_stage(direction: Direction, stage: PipelineStage): Stage = {
    Stage{LRouter, direction, stage}
}

function stage_id(stage: Stage): (integer, string) =
{
    match ((stage.datapath, stage.direction, stage.stage)) {
        /* Logical switch ingress stages. */
        (LSwitch, IN,  PORT_SEC_L2)   -> (0,  "ls_in_port_sec_l2"),
        (LSwitch, IN,  PORT_SEC_IP)   -> (1,  "ls_in_port_sec_ip"),
        (LSwitch, IN,  PORT_SEC_ND)   -> (2,  "ls_in_port_sec_nd"),
        (LSwitch, IN,  PRE_ACL)       -> (3,  "ls_in_pre_acl"),
        (LSwitch, IN,  PRE_LB)        -> (4,  "ls_in_pre_lb"),
        (LSwitch, IN,  PRE_STATEFUL)  -> (5,  "ls_in_pre_stateful"),
        (LSwitch, IN,  ACL)           -> (6,  "ls_in_acl"),
        (LSwitch, IN,  QOS_MARK)      -> (7,  "ls_in_qos_mark"),
        (LSwitch, IN,  QOS_METER)     -> (8,  "ls_in_qos_meter"),
        (LSwitch, IN,  LB)            -> (9,  "ls_in_lb"),
        (LSwitch, IN,  STATEFUL)      -> (10, "ls_in_stateful"),
        (LSwitch, IN,  PRE_HAIRPIN)   -> (11, "ls_in_pre_hairpin"),
        (LSwitch, IN,  HAIRPIN)       -> (12, "ls_in_hairpin"),
        (LSwitch, IN,  ARP_ND_RSP)    -> (13, "ls_in_arp_rsp"),
        (LSwitch, IN,  DHCP_OPTIONS)  -> (14, "ls_in_dhcp_options"),
        (LSwitch, IN,  DHCP_RESPONSE) -> (15, "ls_in_dhcp_response"),
        (LSwitch, IN,  DNS_LOOKUP)    -> (16, "ls_in_dns_lookup"),
        (LSwitch, IN,  DNS_RESPONSE)  -> (17, "ls_in_dns_response"),
        (LSwitch, IN,  EXTERNAL_PORT) -> (18, "ls_in_external_port"),
        (LSwitch, IN,  L2_LKUP)       -> (19, "ls_in_l2_lkup"),

        /* Logical switch egress stages. */
        (LSwitch, OUT, PRE_LB)        -> (0,  "ls_out_pre_lb"),
        (LSwitch, OUT, PRE_ACL)       -> (1,  "ls_out_pre_acl"),
        (LSwitch, OUT, PRE_STATEFUL)  -> (2,  "ls_out_pre_stateful"),
        (LSwitch, OUT, LB)            -> (3,  "ls_out_lb"),
        (LSwitch, OUT, ACL)           -> (4,  "ls_out_acl"),
        (LSwitch, OUT, QOS_MARK)      -> (5,  "ls_out_qos_mark"),
        (LSwitch, OUT, QOS_METER)     -> (6,  "ls_out_qos_meter"),
        (LSwitch, OUT, STATEFUL)      -> (7,  "ls_out_stateful"),
        (LSwitch, OUT, PORT_SEC_IP)   -> (8,  "ls_out_port_sec_ip"),
        (LSwitch, OUT, PORT_SEC_L2)   -> (9,  "ls_out_port_sec_l2"),

        /* Logical router ingress stages. */
        (LRouter, IN,  ADMISSION)     -> (0,  "lr_in_admission"),
        (LRouter, IN,  LOOKUP_NEIGHBOR) -> (1, "lr_in_lookup_neighbor"),
        (LRouter, IN,  LEARN_NEIGHBOR) -> (2, "lr_in_learn_neighbor"),
        (LRouter, IN,  IP_INPUT)      -> (3,  "lr_in_ip_input"),
        (LRouter, IN,  DEFRAG)        -> (4,  "lr_in_defrag"),
        (LRouter, IN,  UNSNAT)        -> (5,  "lr_in_unsnat"),
        (LRouter, IN,  DNAT)          -> (6,  "lr_in_dnat"),
        (LRouter, IN,  ND_RA_OPTIONS) -> (7,  "lr_in_nd_ra_options"),
        (LRouter, IN,  ND_RA_RESPONSE)-> (8,  "lr_in_nd_ra_response"),
       (LRouter, IN,  IP_ROUTING)    -> (9,  "lr_in_ip_routing"),
       (LRouter, IN,  IP_ROUTING_ECMP) -> (10,  "lr_in_ip_routing_ecmp"),
       (LRouter, IN,  POLICY)        -> (11,  "lr_in_policy"),
       (LRouter, IN,  ARP_RESOLVE)   -> (12,  "lr_in_arp_resolve"),
       (LRouter, IN,  CHK_PKT_LEN)   -> (13, "lr_in_chk_pkt_len"),
       (LRouter, IN,  LARGER_PKTS)   -> (14, "lr_in_larger_pkts"),
       (LRouter, IN,  GW_REDIRECT)   -> (15, "lr_in_gw_redirect"),
       (LRouter, IN,  ARP_REQUEST)   -> (16, "lr_in_arp_request"),

       /* Logical router egress stages. */
       (LRouter, OUT, UNDNAT)        -> (0,  "lr_out_undnat"),
        (LRouter, OUT, SNAT)          -> (1,  "lr_out_snat"),
        (LRouter, OUT, EGR_LOOP)      -> (2,  "lr_out_egr_loop"),
        (LRouter, OUT, DELIVERY)      -> (3,  "lr_out_delivery"),

        _                             -> (64'hffffffffffffffff, "") /* alternatively crash? */
    }
}


/* Register definitions specific to switches. */
function rEGBIT_CONNTRACK_DEFRAG() : string = "reg0[0]"
function rEGBIT_CONNTRACK_COMMIT() : string = "reg0[1]"
function rEGBIT_CONNTRACK_NAT()    : string = "reg0[2]"
function rEGBIT_DHCP_OPTS_RESULT() : string = "reg0[3]"
function rEGBIT_DNS_LOOKUP_RESULT(): string = "reg0[4]"
function rEGBIT_ND_RA_OPTS_RESULT(): string = "reg0[5]"
function rEGBIT_HAIRPIN()          : string = "reg0[6]"

/* Register definitions for switches and routers. */

/* Indicate that this packet has been recirculated using egress
 * loopback.  This allows certain checks to be bypassed, such as a
* logical router dropping packets with source IP address equals
* one of the logical router's own IP addresses. */
function rEGBIT_EGRESS_LOOPBACK()  : string = "reg9[0]"
/* Register to store the result of check_pkt_larger action. */
function rEGBIT_PKT_LARGER()       : string = "reg9[1]"
function rEGBIT_LOOKUP_NEIGHBOR_RESULT() : string = "reg9[2]"
function rEGBIT_SKIP_LOOKUP_NEIGHBOR() : string = "reg9[3]"
/* Register for ECMP bucket selection. */
function rEG_ECMP_GROUP_ID()  : string = "reg8[0..15]"
function rEG_ECMP_MEMBER_ID() : string = "reg8[16..31]"

function fLAGBIT_NOT_VXLAN() : string = "flags[1] == 0"

function mFF_N_LOG_REGS()          : bit<32> = 10

/*
 * Logical_Flow
   relation Out_Logical_Flow (
        logical_datapath: string,
        pipeline: string,
        table_id: integer,
        priority: integer,
        __match: string,
        actions: string,
        external_ids: Map<string,string>)
 */

relation Flow (
    logical_datapath: uuid,
    stage:            Stage,
    priority:         integer,
    __match:          string,
    actions:          string,
    external_ids:     Map<string,string>
)

sb.Out_Logical_Flow(._uuid            = hash128((f.logical_datapath, f.stage, f.priority, f.__match, f.actions, f.external_ids)),
                    .logical_datapath = f.logical_datapath,
                    .pipeline         = if (f.stage.direction == IN) "ingress" else "egress",
                    .table_id         = table_id,
                    .priority         = f.priority,
                    .__match          = f.__match,
                    .actions          = f.actions,
                    .external_ids     = map_insert_imm(f.external_ids, "stage-name", table_name)) :-
    Flow[f],
    (var table_id, var table_name) = stage_id(f.stage).

/* Logical flows for forwarding groups. */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, ARP_ND_RSP),
     .priority         = 50,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(fg_uuid)) :-
    sw in &Switch(),
    var fg_uuid = FlatMap(sw.ls.forwarding_groups),
    fg in nb.Forwarding_Group(._uuid = fg_uuid),
    not set_is_empty(fg.child_port),
    var __match = "arp.tpa == ${fg.vip} && arp.op == 1",
    var actions = "eth.dst = eth.src; "
                  "eth.src = ${fg.vmac}; "
                  "arp.op = 2; /* ARP reply */ "
                  "arp.tha = arp.sha; "
                  "arp.sha = ${fg.vmac}; "
                  "arp.tpa = arp.spa; "
                  "arp.spa = ${fg.vip}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output;".

function escape_child_ports(child_port: Set<string>): string {
    var escaped: Vec<string> = vec_with_capacity(set_size(child_port));
    for (s in child_port) {
        vec_push(escaped, json_string_escape(s))
    };
    string_join(escaped, ",")
}
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, L2_LKUP),
     .priority         = 50,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    sw in &Switch(),
    var fg_uuid = FlatMap(sw.ls.forwarding_groups),
    fg in nb.Forwarding_Group(._uuid = fg_uuid),
    not set_is_empty(fg.child_port),
    var __match = "eth.dst == ${fg.vmac}",
    var actions = "fwd_group(" ++
                  if (fg.liveness) { "liveness=\"true\"," } else { "" } ++
                  "childports=" ++ escape_child_ports(fg.child_port) ++ ");".

/* Logical switch ingress table PORT_SEC_L2: admission control framework
 * (priority 100) */
for (sw in &Switch()) {
    /* Logical VLANs not supported */
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, PORT_SEC_L2),
         .priority         = 100,
         .__match          = "vlan.present",
         .actions          = "drop;",
         .external_ids     = map_empty() /*TODO: check*/);

    /* Broadcast/multicast source address is invalid */
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, PORT_SEC_L2),
         .priority         = 100,
         .__match          = "eth.src[40]",
         .actions          = "drop;",
         .external_ids     = map_empty() /*TODO: check*/)
    /* Port security flows have priority 50 (see below) and will continue to the next table
       if packet source is acceptable. */
}

// space-separated vector of strings
function vec_space_sep(items: Vec<string>): string = {
    string_join(items, " ")
}

// space-separated set of strings
function set_space_sep(items: Set<string>): string = {
    vec_space_sep(set2vec(items))
}

function build_port_security_ipv6_flow(
    pipeline: Direction,
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var ip6_addrs: Vec<string> = vec_empty();

    /* Allow link-local address. */
    vec_push(ip6_addrs, ipv6_string_mapped(in6_generate_lla(ea)));

    /* Allow ip6.dst=ff00::/8 for multicast packets */
    if (pipeline == OUT) {
        vec_push(ip6_addrs, "ff00::/8")
    } else ();
    for (addr in ipv6_addrs) {
        vec_push(ip6_addrs, ipv6_string_mapped(addr.addr))
    };

    " && ${if (pipeline == IN) \"ip6.src\" else \"ip6.dst\"} == {${string_join(ip6_addrs, \", \")}}"
}

function build_port_security_ipv6_nd_flow(
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var __match = " && ip6 && nd && ((nd.sll == ${eth_addr_zero()} || "
                  "nd.sll == ${ea}) || ((nd.tll == ${eth_addr_zero()} || "
                  "nd.tll == ${ea})";
    if (vec_is_empty(ipv6_addrs)) {
        __match ++ "))"
    } else {
        var ip6_str = ipv6_string_mapped(in6_generate_lla(ea));
        __match = __match ++ " && (nd.target == ${ip6_str}";

        for(addr in ipv6_addrs) {
            ip6_str = ipv6_string_mapped(addr.addr);
            __match = __match ++ " || nd.target == ${ip6_str}"
        };
        __match ++ ")))"
    }
}

/* Pre-ACL */
for (&Switch(.ls =ls)) {
    /* Ingress and Egress Pre-ACL Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_ACL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_ACL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_ACL),
         .priority         = 110,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_ACL),
         .priority         = 110,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty())
}


/* If there are any stateful ACL rules in this datapath, we must
 * send all IP packets through the conntrack action, which handles
 * defragmentation, in order to match L4 headers. */

for (&SwitchPort(.lsp = lsp@nb.Logical_Switch_Port{.__type = "router"},
                 .json_name = lsp_name,
                 .sw = &Switch{.ls = ls, .has_stateful_acl = true})) {
    /* Can't use ct() for router ports. Consider the
     * following configuration: lp1(10.0.0.2) on
     * hostA--ls1--lr0--ls2--lp2(10.0.1.2) on hostB, For a
     * ping from lp1 to lp2, First, the response will go
     * through ct() with a zone for lp2 in the ls2 ingress
     * pipeline on hostB.  That ct zone knows about this
     * connection. Next, it goes through ct() with the zone
     * for the router port in the egress pipeline of ls2 on
     * hostB.  This zone does not know about the connection,
     * as the icmp request went through the logical router
     * on hostA, not hostB. This would only work with
     * distributed conntrack state across all chassis. */
    // FIXME: is this check redundant?
    Some{var router_port} = map_get(lsp.options, "router-port") in {
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, PRE_ACL),
             .priority         = 110,
             .__match          = "ip && inport == ${lsp_name}",
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid));
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, PRE_ACL),
             .priority         = 110,
             .__match          = "ip && outport == ${lsp_name}",
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

for (&SwitchPort(.lsp = lsp@nb.Logical_Switch_Port{.__type = "localnet"},
                 .json_name = lsp_name,
                 .sw = &Switch{.ls = ls, .has_stateful_acl = true})) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_ACL),
         .priority         = 110,
         .__match          = "ip && inport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid));
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_ACL),
         .priority         = 110,
         .__match          = "ip && outport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (&Switch(.ls = ls, .has_stateful_acl = true)) {
    /* Ingress and Egress Pre-ACL Table (Priority 110).
     *
     * Not to do conntrack on ND and ICMP destination
     * unreachable packets. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_ACL),
         .priority         = 110,
         .__match          = "nd || nd_rs || nd_ra || "
                             "(udp && udp.src == 546 && udp.dst == 547)",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_ACL),
         .priority         = 110,
         .__match          = "nd || nd_rs || nd_ra || "
                             "(udp && udp.src == 546 && udp.dst == 547)",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Ingress and Egress Pre-ACL Table (Priority 100).
     *
     * Regardless of whether the ACL is "from-lport" or "to-lport",
     * we need rules in both the ingress and egress table, because
     * the return traffic needs to be followed.
     *
     * 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
     * it to conntrack for tracking and defragmentation. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_ACL),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_ACL),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty())
}

/* Pre-LB */
for (&Switch(.ls = ls)) {
    /* Do not send ND packets to conntrack */
    var __match = "nd || nd_rs || nd_ra" in {
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, PRE_LB),
             .priority         = 110,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, PRE_LB),
             .priority         = 110,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = map_empty())
    };

    /* Do not send service monitor packets to conntrack. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_LB),
         .priority         = 110,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_LB),
         .priority         = 110,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Allow all packets to go to next tables by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_LB),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_LB),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

relation HasEventElbMeter(has_meter: bool)

HasEventElbMeter(true) :-
    nb.Meter(.name = "event-elb").

HasEventElbMeter(false) :-
    Unit(),
    not nb.Meter(.name = "event-elb").

/* Empty LoadBalancer Controller event */
function build_empty_lb_event_flow(key: string, lb: nb.Load_Balancer,
                                   meter: bool):
         Option<(string, string)> = {
    var __proto = if (lb.protocol == Some{"tcp"}) {
        "tcp"
    } else {
        "udp"
    };
    var __meter = if (meter) {
        "event-elb"
    } else {
        ""
    };
    var __action = "trigger_event(event = \"empty_lb_backends\", \
                    \meter = \"${__meter}\", protocol = \"${__proto}\", ";
    var __uuid = uuid2str(lb._uuid);
    var __match = "";

    match (ip_address_and_port_from_lb_key(key)) {
        Some{(ip_address_, port_, addr_family_)} -> {
            __action = __action ++ "load_balancer = \"${__uuid}\", \
                       \vip = \"${ip_address_}";
            if (addr_family_ == aF_INET()) {
                __match = "ip4.dst == ${ip_address_}"
            } else {
                __match = "ip6.dst == ${ip_address_}"
            };
            if (port_ != 0) {
                __action = __action ++ ":${port_}\");";
                __match = __match ++ " && ${__proto} && ${__proto}.dst == ${port_}"
            } else {
                __action = __action ++ "\");"
            }
            },
        None -> ()
    };
    Some{(__match, __action)}
}

/* ControllerEventEn has exactly one row, either 'true' to enable controller
 * events or 'false' to disable them. */
relation ControllerEventEn(enable: bool)
ControllerEventEn(map_get_bool_def(options, "controller_event", false)) :-
    nb.NB_Global(.options = options).
ControllerEventEn(false) :- Unit(), not nb.NB_Global().

Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, PRE_LB),
     .priority         = 130,
     .__match          = __match,
     .actions          = __action,
     .external_ids     = stage_hint(lb._uuid)) :-
    ControllerEventEn(true),
    SwitchLBVIP(.sw = &sw, .lb = &lb, .vip = vip, .backends = backends),
    backends == "",
    HasEventElbMeter(has_elb_meter),
    Some {(var __match, var __action)} = build_empty_lb_event_flow(
        vip, lb, has_elb_meter).

/* 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
 * packet to conntrack for defragmentation. */

function make_ip_dst_match(ip_address: string, addr_family: bit<32>): string = {
    if (addr_family == aF_INET()) {
        "ip4.dst == ${ip_address}"
    } else {
        "ip6.dst == ${ip_address}"
    }
}

for (SwitchLBVIP(.sw = &sw, .lb = lb, .vip = vip)) {
    /* Ignore L4 port information in the key because fragmented packets
     * may not have L4 information.  The pre-stateful table will send
     * the packet through ct() action to de-fragment. In stateful
     * table, we will eventually look at L4 information. */
    Some{(var ip_address, _, var addr_family)} = ip_address_and_port_from_lb_key(vip) in
    var ip_dst_match = make_ip_dst_match(ip_address, addr_family) in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, PRE_LB),
         .priority         = 100,
         .__match          = "ip && " ++ ip_dst_match,
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = stage_hint(lb._uuid))
}

for (SwitchHasLBVIP(&sw)) {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(OUT, PRE_LB),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty())
}

/* Pre-stateful */
for (&Switch(.ls = ls)) {
    /* Ingress and Egress pre-stateful Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_STATEFUL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_STATEFUL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_DEFRAG is set as 1, then the packets should be
     * sent to conntrack for tracking and defragmentation. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PRE_STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_DEFRAG()} == 1",
         .actions          = "ct_next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PRE_STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_DEFRAG()} == 1",
         .actions          = "ct_next;",
         .external_ids     = map_empty())
}

function build_acl_log(acl: nb.ACL): string =
{
    if (not acl.log) {
        ""
    } else {
        var strs: Vec<string> = vec_empty();
        match (acl.name) {
            None -> (),
            Some{name} -> vec_push(strs, "name=${json_string_escape(name)}")
        };
        /* If a severity level isn't specified, default to "info". */
        match (acl.severity) {
            None -> vec_push(strs, "severity=info"),
            Some{severity} -> vec_push(strs, "severity=${severity}")
        };
        match (acl.action) {
            "drop" -> {
                vec_push(strs, "verdict=drop")
            },
            "reject" -> {
                vec_push(strs, "verdict=reject")
            },
            "allow" -> {
                vec_push(strs, "verdict=allow")
            },
            "allow-related" -> {
                vec_push(strs, "verdict=allow")
            },
            _ -> ()
        };
        match (acl.meter) {
            None -> (),
            Some{meter} -> vec_push(strs, "meter=${json_string_escape(meter)}")
        };
        "log(${string_join(strs, \", \")}); "
    }
}

/* Due to various hard-coded priorities need to implement ACLs, the
 * northbound database supports a smaller range of ACL priorities than
 * are available to logical flows.  This value is added to an ACL
 * priority to determine the ACL's logical flow priority. */
function oVN_ACL_PRI_OFFSET(): integer = 1000

/* Intermediate relation that stores reject ACLs.
 * The following rules generate logical flows for these ACLs.
 */
relation Reject(lsuuid: uuid, pipeline: string, stage: Stage, acl: nb.ACL, extra_match: string, extra_actions: string)

/* build_reject_acl_rules() */
for (Reject(lsuuid, pipeline, stage, acl, extra_match_, extra_actions_)) {
    var extra_match = match (extra_match_) {
        "" -> "",
        s -> "(${s}) && "
    } in
    var extra_actions = match (extra_actions_) {
        "" -> "",
        s -> "${s} "
    } in
    var next = match (pipeline == "ingress") {
        true  -> "next(pipeline=egress,table=5)",
        false -> "next(pipeline=ingress,table=19)"
    } in
    var acl_log = build_acl_log(acl) in {
        /* TCP */
        var __match = extra_match ++ "ip4 && tcp && (${acl.__match})" in
        var actions = acl_log ++ "reg0 = 0; "
                      "eth.dst <-> eth.src; ip4.dst <-> ip4.src; "
                      "tcp_reset { outport <-> inport; ${next}; };" in
        Flow(.logical_datapath = lsuuid,
             .stage            = stage,
             .priority         = acl.priority + oVN_ACL_PRI_OFFSET() + 10,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(acl._uuid));

        var __match = extra_match ++ "ip6 && tcp && (${acl.__match})" in
        var actions = acl_log ++ "reg0 = 0; "
                      "eth.dst <-> eth.src; ip6.dst <-> ip6.src; "
                      "tcp_reset { outport <-> inport; ${next}; };" in
        Flow(.logical_datapath = lsuuid,
             .stage            = stage,
             .priority         = acl.priority + oVN_ACL_PRI_OFFSET() + 10,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(acl._uuid));

        /* IP traffic */
        var __match = extra_match ++ "ip4 && (${acl.__match})" in
        var actions = acl_log ++ extra_actions ++ 
                      "reg0 = 0; "
                      "icmp4 { "
                          "eth.dst <-> eth.src; "
                          "ip4.dst <-> ip4.src; "
                          "outport <-> inport; "
                          "${next}; "
                      "};" in
        Flow(.logical_datapath = lsuuid,
             .stage            = stage,
             .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(acl._uuid));

        var __match = extra_match ++ "ip6 && (${acl.__match})" in
        var actions = acl_log ++ extra_actions ++
                      "reg0 = 0; "
                      "icmp6 { "
                          "eth.dst <-> eth.src; "
                          "ip6.dst <-> ip6.src; "
                          "outport <-> inport; "
                          "${next}; "
                      "};" in
        Flow(.logical_datapath = lsuuid,
             .stage            = stage,
             .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(acl._uuid))
    }
}

/* build_acls */
for (&Switch(.ls = ls,
             .has_stateful_acl = has_stateful,
             .has_dns_records = has_dns_records)) {
    /* Ingress and Egress ACL Table (Priority 0): Packets are allowed by
     * default.  A related rule at priority 1 is added below if there
     * are any stateful ACLs in this datapath. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, ACL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, ACL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    if (has_stateful) {
        /* Ingress and Egress ACL Table (Priority 1).
         *
         * By default, traffic is allowed.  This is partially handled by
         * the Priority 0 ACL flows added earlier, but we also need to
         * commit IP flows.  This is because, while the initiater's
         * direction may not have any stateful rules, the server's may
         * and then its return traffic would not have an associated
         * conntrack entry and would return "+invalid".
         *
         * We use "ct_commit" for a connection that is not already known
         * by the connection tracker.  Once a connection is committed,
         * subsequent packets will hit the flow at priority 0 that just
         * uses "next;"
         *
         * We also check for established connections that have ct_label.blocked
         * set on them.  That's a connection that was disallowed, but is
         * now allowed by policy again since it hit this default-allow flow.
         * We need to set ct_label.blocked=0 to let the connection continue,
         * which will be done by ct_commit() in the "stateful" stage.
         * Subsequent packets will hit the flow at priority 0 that just
         * uses "next;". */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, ACL),
             .priority         = 1,
             .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
             .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 1,
             .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
             .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Always drop traffic that's in an invalid state.  Also drop
         * reply direction packets for connections that have been marked
         * for deletion (bit 0 of ct_label is set).
         *
         * This is enforced at a higher priority than ACLs can be defined. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, ACL),
             .priority         = 65535,
             .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
             .actions          = "drop;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 65535,
             .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
             .actions          = "drop;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Allow reply traffic that is part of an established
         * conntrack entry that has not been marked for deletion
         * (bit 0 of ct_label).  We only match traffic in the
         * reply direction because we want traffic in the request
         * direction to hit the currently defined policy from ACLs.
         *
         * This is enforced at a higher priority than ACLs can be defined. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, ACL),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv "
                                 "&& ct.rpl && ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv "
                                 "&& ct.rpl && ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Allow traffic that is related to an existing conntrack entry that
         * has not been marked for deletion (bit 0 of ct_label).
         *
         * This is enforced at a higher priority than ACLs can be defined.
         *
         * NOTE: This does not support related data sessions (eg,
         * a dynamically negotiated FTP data channel), but will allow
         * related traffic such as an ICMP Port Unreachable through
         * that's generated from a non-listening UDP port.  */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, ACL),
             .priority         = 65535,
             .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv "
                                 "&& ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 65535,
             .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv "
                                 "&& ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Not to do conntrack on ND packets. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, ACL),
             .priority         = 65535,
             .__match          = "nd",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 65535,
             .__match          = "nd",
             .actions          = "next;",
             .external_ids     = map_empty())
    };

    /* Add a 34000 priority flow to advance the DNS reply from ovn-controller,
     * if the CMS has configured DNS records for the datapath.
     */
    if (has_dns_records) {
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, ACL),
             .priority         = 34000,
             .__match          = "udp.src == 53",
             .actions          = if has_stateful "ct_commit; next;" else "next;",
             .external_ids     = map_empty())
    };

    /* Add a 34000 priority flow to advance the service monitor reply
     * packets to skip applying ingress ACLs. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, ACL),
         .priority         = 34000,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, ACL),
         .priority         = 34000,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Ingress or Egress ACL Table (Various priorities). */
for (&SwitchACL(.sw = &Switch{.ls = ls, .has_stateful_acl = has_stateful}, .acl = &acl)) {
    /* consider_acl */
    var ingress = acl.direction == "from-lport" in
    var stage = if ingress switch_stage(IN, ACL) else switch_stage(OUT, ACL) in
    var pipeline = if ingress "ingress" else "egress" in
    var stage_hint = stage_hint(acl._uuid) in
    if (acl.action == "allow" or acl.action == "allow-related") {
        /* If there are any stateful flows, we must even commit "allow"
         * actions.  This is because, while the initiater's
         * direction may not have any stateful rules, the server's
         * may and then its return traffic would not have an
         * associated conntrack entry and would return "+invalid". */
        if (not has_stateful) {
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = acl.__match,
                 .actions          = "${build_acl_log(acl)}next;",
                 .external_ids     = stage_hint)
        } else {
            /* Commit the connection tracking entry if it's a new
             * connection that matches this ACL.  After this commit,
             * the reply traffic is allowed by a flow we create at
             * priority 65535, defined earlier.
             *
             * It's also possible that a known connection was marked for
             * deletion after a policy was deleted, but the policy was
             * re-added while that connection is still known.  We catch
             * that case here and un-set ct_label.blocked (which will be done
             * by ct_commit in the "stateful" stage) to indicate that the
             * connection should be allowed to resume.
             */
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = "((ct.new && !ct.est) || (!ct.new && ct.est && !ct.rpl "
                                     "&& ct_label.blocked == 1)) && (${acl.__match})",
                 .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; ${build_acl_log(acl)}next;",
                 .external_ids     = stage_hint);

            /* Match on traffic in the request direction for an established
             * connection tracking entry that has not been marked for
             * deletion.  There is no need to commit here, so we can just
             * proceed to the next table. We use this to ensure that this
             * connection is still allowed by the currently defined
             * policy. Match untracked packets too. */
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = "(!ct.trk || (!ct.new && ct.est && !ct.rpl"
                                     " && ct_label.blocked == 0)) && (${acl.__match})",
                 .actions          = "${build_acl_log(acl)}next;",
                 .external_ids     = stage_hint)
        }
    } else if (acl.action == "drop" or acl.action == "reject") {
        /* The implementation of "drop" differs if stateful ACLs are in
         * use for this datapath.  In that case, the actions differ
         * depending on whether the connection was previously committed
         * to the connection tracker with ct_commit. */
        if (has_stateful) {
            /* If the packet is not tracked or not part of an established
             * connection, then we can simply reject/drop it. */
            var __match = "(!ct.trk || !ct.est"
                          " || (ct.est && ct_label.blocked == 1))" in
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, __match, "")
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = __match ++ " && (${acl.__match})",
                     .actions          = "${build_acl_log(acl)}/* drop */",
                     .external_ids     = stage_hint)
            };
            /* For an existing connection without ct_label set, we've
             * encountered a policy change. ACLs previously allowed
             * this connection and we committed the connection tracking
             * entry.  Current policy says that we should drop this
             * connection.  First, we set bit 0 of ct_label to indicate
             * that this connection is set for deletion.  By not
             * specifying "next;", we implicitly drop the packet after
             * updating conntrack state.  We would normally defer
             * ct_commit() to the "stateful" stage, but since we're
             * rejecting/dropping the packet, we go ahead and do it here.
             */
            var __match = "ct.est && ct_label.blocked == 0" in
            var actions = "ct_commit(ct_label=1/1); " in
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, __match, actions)
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = __match ++ " && (${acl.__match})",
                     .actions          = "${actions}${build_acl_log(acl)}/* drop */",
                     .external_ids     = stage_hint)
            }
        } else {
            /* There are no stateful ACLs in use on this datapath,
             * so a "reject/drop" ACL is simply the "reject/drop"
             * logical flow action in all cases. */
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, "", "")
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = acl.__match,
                     .actions          = "${build_acl_log(acl)}/* drop */",
                     .external_ids     = stage_hint)
            }
        }
    }
}

/* Add 34000 priority flow to allow DHCP reply from ovn-controller to all
 * logical ports of the datapath if the CMS has configured DHCPv4 options.
 * */
for (SwitchPortDHCPv4Options(.port = &SwitchPort{.lsp = lsp, .sw = &sw},
                             .dhcpv4_options = dhcpv4_options@&nb.DHCP_Options{.options = options})
     if lsp.__type != "external") {
    (Some{var server_id}, Some{var server_mac}, Some{var lease_time}) =
        (map_get(options, "server_id"), map_get(options, "server_mac"), map_get(options, "lease_time")) in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(OUT, ACL),
         .priority         = 34000,
         .__match          = "outport == ${json_string_escape(lsp.name)} "
                             "&& eth.src == ${server_mac} "
                             "&& ip4.src == ${server_id} && udp && udp.src == 67 "
                             "&& udp.dst == 68",
         .actions          = if (sw.has_stateful_acl) "ct_commit; next;" else "next;",
         .external_ids     = stage_hint(dhcpv4_options._uuid))
}

for (SwitchPortDHCPv6Options(.port = &SwitchPort{.lsp = lsp, .sw = &sw},
                             .dhcpv6_options = dhcpv6_options@&nb.DHCP_Options{.options=options} )
     if lsp.__type != "external") {
    Some{var server_mac} = map_get(options, "server_id") in
    Some{var ea} = eth_addr_from_string(server_mac) in
    var server_ip = ipv6_string_mapped(in6_generate_lla(ea)) in
    /* Get the link local IP of the DHCPv6 server from the
     * server MAC. */
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(OUT, ACL),
         .priority         = 34000,
         .__match          = "outport == ${json_string_escape(lsp.name)} "
                             "&& eth.src == ${server_mac} "
                             "&& ip6.src == ${server_ip} && udp && udp.src == 547 "
                             "&& udp.dst == 546",
         .actions          = if (sw.has_stateful_acl) "ct_commit; next;" else "next;",
         .external_ids     = stage_hint(dhcpv6_options._uuid))
}

relation QoSAction(qos: uuid, key_action: string, value_action: integer)

QoSAction(qos, k, v) :-
    nb.QoS(._uuid = qos, .action = actions),
    var action = FlatMap(actions),
    (var k, var v) = action.

/* QoS rules */
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, QOS_MARK),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, QOS_MARK),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, QOS_METER),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, QOS_METER),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

for (SwitchQoS(.sw = &sw, .qos = &qos)) {
    var ingress = if (qos.direction == "from-lport") true else false in
    var pipeline = if ingress "ingress" else "egress" in {
        var stage = if ingress switch_stage(IN, QOS_MARK) else switch_stage(OUT, QOS_MARK) in
        /* FIXME: Can value_action be negative? */
        for (QoSAction(qos._uuid, key_action, value_action)) {
            if (key_action == "dscp") {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = stage,
                     .priority         = qos.priority,
                     .__match          = qos.__match,
                     .actions          = "ip.dscp = ${value_action}; next;",
                     .external_ids     = stage_hint(qos._uuid))
            }
        };

        (var burst: bit<64>, var rate: bit<64>) = {
            var rate: bit<64> = 0;
            var burst: bit<64> = 0;
            for (bw in qos.bandwidth) {
                /* FIXME: Can value_bandwidth be negative? */
                (var key_bandwidth, var value_bandwidth) = bw;
                if (key_bandwidth == "rate") {
                    rate = value_bandwidth
                } else if (key_bandwidth == "burst") {
                    burst = value_bandwidth
                } else ()
            };
            (burst, rate)
        } in
        if (rate != 0) {
            var stage = if (ingress) switch_stage(IN, QOS_METER) else switch_stage(OUT, QOS_METER) in
            var meter_action = if (burst != 0) {
                    "set_meter(${rate}, ${burst}); next;"
                } else {
                    "set_meter(${rate}); next;"
                } in
            /* Ingress and Egress QoS Meter Table.
             *
             * We limit the bandwidth of this flow by adding a meter table.
             */
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = stage,
                 .priority         = qos.priority,
                 .__match          = qos.__match,
                 .actions          = meter_action,
                 .external_ids     = stage_hint(qos._uuid))
        }
    }
}

/* LB rules */
for (&Switch(.ls = ls)) {
    /* Ingress and Egress LB Table (Priority 0): Packets are allowed by
     * default.  */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, LB),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, LB),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    if (not set_is_empty(ls.load_balancer)) {
        /* Ingress and Egress LB Table (Priority 65535).
         *
         * Send established traffic through conntrack for just NAT. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(IN, LB),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv",
             .actions          = "${rEGBIT_CONNTRACK_NAT()} = 1; next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = switch_stage(OUT, LB),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv",
             .actions          = "${rEGBIT_CONNTRACK_NAT()} = 1; next;",
             .external_ids     = map_empty())
    }
}

/* stateful rules */
for (&Switch(.ls = ls)) {
    /* Ingress and Egress stateful Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, STATEFUL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, STATEFUL),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_COMMIT is set as 1, then the packets should be
     * committed to conntrack. We always set ct_label.blocked to 0 here as
     * any packet that makes it this far is part of a connection we
     * want to allow to continue. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_COMMIT()} == 1",
         .actions          = "ct_commit(ct_label=0/1); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_COMMIT()} == 1",
         .actions          = "ct_commit(ct_label=0/1); next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_NAT is set as 1, then packets should just be sent
     * through nat (without committing).
     *
     * REGBIT_CONNTRACK_COMMIT is set for new connections and
     * REGBIT_CONNTRACK_NAT is set for established connections. So they
     * don't overlap.
     */
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_NAT()} == 1",
         .actions          = "ct_lb;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, STATEFUL),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_NAT()} == 1",
         .actions          = "ct_lb;",
         .external_ids     = map_empty())
}

/* Load balancing rules for new connections get committed to conntrack
 * table.  So even if REGBIT_CONNTRACK_COMMIT is set in a previous table
 * a higher priority rule for load balancing below also commits the
 * connection, so it is okay if we do not hit the above match on
 * REGBIT_CONNTRACK_COMMIT. */
function get_match_for_lb_key(ip_address: string,
                              port: bit<16>,
                              addr_family: bit<32>,
                              protocol: Option<string>,
                              redundancy: bool): string = {
    var port_match = if (port != 0) {
        var proto = if (protocol == Some{"udp"}) {
            "udp"
        } else {
            "tcp"
        };
        if (redundancy) { " && ${proto}" } else { "" } ++
        " && ${proto}.dst == ${port}"
    } else {
        ""
    };

    var ipX = if (addr_family == aF_INET()) { "ip4" } else { "ip6" };
    var ip_match = "${ipX}.dst == ${ip_address}";

    if (redundancy) { "ip && " } else { "" } ++ ip_match ++ port_match
}
/* New connections in Ingress table. */
function ct_lb(backends: string, selection_fields: Set<string>): string {
    if (set_is_empty(selection_fields)) {
        "ct_lb(backends=${backends});"
    } else {
        "ct_lb(backends=${backends}; hash_fields=" ++
        json_string_escape(string_join(set2vec(selection_fields), ",")) ++
        ");"
    }
}
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, STATEFUL),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    sw in &Switch(),
    LBVIPBackend[lbvipbackend],
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(sw.ls.load_balancer, lb._uuid),
    bs in &LBVIPBackendStatus(.port = lbvipbackend.port,
                              .ip = lbvipbackend.ip,
                              .protocol = default_protocol(lb.protocol),
                              .logical_port = svc_monitor.port_name),
    var bses = Aggregate((sw, lbvip, lb), group2set(bs)),
    var __match = "ct.new && " ++ get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lbvip.addr_family, lb.protocol, false),
    var priority = if (lbvip.vip_port != 0) { 64'd120 } else { 64'd110 },
    var up_backends = {
        var up_backends: Set<string> = set_empty();
        for (bs in bses) {
            if (bs.up) {
                set_insert(up_backends, "${bs.ip}:${bs.port}")
            }
        };
        up_backends
    },
    var actions = if (set_is_empty(up_backends)) {
        "drop;"
    } else {
        ct_lb(string_join(set2vec(up_backends), ","), lb.selection_fields)
    }.
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, STATEFUL),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    sw in &Switch(),
    LBVIPBackend[lbvipbackend],
    None = lbvipbackend.svc_monitor,
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(sw.ls.load_balancer, lb._uuid),
    var __match = "ct.new && " ++ get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lbvip.addr_family, lb.protocol, false),
    var priority = if (lbvip.vip_port != 0) { 64'd120 } else { 64'd110 },
    var actions = ct_lb(lbvip.backend_ips, lb.selection_fields).

/* Also install flows that allow hairpinning of traffic (i.e., if
 * a load balancer VIP is DNAT-ed to a backend that happens to be
 * the source of the traffic).
 */

function get_hairpin_match(lbvipbackend: Ref<LBVIPBackend>,
                           l4_dir: string, l3_dst: Option<string>): string = {
    var lbvip = lbvipbackend.lbvip;
    var lb = lbvip.lb;
    var ipX = if (lbvip.addr_family == aF_INET()) {
        "ip4"
    } else {
        "ip6"
    };

    var __match: Vec<string> = vec_with_capacity(3);

    vec_push(__match, "${ipX}.src == ${lbvipbackend.ip}");

    match (l3_dst) {
        Some{s} -> vec_push(__match, "${ipX}.dst == ${s}"),
        _ -> ()
    };

    if (lbvip.vip_port != 0) {
        var proto = match (lb.protocol) {
            Some{value} -> value,
            None -> "tcp"
        };
        vec_push(__match, "${proto}.${l4_dir} == ${lbvipbackend.port}")
    };

    "(" ++ string_join(__match, " && ") ++ ")"
}

/* Ingress Pre-Hairpin table.
 * - Priority 2: SNAT load balanced traffic that needs to be hairpinned:
 *   - Both SRC and DST IP match backend->ip and destination port
 *     matches backend->port.
 * - Priority 1: unSNAT replies to hairpinned load balanced traffic.
 *   - SRC IP matches backend->ip, DST IP matches LB VIP and source port
 *     matches backend->port.
 */
/* Packets that after load balancing have equal source and
 * destination IPs should be hairpinned.
 */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, PRE_HAIRPIN),
     .priority         = 2,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    sw in &Switch(),
    LBVIPBackend[lbvipbackend],
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(sw.ls.load_balancer, lb._uuid),
    var __match = get_hairpin_match(lbvipbackend, "dst", Some{lbvipbackend.ip}),
    var matches = Aggregate((lbvip, lb, sw), group2vec(__match)),
    var __match = string_join(matches, " || "),
    var actions = "${rEGBIT_HAIRPIN()} = 1; ct_snat(${lbvip.vip_addr});".
/* If the packets are replies for hairpinned traffic, UNSNAT them. */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, PRE_HAIRPIN),
     .priority         = 1,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    sw in &Switch(),
    LBVIPBackend[lbvipbackend],
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(sw.ls.load_balancer, lb._uuid),
    var __match = get_hairpin_match(lbvipbackend, "src", None),
    var matches = Aggregate((lbvip, lb, sw), group2vec(__match)),
    var ipX = if (lbvip.addr_family == aF_INET()) { "ip4" } else { "ip6" },
    var __match = "(" ++ string_join(matches, " || ") ++ ") && "
                  "${ipX}.dst == ${lbvip.vip_addr}",
    var actions = "${rEGBIT_HAIRPIN()} = 1; ct_snat;".


/* Ingress Pre-Hairpin table (Priority 0). Packets that don't need
 * hairpinning should continue processing.
 */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, PRE_HAIRPIN),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    sw in &Switch().

/* Ingress Hairpin table.
 * - Priority 0: Packets that don't need hairpinning should continue
 *   processing.
 * - Priority 1: Packets that were SNAT-ed for hairpinning should be
 *   looped back (i.e., swap ETH addresses and send back on inport).
 */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, HAIRPIN),
     .priority         = 1,
     .__match          = "${rEGBIT_HAIRPIN()} == 1",
     .actions          = "eth.dst <-> eth.src;"
                         "outport = inport;"
                         "flags.loopback = 1;"
                         "output;",
     .external_ids     = map_empty()) :-
    sw in &Switch().
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, HAIRPIN),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    sw in &Switch().


/* Logical switch ingress table PORT_SEC_L2: ingress port security - L2 (priority 50)
                  ingress table PORT_SEC_IP: ingress port security - IP (priority 90 and 80)
                  ingress table PORT_SEC_ND: ingress port security - ND (priority 90 and 80) */
for (&SwitchPort(.lsp = lsp, .sw = &sw, .json_name = json_name, .ps_eth_addresses = ps_eth_addresses)
     if is_enabled(lsp.enabled) and lsp.__type != "external") {
     for (pbinding in sb.Out_Port_Binding(.logical_port = lsp.name)) {
        var __match = if (vec_is_empty(ps_eth_addresses)) {
                "inport == ${json_name}"
            } else {
                "inport == ${json_name} && eth.src == {${vec_space_sep(ps_eth_addresses)}}"
            } in
        var actions = match (map_get(pbinding.options, "qdisc_queue_id")) {
                None -> "next;",
                Some{id} -> "set_queue(${id}); next;"
            } in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, PORT_SEC_L2),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/**
* Build port security constraints on IPv4 and IPv6 src and dst fields
* and add logical flows to S_SWITCH_(IN/OUT)_PORT_SEC_IP stage.
*
* For each port security of the logical port, following
* logical flows are added
*   - If the port security has IPv4 addresses,
*     - Priority 90 flow to allow IPv4 packets for known IPv4 addresses
*
*   - If the port security has IPv6 addresses,
*     - Priority 90 flow to allow IPv6 packets for known IPv6 addresses
*
*   - If the port security has IPv4 addresses or IPv6 addresses or both
*     - Priority 80 flow to drop all IPv4 and IPv6 traffic
*/
for (SwitchPortPSAddresses(.port = &port@SwitchPort{.sw = &sw}, .ps_addrs = ps)
     if is_enabled(port.lsp.enabled) and
        (vec_len(ps.ipv4_addrs) > 64'd0 or vec_len(ps.ipv6_addrs) > 64'd0) and
        port.lsp.__type != "external")
{
    if (vec_len(ps.ipv4_addrs) > 64'd0) {
        var dhcp_match = "inport == ${port.json_name}"
                         " && eth.src == ${ps.ea_s}"
                         " && ip4.src == 0.0.0.0"
                         " && ip4.dst == 255.255.255.255"
                         " && udp.src == 68 && udp.dst == 67" in {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = switch_stage(IN, PORT_SEC_IP),
                 .priority         = 90,
                 .__match          = dhcp_match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        };
        var addrs = {
            var addrs: Vec<string> = vec_empty();
            for (addr in ps.ipv4_addrs) {
                /* When the netmask is applied, if the host portion is
                 * non-zero, the host can only use the specified
                 * address.  If zero, the host is allowed to use any
                 * address in the subnet.
                 */
                vec_push(addrs,
                         if (addr.plen == 32 or ((addr.addr & ~addr.mask) != 0)) {
                             addr.addr_s
                         } else {
                             /* host portion is zero */
                             "${addr.network_s}/${addr.plen}"
                         })
            };
            addrs
        } in
        var __match =
            "inport == ${port.json_name} && eth.src == ${ps.ea_s} && ip4.src == {" ++
            string_join(addrs, ", ") ++ "}" in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage         = switch_stage(IN, PORT_SEC_IP),
                 .priority         = 90,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        }
    };
    if (vec_len(ps.ipv6_addrs) > 64'd0) {
        var dad_match = "inport == ${port.json_name}"
                        " && eth.src == ${ps.ea_s}"
                        " && ip6.src == ::"
                        " && ip6.dst == ff02::/16"
                        " && icmp6.type == {131, 135, 143}" in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = switch_stage(IN, PORT_SEC_IP),
                 .priority         = 90,
                 .__match          = dad_match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        };
        var __match = "inport == ${port.json_name} && eth.src == ${ps.ea_s}" ++
                      build_port_security_ipv6_flow(IN, ps.ea, ps.ipv6_addrs) in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = switch_stage(IN, PORT_SEC_IP),
                 .priority         = 90,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        }
    };
    var __match = "inport == ${port.json_name} && eth.src == ${ps.ea_s} && ip" in
    {
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, PORT_SEC_IP),
             .priority         = 80,
             .__match          = __match,
             .actions          = "drop;",
             .external_ids     = stage_hint(port.lsp._uuid))
    }
}

/**
 * Build port security constraints on ARP and IPv6 ND fields
 * and add logical flows to S_SWITCH_IN_PORT_SEC_ND stage.
 *
 * For each port security of the logical port, following
 * logical flows are added
 *   - If the port security has no IP (both IPv4 and IPv6) or
 *     if it has IPv4 address(es)
 *      - Priority 90 flow to allow ARP packets for known MAC addresses
 *        in the eth.src and arp.spa fields. If the port security
 *        has IPv4 addresses, allow known IPv4 addresses in the arp.tpa field.
 *
 *   - If the port security has no IP (both IPv4 and IPv6) or
 *     if it has IPv6 address(es)
 *     - Priority 90 flow to allow IPv6 ND packets for known MAC addresses
 *       in the eth.src and nd.sll/nd.tll fields. If the port security
 *       has IPv6 addresses, allow known IPv6 addresses in the nd.target field
 *       for IPv6 Neighbor Advertisement packet.
 *
 *   - Priority 80 flow to drop ARP and IPv6 ND packets.
 */
for (SwitchPortPSAddresses(.port = &port@SwitchPort{.sw = &sw}, .ps_addrs = ps)
     if is_enabled(port.lsp.enabled) and port.lsp.__type != "external")
{
    var no_ip = vec_is_empty(ps.ipv4_addrs) and vec_is_empty(ps.ipv6_addrs) in
    {
        if (not vec_is_empty(ps.ipv4_addrs) or no_ip) {
            var __match: string = {
                var prefix = "inport == ${port.json_name} && eth.src == ${ps.ea_s} && arp.sha == ${ps.ea_s}";
                if (not vec_is_empty(ps.ipv4_addrs)) {
                    var spas: Vec<string> = vec_empty();
                    for (addr in ps.ipv4_addrs) {
                        /* When the netmask is applied, if the host portion is
                         * non-zero, the host can only use the specified
                         * address in the arp.spa.  If zero, the host is allowed
                         * to use any address in the subnet. */
                        if (addr.plen == 32 or (addr.addr & ~addr.mask) != 0) {
                            vec_push(spas, addr.addr_s)
                        } else {
                            vec_push(spas, "${addr.network_s}/${addr.plen}")
                        }
                    };
                    prefix ++ " && arp.spa == {${string_join(spas, \", \")}}"
                } else {
                    prefix
                }
            } in {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = switch_stage(IN, PORT_SEC_ND),
                     .priority         = 90,
                     .__match          = __match,
                     .actions          = "next;",
                     .external_ids     = stage_hint(port.lsp._uuid))
            }
        };
        if (not vec_is_empty(ps.ipv6_addrs) or no_ip) {
            var __match = "inport == ${port.json_name} && eth.src == ${ps.ea_s}" ++
                          build_port_security_ipv6_nd_flow(ps.ea, ps.ipv6_addrs) in
            {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = switch_stage(IN, PORT_SEC_ND),
                     .priority         = 90,
                     .__match          = __match,
                     .actions          = "next;",
                     .external_ids     = stage_hint(port.lsp._uuid))
            }
        };
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, PORT_SEC_ND),
             .priority         = 80,
             .__match          = "inport == ${port.json_name} && (arp || nd)",
             .actions          = "drop;",
             .external_ids     = stage_hint(port.lsp._uuid))
    }
}

/* Ingress table PORT_SEC_ND and PORT_SEC_IP: Port security - IP and ND, by
 * default goto next.  (priority 0)*/
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PORT_SEC_ND),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, PORT_SEC_IP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, skip requests coming from
 * localnet and vtep ports. (priority 100); see ovn-northd.8.xml for the
 * rationale. */
for (&SwitchPort(.lsp = lsp, .sw = &sw, .json_name = json_name)
     if is_enabled(lsp.enabled) and
        (lsp.__type == "localnet" or lsp.__type == "vtep"))
{
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, ARP_ND_RSP),
         .priority         = 100,
         .__match          = "inport == ${json_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

function lsp_is_up(lsp: nb.Logical_Switch_Port): bool = {
    lsp.up == Some{true}
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, reply for known IPs.
 * (priority 50). */
/* Handle
 *  - GARPs for virtual ip which belongs to a logical port
 *    of type 'virtual' and bind that port.
 *
 *  - ARP reply from the virtual ip which belongs to a logical
 *    port of type 'virtual' and bind that port.
 * */
 Flow(.logical_datapath = sp.sw.ls._uuid,
      .stage            = switch_stage(IN, ARP_ND_RSP),
      .priority         = 100,
      .__match          = "inport == ${vp.json_name} && "
                          "((arp.op == 1 && arp.spa == ${virtual_ip} && arp.tpa == ${virtual_ip}) || "
                          "(arp.op == 2 && arp.spa == ${virtual_ip}))",
      .actions          = "bind_vport(${sp.json_name}, inport); next;",
      .external_ids     = stage_hint(lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb.Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip} = map_get(lsp.options, "virtual-ip"),
    Some{var virtual_parents} = map_get(lsp.options, "virtual-parents"),
    Some{var ip} = ip_parse(virtual_ip),
    var vparent = FlatMap(string_split(virtual_parents, ",")),
    vp in &SwitchPort(.lsp = nb.Logical_Switch_Port{.name = vparent}),
    vp.sw == sp.sw.

/*
 * Add ARP/ND reply flows if either the
 *  - port is up and it doesn't have 'unknown' address defined or
 *  - port type is router or
 *  - port type is localport
 */
for (SwitchPortIPv4Address(.port = &SwitchPort{.lsp = lsp, .sw = &sw, .json_name = json_name},
                           .ea_s = ea_s, .addr = addr)
     if is_enabled(lsp.enabled) and
        (lsp_is_up(lsp) or lsp.__type == "router" or lsp.__type == "localport") and
        lsp.__type != "external" and lsp.__type != "virtual" and
        not set_contains(lsp.addresses, "unknown"))
{
    var __match = "arp.tpa == ${addr.addr_s} && arp.op == 1" in
    var actions = "eth.dst = eth.src; "
                  "eth.src = ${ea_s}; "
                  "arp.op = 2; /* ARP reply */ "
                  "arp.tha = arp.sha; "
                  "arp.sha = ${ea_s}; "
                  "arp.tpa = arp.spa; "
                  "arp.spa = ${addr.addr_s}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output;" in
    {
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, ARP_ND_RSP),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lsp._uuid));

        /* Do not reply to an ARP request from the port that owns the
         * address (otherwise a DHCP client that ARPs to check for a
         * duplicate address will fail).  Instead, forward it the usual
         * way.
         *
         * (Another alternative would be to simply drop the packet.  If
         * everything is working as it is configured, then this would
         * produce equivalent results, since no one should reply to the
         * request.  But ARPing for one's own IP address is intended to
         * detect situations where the network is not working as
         * configured, so dropping the request would frustrate that
         * intent.) */
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, ARP_ND_RSP),
             .priority         = 100,
             .__match          = __match ++ " && inport == ${json_name}",
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/* For ND solicitations, we need to listen for both the
 * unicast IPv6 address and its all-nodes multicast address,
 * but always respond with the unicast IPv6 address. */
for (SwitchPortIPv6Address(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                           .ea_s = ea_s, .addr = addr)
     if is_enabled(lsp.enabled) and
        (lsp_is_up(lsp) or lsp.__type == "router" or lsp.__type == "localport") and
        lsp.__type != "external" and lsp.__type != "virtual")
{
    var __match = "nd_ns && ip6.dst == {${addr.addr_s}, ${addr.sn_addr_s}} && nd.target == ${addr.addr_s}" in
    var actions = "${if (lsp.__type == \"router\") \"nd_na_router\" else \"nd_na\"} { "
                  "eth.src = ${ea_s}; "
                  "ip6.src = ${addr.addr_s}; "
                  "nd.target = ${addr.addr_s}; "
                  "nd.tll = ${ea_s}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output; "
                  "};" in
    {
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, ARP_ND_RSP),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lsp._uuid));

        /* Do not reply to a solicitation from the port that owns the
         * address (otherwise DAD detection will fail). */
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, ARP_ND_RSP),
             .priority         = 100,
             .__match          = __match ++ " && inport == ${json_name}",
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, by default goto next.
 * (priority 0)*/
for (ls in nb.Logical_Switch) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, ARP_ND_RSP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Ingress table ARP_ND_RSP: ARP/ND responder for service monitor source ip.
 * (priority 110)*/
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = switch_stage(IN, ARP_ND_RSP),
     .priority         = 110,
     .__match          = "arp.tpa == ${svc_mon_src_ip} && arp.op == 1",
     .actions          = "eth.dst = eth.src; "
                         "eth.src = ${svc_monitor_mac}; "
                         "arp.op = 2; /* ARP reply */ "
                         "arp.tha = arp.sha; "
                         "arp.sha = ${svc_monitor_mac}; "
                         "arp.tpa = arp.spa; "
                         "arp.spa = ${svc_mon_src_ip}; "
                         "outport = inport; "
                         "flags.loopback = 1; "
                         "output;",
     .external_ids     = stage_hint(lbvipbackend.lbvip.lb._uuid)) :-
    LBVIPBackend[lbvipbackend],
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    sp in &SwitchPort(
        .lsp = nb.Logical_Switch_Port{.name = svc_monitor.port_name}),
    var svc_mon_src_ip = svc_monitor.src_ip,
    SvcMonitorMac(svc_monitor_mac).

function build_dhcpv4_action(
    lsp_json_key: string,
    dhcpv4_options: nb.DHCP_Options,
    offer_ip: ovs_be32) : Option<(string, string, string)> =
{
    match (ip_parse_masked(dhcpv4_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            None
        },
        Right{(var host_ip, var mask)} -> {
            if (((offer_ip ^ host_ip) & mask) != 0) {
               /* the offer ip of the logical port doesn't belong to the cidr
                * defined in the DHCPv4 options.
                */
                None
            } else {
                match ((map_get(dhcpv4_options.options, "server_id"),
                        map_get(dhcpv4_options.options, "server_mac"),
                        map_get(dhcpv4_options.options, "lease_time")))
                {
                    (Some{var server_ip}, Some{var server_mac}, Some{var lease_time}) -> {
                        var options_map = dhcpv4_options.options;

                        /* server_mac is not DHCPv4 option, delete it from the smap. */
                        map_remove(options_map, "server_mac");
                        map_insert(options_map, "netmask", ip_fmt(mask));

                        /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                         * options on different architectures (big or little endian, SSE4.2) */
                        var options: Vec<string> = vec_empty();
                        for (node in options_map) {
                            (var k, var v) = node;
                            vec_push(options, "${k} = ${v}")
                        };
                        var options_action = "${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcp_opts(offerip = ${ip_fmt(offer_ip)}, " ++
                                             string_join(options, ", ") ++ "); next;";
                        var response_action = "eth.dst = eth.src; eth.src = ${server_mac}; "
                                              "ip4.src = ${server_ip}; udp.src = 67; "
                                              "udp.dst = 68; outport = inport; flags.loopback = 1; "
                                              "output;";

                        var ipv4_addr_match = "ip4.src == ${ip_fmt(offer_ip)} && ip4.dst == {${server_ip}, 255.255.255.255}";
                        Some{(options_action, response_action, ipv4_addr_match)}
                    },
                    _ -> {
                        /* "server_id", "server_mac" and "lease_time" should be
                         * present in the dhcp_options. */
                        //static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);
                        warn("Required DHCPv4 options not defined for lport - ${lsp_json_key}");
                        None
                    }
                }
            }
        }
    }
}

function build_dhcpv6_action(
    lsp_json_key: string,
    dhcpv6_options: nb.DHCP_Options,
    offer_ip: in6_addr): Option<(string, string)> =
{
    match (ipv6_parse_masked(dhcpv6_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            //warn("cidr is invalid - ${err}");
            None
        },
        Right{(var host_ip, var mask)} -> {
            var ip6_mask: in6_addr = ipv6_addr_bitxor(offer_ip, host_ip);
            ip6_mask = ipv6_addr_bitand(ip6_mask, mask);
            if (not ipv6_mask_is_any(ip6_mask)) {
                /* offer_ip doesn't belongs to the cidr defined in lport's DHCPv6
                 * options.*/
                //warn("ip does not belong to cidr");
                None
            } else {
                /* "server_id" should be the MAC address. */
                match (map_get(dhcpv6_options.options, "server_id")) {
                    None -> {
                        warn("server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                        None
                    },
                    Some{server_mac} -> {
                        match (eth_addr_from_string(server_mac)) {
                            None -> {
                                warn("server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                                None
                            },
                            Some{ea} -> {
                                /* Get the link local IP of the DHCPv6 server from the server MAC. */
                                var server_ip = ipv6_string_mapped(in6_generate_lla(ea));
                                var ia_addr = ipv6_string_mapped(offer_ip);
                                var options: Vec<string> = vec_empty();

                                /* Check whether the dhcpv6 options should be configured as stateful.
                                 * Only reply with ia_addr option for dhcpv6 stateful address mode. */
                                if (map_get_bool_def(dhcpv6_options.options, "dhcpv6_stateless", false) == false) {
                                    vec_push(options, "ia_addr = ${ia_addr}")
                                } else ();

                                /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                                 * options on different architectures (big or little endian, SSE4.2) */
                                // FIXME: enumerate map in ascending order of keys. Is this good enough?
                                for (node in dhcpv6_options.options) {
                                    (var k, var v) = node;
                                    if (k != "dhcpv6_stateless") {
                                        vec_push(options, "${k} = ${v}")
                                    } else ()
                                };

                                var options_action = "${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcpv6_opts(" ++
                                                     string_join(options, ", ")                         ++
                                                     "); next;";
                                var response_action = "eth.dst = eth.src; eth.src = ${server_mac}; "
                                                      "ip6.dst = ip6.src; ip6.src = ${server_ip}; udp.src = 547; "
                                                       "udp.dst = 546; outport = inport; flags.loopback = 1; "
                                                       "output;";
                                Some{(options_action, response_action)}
                            }
                        }
                    }
                }
            }
        }
    }
}

/*
 * Ordinarily, returns a match against 'lsp'.
 *
 * If 'lsp' is an external port, returns a match against the localnet port on
 * its switch along with a condition that it only operate if 'lsp' is
 * chassis-resident.  This makes sense as a condition for sending DHCP replies
 * to external ports because only one chassis should send such a reply.
 *
 * Returns a prefix and a suffix string.  There is no reason for this except
 * that it makes it possible to exactly mimic the format used by ovn-northd.c
 * so that text-based comparisons do not show differences.
 */
function match_dhcp_input(lsp: Ref<SwitchPort>): (string, string) =
{
    if (lsp.lsp.__type == "external") {
        match(lsp.sw.localnet_port_name) {
            Some{localnet_port_name} -> return (
                "inport == ${json_string_escape(localnet_port_name)} && ",
                " && is_chassis_resident(${lsp.json_name})"),
            None -> ()
        }
    } else ();
    ("inport == ${lsp.json_name} && ", "")
}

/* Logical switch ingress tables DHCP_OPTIONS and DHCP_RESPONSE: DHCP options
 * and response priority 100 flows. */
for (lsp in &SwitchPort
         /* Don't add the DHCP flows if the port is not enabled or if the
          * port is a router port. */
         if (is_enabled(lsp.lsp.enabled) and lsp.lsp.__type != "router")
         /* If it's an external port and there is no localnet port
          * and if it doesn't belong to an HA chassis group ignore it. */
         and (lsp.lsp.__type != "external"
              or (lsp.sw.has_localnet_port
                  and is_some(lsp.lsp.ha_chassis_group))))
{
    for (lps in LogicalSwitchPort(.lport = lsp.lsp._uuid, .lswitch = lsuuid)) {
        var json_key = json_string_escape(lsp.lsp.name) in
        (var pfx, var sfx) = match_dhcp_input(lsp) in
        {
            /* DHCPv4 options enabled for this port */
            Some{var dhcpv4_options_uuid} = lsp.lsp.dhcpv4_options in
            {
                for (dhcpv4_options in nb.DHCP_Options(._uuid = dhcpv4_options_uuid)) {
                    for (SwitchPortIPv4Address(.port = &SwitchPort{.lsp = nb.Logical_Switch_Port{._uuid = lsp.lsp._uuid}}, .ea_s = ea_s, .addr = addr)) {
                        Some{(var options_action, var response_action, var ipv4_addr_match)} =
                            build_dhcpv4_action(json_key, dhcpv4_options, addr.addr) in
                        {
                            var __match =
                                pfx ++ "eth.src == ${ea_s} && "
                                "ip4.src == 0.0.0.0 && ip4.dst == 255.255.255.255 && "
                                "udp.src == 68 && udp.dst == 67" ++ sfx
                            in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = switch_stage(IN, DHCP_OPTIONS),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = options_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid));

                            /* Allow ip4.src = OFFER_IP and
                             * ip4.dst = {SERVER_IP, 255.255.255.255} for the below
                             * cases
                             *  -  When the client wants to renew the IP by sending
                             *     the DHCPREQUEST to the server ip.
                             *  -  When the client wants to renew the IP by
                             *     broadcasting the DHCPREQUEST.
                             */
                            var __match = pfx ++ "eth.src == ${ea_s} && "
                                "${ipv4_addr_match} && udp.src == 68 && udp.dst == 67" ++ sfx in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = switch_stage(IN, DHCP_OPTIONS),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = options_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid));

                            /* If REGBIT_DHCP_OPTS_RESULT is set, it means the
                             * put_dhcp_opts action  is successful. */
                            var __match = pfx ++ "eth.src == ${ea_s} && "
                                "ip4 && udp.src == 68 && udp.dst == 67 && " ++
                                rEGBIT_DHCP_OPTS_RESULT() ++ sfx in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = switch_stage(IN, DHCP_RESPONSE),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = response_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid))
                            // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                            // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this break
                            // by computing an aggregate that returns the first element of a group.
                            //break;
                        }
                    }
                }
            };

            /* DHCPv6 options enabled for this port */
            Some{var dhcpv6_options_uuid} = lsp.lsp.dhcpv6_options in
            {
                for (dhcpv6_options in nb.DHCP_Options(._uuid = dhcpv6_options_uuid)) {
                    for (SwitchPortIPv6Address(.port = &SwitchPort{.lsp = nb.Logical_Switch_Port{._uuid = lsp.lsp._uuid}}, .ea_s = ea_s, .addr = addr)) {
                        Some{(var options_action, var response_action)} =
                            build_dhcpv6_action(json_key, dhcpv6_options, addr.addr) in
                        {
                            var __match = pfx ++ "eth.src == ${ea_s}"
                                " && ip6.dst == ff02::1:2 && udp.src == 546 &&"
                                " udp.dst == 547" ++ sfx in
                            {
                                Flow(.logical_datapath = lsuuid,
                                     .stage            = switch_stage(IN, DHCP_OPTIONS),
                                     .priority         = 100,
                                     .__match          = __match,
                                     .actions          = options_action,
                                     .external_ids     = stage_hint(lsp.lsp._uuid));

                                /* If REGBIT_DHCP_OPTS_RESULT is set to 1, it means the
                                 * put_dhcpv6_opts action is successful */
                                Flow(.logical_datapath = lsuuid,
                                     .stage            = switch_stage(IN, DHCP_RESPONSE),
                                     .priority         = 100,
                                     .__match          = __match ++ " && ${rEGBIT_DHCP_OPTS_RESULT()}",
                                     .actions          = response_action,
                                     .external_ids     = stage_hint(lsp.lsp._uuid))
                                // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                                // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this breaks
                                // by computing an aggregate that returns the first element of a group.
                                //break;
                            }
                        }
                    }
                }
            }
        }
    }
}

/* Logical switch ingress tables DNS_LOOKUP and DNS_RESPONSE: DNS lookup and
 * response priority 100 flows.
 */
for (LogicalSwitchHasDNSRecords(ls, true))
{
    Flow(.logical_datapath = ls,
         .stage            = switch_stage(IN, DNS_LOOKUP),
         .priority         = 100,
         .__match          = "udp.dst == 53",
         .actions          = "${rEGBIT_DNS_LOOKUP_RESULT()} = dns_lookup(); next;",
         .external_ids     = map_empty());

    var action = "eth.dst <-> eth.src; ip4.src <-> ip4.dst; "
                 "udp.dst = udp.src; udp.src = 53; outport = inport; "
                 "flags.loopback = 1; output;" in
    Flow(.logical_datapath = ls,
         .stage            = switch_stage(IN, DNS_RESPONSE),
         .priority         = 100,
         .__match          = "udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
         .actions          = action,
         .external_ids     = map_empty());

    var action = "eth.dst <-> eth.src; ip6.src <-> ip6.dst; "
                 "udp.dst = udp.src; udp.src = 53; outport = inport; "
                 "flags.loopback = 1; output;" in
    Flow(.logical_datapath = ls,
         .stage            = switch_stage(IN, DNS_RESPONSE),
         .priority         = 100,
         .__match          = "udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
         .actions          = action,
         .external_ids     = map_empty())
}

/* Ingress table DHCP_OPTIONS and DHCP_RESPONSE: DHCP options and response, by
 * default goto next. (priority 0).
 *
 * Ingress table DNS_LOOKUP and DNS_RESPONSE: DNS lookup and response, by
 * default goto next.  (priority 0).

 * Ingress table EXTERNAL_PORT - External port handling, by default goto next.
 * (priority 0). */
for (ls in nb.Logical_Switch) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, DHCP_OPTIONS),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, DHCP_RESPONSE),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, DNS_LOOKUP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, DNS_RESPONSE),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, EXTERNAL_PORT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

Flow(.logical_datapath = sw.ls._uuid,
     .stage = switch_stage(IN, L2_LKUP),
     .priority = 110,
     .__match = "eth.dst == $svc_monitor_mac",
     .actions = "handle_svc_check(inport);",
     .external_ids = map_empty()) :-
    sw in &Switch().

for (sw in &Switch(.ls = ls, .mcast_cfg = &mcast_cfg)
        if (mcast_cfg.enabled)) {
    for (SwitchMcastFloodRelayPorts(sw, relay_ports)) {
        for (SwitchMcastFloodReportPorts(sw, flood_report_ports)) {
            for (SwitchMcastFloodPorts(sw, flood_ports)) {
                var flood_relay = not set_is_empty(relay_ports) in
                var flood_reports = not set_is_empty(flood_report_ports) in
                var flood_static = not set_is_empty(flood_ports) in
                var igmp_act = {
                    if (flood_reports) {
                        var mrouter_static = json_string_escape(mC_MROUTER_STATIC().0);
                        "clone { "
                            "outport = ${mrouter_static}; "
                            "output; "
                        "};igmp;"
                    } else {
                        "igmp;"
                    }
                } in {
                    /* Punt IGMP traffic to controller. */
                    Flow(.logical_datapath = ls._uuid,
                         .stage            = switch_stage(IN, L2_LKUP),
                         .priority         = 100,
                         .__match          = "ip4 && ip.proto == 2",
                         .actions          = "${igmp_act}",
                         .external_ids     = map_empty());

                    /* Punt MLD traffic to controller. */
                    Flow(.logical_datapath = ls._uuid,
                         .stage            = switch_stage(IN, L2_LKUP),
                         .priority         = 100,
                         .__match          = "mldv1 || mldv2",
                         .actions          = "${igmp_act}",
                         .external_ids     = map_empty());

                    /* Flood all IP multicast traffic destined to 224.0.0.X to
                     * all ports - RFC 4541, section 2.1.2, item 2.
                     */
                    var flood = json_string_escape(mC_FLOOD().0) in
                    Flow(.logical_datapath = ls._uuid,
                         .stage            = switch_stage(IN, L2_LKUP),
                         .priority         = 85,
                         .__match          = "ip4.mcast && ip4.dst == 224.0.0.0/24",
                         .actions          = "outport = ${flood}; output;",
                         .external_ids     = map_empty());

                    /* Flood all IPv6 multicast traffic destined to reserved
                     * multicast IPs (RFC 4291, 2.7.1).
                     */
                    var flood = json_string_escape(mC_FLOOD().0) in
                    Flow(.logical_datapath = ls._uuid,
                         .stage            = switch_stage(IN, L2_LKUP),
                         .priority         = 85,
                         .__match          = "ip6.mcast_flood",
                         .actions          = "outport = ${flood}; output;",
                         .external_ids     = map_empty());

                    /* Forward uregistered IP multicast to routers with relay
                     * enabled and to any ports configured to flood IP
                     * multicast traffic. If configured to flood unregistered
                     * traffic this will be handled by the L2 multicast flow.
                     */
                    if (not mcast_cfg.flood_unreg) {
                        var relay_act = {
                            if (flood_relay) {
                                var rtr_flood = json_string_escape(mC_MROUTER_FLOOD().0);
                                "clone { "
                                    "outport = ${rtr_flood}; "
                                    "output; "
                                "}; "
                            } else {
                                ""
                            }
                        } in
                        var static_act = {
                            if (flood_static) {
                                var mc_static = json_string_escape(mC_STATIC().0);
                                "outport =${mc_static}; output;"
                            } else {
                                ""
                            }
                        } in
                        var drop_act = {
                            if (not flood_relay and not flood_static) {
                                "drop;"
                            } else {
                                ""
                            }
                        } in
                        Flow(.logical_datapath = ls._uuid,
                             .stage            = switch_stage(IN, L2_LKUP),
                             .priority         = 80,
                             .__match          = "ip4.mcast || ip6.mcast",
                             .actions          =
                                "${relay_act}${static_act}${drop_act}",
                             .external_ids     = map_empty())
                    }
                }
            }
        }
    }
}

/* Ingress table L2_LKUP: Add IP multicast flows learnt from IGMP/MLD (priority
 * 90). */
for (IgmpSwitchMulticastGroup(.address = address, .switch = &sw)) {
    /* RFC 4541, section 2.1.2, item 2: Skip groups in the 224.0.0.X
     * range.
     *
     * RFC 4291, section 2.7.1: Skip groups that correspond to all
     * hosts.
     */
    (var skip_address, var ipX) = match (ip46_parse(address)) {
        Some{IPv4{ipv4}} -> (ip_is_local_multicast(ipv4), "ip4"),
        Some{IPv6{ipv6}} -> (ipv6_is_all_hosts(ipv6), "ip6"),
        _ -> (true, "")
    } in
    for (SwitchMcastFloodRelayPorts(&sw, relay_ports) if not skip_address) {
        for (SwitchMcastFloodPorts(&sw, flood_ports)) {
            var flood_relay = not set_is_empty(relay_ports) in
            var flood_static = not set_is_empty(flood_ports) in
            var mc_rtr_flood = json_string_escape(mC_MROUTER_FLOOD().0) in
            var mc_static = json_string_escape(mC_STATIC().0) in
            var relay_act = {
                if (flood_relay) {
                    "clone { "
                        "outport = ${mc_rtr_flood}; output; "
                    "};"
                } else {
                    ""
                }
            } in
            var static_act = {
                if (flood_static) {
                    "clone { "
                        "outport =${mc_static}; "
                        "output; "
                    "};"
                } else {
                    ""
                }
            } in
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = switch_stage(IN, L2_LKUP),
                 .priority         = 90,
                 .__match          = "eth.mcast && ${ipX} && ${ipX}.dst == ${address}",
                 .actions          =
                    "${relay_act} ${static_act} outport = \"${address}\"; "
                    "output;",
                 .external_ids     = map_empty())
        }
    }
}

/* Table EXTERNAL_PORT: External port. Drop ARP request for router ips from
 * external ports on chassis not binding those ports.  This makes the router
 * pipeline to be run only on the chassis binding the external ports.
 *
 * For an external port X on logical switch LS, if X is not resident on this
 * chassis, drop ARP requests arriving on localnet ports from X's Ethernet
 * address, if the ARP request is asking to translate the IP address of a
 * router port on LS. */
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = switch_stage(IN, EXTERNAL_PORT),
     .priority         = 100,
     .__match          = ("inport == ${json_string_escape(localnet_port_name)} && "
                          "eth.src == ${lp_addr.ea_s} && "
                          "!is_chassis_resident(${sp.json_name}) && "
                          "arp.tpa == ${rp_addr.addr_s} && arp.op == 1"),
     .actions          = "drop;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    Some{var localnet_port_name} = sp.sw.localnet_port_name,
    var lp_addr = FlatMap(sp.static_addresses),
    rp in &SwitchPort(.sw = sp.sw),
    rp.lsp.__type == "router",
    SwitchPortIPv4Address(.port = rp, .addr = rp_addr).
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = switch_stage(IN, EXTERNAL_PORT),
     .priority         = 100,
     .__match          = ("inport == ${json_string_escape(localnet_port_name)} && "
                          "eth.src == ${lp_addr.ea_s} && "
                          "!is_chassis_resident(${sp.json_name}) && "
                          "nd_ns && ip6.dst == {${rp_addr.addr_s}, ${rp_addr.sn_addr_s}} && "
                          "nd.target == ${rp_addr.addr_s}"),
     .actions          = "drop;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    Some{var localnet_port_name} = sp.sw.localnet_port_name,
    var lp_addr = FlatMap(sp.static_addresses),
    rp in &SwitchPort(.sw = sp.sw),
    rp.lsp.__type == "router",
    SwitchPortIPv6Address(.port = rp, .addr = rp_addr).

/* Ingress table L2_LKUP: Destination lookup, broadcast and multicast handling
 * (priority 100). */
for (ls in nb.Logical_Switch) {
    var mc_flood = json_string_escape(mC_FLOOD().0) in
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(IN, L2_LKUP),
         .priority         = 70,
         .__match          = "eth.mcast",
         .actions          = "outport = ${mc_flood}; output;",
         .external_ids     = map_empty())
}

/* Ingress table L2_LKUP: Destination lookup, unicast handling (priority 50).
*/
for (SwitchPortStaticAddresses(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                               .addrs = addrs)
     if lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, L2_LKUP),
         .priority         = 50,
         .__match          = "eth.dst == ${addrs.ea}",
         .actions          = "outport = ${json_name}; output;",
         .external_ids     = stage_hint(lsp._uuid))
}

/*
 * Ingress table L2_LKUP: Flows that flood self originated ARP/ND packets in the
 * switching domain.
 */
 /* Self originated (G)ARP requests/ND need to be flooded as usual.
  * Determine that packets are self originated by also matching on
  * source MAC. Matching on ingress port is not reliable in case this
  * is a VLAN-backed network.
  * Priority: 80.
  */

Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, L2_LKUP),
     .priority         = 80,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.sw = sw, .peer = Some{rp}),
    is_enabled(rp.lrp.enabled),
    var eth_src_vec = {
        var eth_src_vec = vec_singleton(rp.networks.ea_s);
        for (nat in rp.router.nats) {
            match (nat.external_mac) {
                Some{mac} -> vec_push(eth_src_vec, mac),
                None -> ()
            }
        };
        eth_src_vec
    },
    var eth_src = "{ " ++ string_join(eth_src_vec, ", ") ++ "}",
    var __match = "eth.src == ${eth_src} && (arp.op == 1 || nd_ns)",
    var mc_flood = json_string_escape(mC_FLOOD().0),
    var actions = "outport = ${mc_flood}; output;".

/* Forward ARP requests for owned IP addresses (L3, VIP, NAT) only to this
 * router port.
 * Priority: 75.
 */
function get_arp_forward_ips(rp: Ref<RouterPort>): (Set<string>, Set<string>) = {
    (var all_ips_v4, var all_ips_v6)
        = get_router_load_balancer_ips(deref(rp.router));
    for (a in rp.networks.ipv4_addrs) {
        set_insert(all_ips_v4, a.addr_s)
    };
    for (a in rp.networks.ipv6_addrs) {
        set_insert(all_ips_v6, a.addr_s)
    };
    for (nat in rp.router.nats) {
        if (nat.__type != "snat") {
            match (ip_parse_masked(nat.external_ip)) {
                Left{_} -> set_insert(all_ips_v6, nat.external_ip),
                Right{_} -> set_insert(all_ips_v4, nat.external_ip)
            }
        }
    };
    (all_ips_v4, all_ips_v6)
}
/* Packets received from VXLAN tunnels have already been through the
 * router pipeline so we should skip them. Normally this is done by the
 * multicast_group implementation (VXLAN packets skip table 32 which
 * delivers to patch ports) but we're bypassing multicast_groups.
 */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, L2_LKUP),
     .priority         = 75,
     .__match          = fLAGBIT_NOT_VXLAN() ++
                         " && arp.op == 1 && arp.tpa == { " ++
                         string_join(set2vec(all_ips_v4), ", ") ++ "}",
     .actions          = match (sw.localnet_port_name) {
                             Some{name} -> "clone { outport = ${json_string_escape(name)}; output; }; ",
                             None -> ""
                         } ++ "outport = ${sp.json_name}; output;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.sw = sw, .peer = Some{rp}),
    is_enabled(rp.lrp.enabled),
    (var all_ips_v4, _) = get_arp_forward_ips(rp),
    not set_is_empty(all_ips_v4).
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(IN, L2_LKUP),
     .priority         = 75,
     .__match          = fLAGBIT_NOT_VXLAN() ++
                         " && nd_ns && nd.target == { " ++
                         string_join(set2vec(all_ips_v6), ", ") ++ "}",
     .actions          = match (sw.localnet_port_name) {
                             Some{name} -> "clone { outport = ${json_string_escape(name)}; output; }; ",
                             None -> ""
                         } ++ "outport = ${sp.json_name}; output;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.sw = sw, .peer = Some{rp}),
    is_enabled(rp.lrp.enabled),
    (_, var all_ips_v6) = get_arp_forward_ips(rp),
    not set_is_empty(all_ips_v6).

for (SwitchPortNewDynamicAddress(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                                 .address = Some{addrs})
     if lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(IN, L2_LKUP),
         .priority         = 50,
         .__match          = "eth.dst == ${addrs.ea}",
         .actions          = "outport = ${json_name}; output;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (&SwitchPort(.lsp = lsp,
                 .json_name = json_name,
                 .sw = &sw,
                 .peer = Some{&RouterPort{.lrp = lrp,
                                          .is_redirect = is_redirect,
                                          .router = &Router{.lr = lr,
                                                            .redirect_port_name = redirect_port_name}}})
     if (set_contains(lsp.addresses, "router") and lsp.__type != "external"))
{
    Some{var mac} = scan_eth_addr(lrp.mac) in {
        var add_chassis_resident_check =
            sw.has_localnet_port and
            (/* The peer of this port represents a distributed
              * gateway port. The destination lookup flow for the
              * router's distributed gateway port MAC address should
              * only be programmed on the "redirect-chassis". */
             is_redirect or
             /* Check if the option 'reside-on-redirect-chassis'
              * is set to true on the peer port. If set to true
              * and if the logical switch has a localnet port, it
              * means the router pipeline for the packets from
              * this logical switch should be run on the chassis
              * hosting the gateway port.
              */
              map_get_bool_def(lrp.options, "reside-on-redirect-chassis", false)) in
        var __match = if (add_chassis_resident_check) {
            /* The destination lookup flow for the router's
             * distributed gateway port MAC address should only be
             * programmed on the "redirect-chassis". */
            "eth.dst == ${mac} && is_chassis_resident(${redirect_port_name})"
        } else {
            "eth.dst == ${mac}"
        } in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(IN, L2_LKUP),
             .priority         = 50,
             .__match          = __match,
             .actions          = "outport = ${json_name}; output;",
             .external_ids     = stage_hint(lsp._uuid));

        /* Add ethernet addresses specified in NAT rules on
         * distributed logical routers. */
        if (is_redirect) {
            for (LogicalRouterNAT(.lr = lr._uuid, .nat = &nat)) {
                if (nat.__type == "dnat_and_snat") {
                    Some{var lport} = nat.logical_port in
                    Some{var emac} = nat.external_mac in
                    Some{var nat_mac} = eth_addr_from_string(emac) in
                    var __match = "eth.dst == ${nat_mac} && is_chassis_resident(${json_string_escape(lport)})" in
                    Flow(.logical_datapath = sw.ls._uuid,
                         .stage            = switch_stage(IN, L2_LKUP),
                         .priority         = 50,
                         .__match          = __match,
                         .actions          = "outport = ${json_name}; output;",
                         .external_ids     = stage_hint(nat._uuid))
                }
            }
        }
    }
}
// FIXME: do we care about this?
/*        } else {
            static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 1);

            VLOG_INFO_RL(&rl,
                         "%s: invalid syntax '%s' in addresses column",
                         op->nbsp->name, op->nbsp->addresses[i]);
        }*/

/* Ingress table L2_LKUP: Destination lookup for unknown MACs (priority 0). */
for (LogicalSwitchUnknownPorts(.ls = ls_uuid)) {
    var mc_unknown = json_string_escape(mC_UNKNOWN().0) in
    Flow(.logical_datapath = ls_uuid,
         .stage            = switch_stage(IN, L2_LKUP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "outport = ${mc_unknown}; output;",
         .external_ids     = map_empty())
}

/* Egress tables PORT_SEC_IP: Egress port security - IP (priority 0)
 * Egress table PORT_SEC_L2: Egress port security L2 - multicast/broadcast (priority 100). */
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PORT_SEC_IP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = switch_stage(OUT, PORT_SEC_L2),
         .priority         = 100,
         .__match          = "eth.mcast",
         .actions          = "output;",
         .external_ids     = map_empty())
}

/* Egress table PORT_SEC_IP: Egress port security - IP (priorities 90 and 80)
 * if port security enabled.
 *
 * Egress table PORT_SEC_L2: Egress port security - L2 (priorities 50 and 150).
 *
 * Priority 50 rules implement port security for enabled logical port.
 *
 * Priority 150 rules drop packets to disabled logical ports, so that they
 * don't even receive multicast or broadcast packets. */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = switch_stage(OUT, PORT_SEC_L2),
     .priority         = 50,
     .__match          = __match,
     .actions          = queue_action ++ "output;",
     .external_ids     = stage_hint(lsp._uuid)) :-
    &SwitchPort(.sw = &sw, .lsp = lsp, .json_name = json_name, .ps_eth_addresses = ps_eth_addresses),
    is_enabled(lsp.enabled),
    lsp.__type != "external",
    var __match = if (vec_is_empty(ps_eth_addresses)) {
            "outport == ${json_name}"
        } else {
            "outport == ${json_name} && eth.dst == {${vec_space_sep(ps_eth_addresses)}}"
        },
    pbinding in sb.Out_Port_Binding(.logical_port = lsp.name),
    var queue_action = match ((lsp.__type,
                               map_get(pbinding.options, "qdisc_queue_id"))) {
        ("localnet", Some{queue_id}) -> "set_queue(${queue_id});",
        _ -> ""
    }.

for (&SwitchPort(.lsp = lsp, .json_name = json_name, .sw = &sw)
     if not is_enabled(lsp.enabled) and lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(OUT, PORT_SEC_L2),
         .priority         = 150,
         .__match          = "outport == {$json_name}",
         .actions          = "drop;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (SwitchPortPSAddresses(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                           .ps_addrs = ps)
     if (vec_len(ps.ipv4_addrs) > 64'd0 or vec_len(ps.ipv6_addrs) > 64'd0)
         and lsp.__type != "external")
{
    if (vec_len(ps.ipv4_addrs) > 64'd0) {
        var addrs = {
            var addrs: Vec<string> = vec_empty();
            for (addr in ps.ipv4_addrs) {
                /* When the netmask is applied, if the host portion is
                 * non-zero, the host can only use the specified
                 * address.  If zero, the host is allowed to use any
                 * address in the subnet.
                 */
                vec_push(addrs,
                         if (addr.plen == 32 or ((addr.addr & ~addr.mask) != 0)) {
                             addr.addr_s ++
                                if (addr.plen != 32) { ", ${addr.bcast_s}" } else { "" }
                         } else {
                             /* host portion is zero */
                             "${addr.network_s}/${addr.plen}"
                         })
            };
            addrs
        } in
        var __match =
            "outport == ${json_name} && eth.dst == ${ps.ea_s} && ip4.dst == {255.255.255.255, 224.0.0.0/4, " ++
            string_join(addrs, ", ") ++ "}" in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(OUT, PORT_SEC_IP),
             .priority         = 90,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    };
    if (vec_len(ps.ipv6_addrs) > 64'd0) {
        var __match = "outport == ${json_name} && eth.dst == ${ps.ea_s}" ++
                      build_port_security_ipv6_flow(OUT, ps.ea, ps.ipv6_addrs) in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = switch_stage(OUT, PORT_SEC_IP),
             .priority         = 90,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    };
    var __match = "outport == ${json_name} && eth.dst == ${ps.ea_s} && ip" in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = switch_stage(OUT, PORT_SEC_IP),
         .priority         = 80,
         .__match          = __match,
         .actions          = "drop;",
         .external_ids     = stage_hint(lsp._uuid))
}

/* Logical router ingress table ADMISSION: Admission control framework. */
for (&Router(.lr = lr)) {
    /* Logical VLANs not supported.
     * Broadcast/multicast source address is invalid. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ADMISSION),
         .priority         = 100,
         .__match          = "vlan.present || eth.src[40]",
         .actions          = "drop;",
         .external_ids     = map_empty())
}

/* Logical router ingress table ADMISSION: match (priority 50). */
for (&RouterPort(.lrp = lrp,
                 .json_name = json_name,
                 .networks = lrp_networks,
                 .router = &router,
                 .is_redirect = is_redirect)
     /* Drop packets from disabled logical ports (since logical flow
      * tables are default-drop). */
     if is_enabled(lrp.enabled))
{
    //if (op->derived) {
    //    /* No ingress packets should be received on a chassisredirect
    //     * port. */
    //    continue;
    //}

    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, ADMISSION),
         .priority         = 50,
         .__match          = "eth.mcast && inport == ${json_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lrp._uuid));

    var __match =
        "eth.dst == ${lrp_networks.ea_s} && inport == ${json_name}" ++
        if is_redirect {
            /* Traffic with eth.dst = l3dgw_port->lrp_networks.ea_s
             * should only be received on the "redirect-chassis". */
            " && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
        } else { "" } in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, ADMISSION),
         .priority         = 50,
         .__match          = __match,
         .actions          = "next;",
         .external_ids     = stage_hint(lrp._uuid))
}


/* Logical router ingress table LOOKUP_NEIGHBOR and
 * table LEARN_NEIGHBOR. */
/* Learn MAC bindings from ARP/IPv6 ND.
 *
 * For ARP packets, table LOOKUP_NEIGHBOR does a lookup for the
 * (arp.spa, arp.sha) in the mac binding table using the 'lookup_arp'
 * action and stores the result in REGBIT_LOOKUP_NEIGHBOR_RESULT bit.
 *
 * For IPv6 ND NA packets, table LOOKUP_NEIGHBOR does a lookup
 * for the (nd.target, nd.tll) in the mac binding table using the
 * 'lookup_nd' action and stores the result in
 * REGBIT_LOOKUP_NEIGHBOR_RESULT bit.
 *
 * For IPv6 ND NS packets, table LOOKUP_NEIGHBOR does a lookup
 * for the (ip6.src, nd.sll) in the mac binding table using the
 * 'lookup_nd' action and stores the result in
 * REGBIT_LOOKUP_NEIGHBOR_RESULT bit.
 *
 * Table LEARN_NEIGHBOR learns the mac-binding using the action
 * - 'put_arp/put_nd' only if REGBIT_LOOKUP_NEIGHBOR_RESULT bit
 * is not set.
 *
 * */

/* Flows for LOOKUP_NEIGHBOR. */
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LOOKUP_NEIGHBOR),
     .priority         = 100,
     .__match          = "arp.op == 2",
     .actions          = rEGBIT_LOOKUP_NEIGHBOR_RESULT() ++ " = "
                         "lookup_arp(inport, arp.spa, arp.sha); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LOOKUP_NEIGHBOR),
     .priority         = 100,
     .__match          = "nd_na",
     .actions          = rEGBIT_LOOKUP_NEIGHBOR_RESULT() ++ " = "
                         "lookup_nd(inport, nd.target, nd.tll); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LOOKUP_NEIGHBOR),
     .priority         = 100,
     .__match          = "nd_ns",
     .actions          = rEGBIT_LOOKUP_NEIGHBOR_RESULT() ++ " = "
                         "lookup_nd(inport, ip6.src, nd.sll); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
/* For other packet types, we can skip neighbor learning.
 * So set REGBIT_SKIP_LOOKUP_NEIGHBOR to 1. */
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LOOKUP_NEIGHBOR),
     .priority         = 0,
     .__match          = "1",
     .actions          = rEGBIT_SKIP_LOOKUP_NEIGHBOR() ++ " = 1; next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).

/* Flows for LEARN_NEIGHBOR. */
/* Skip Neighbor learning if not required. */
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LEARN_NEIGHBOR),
     .priority         = 100,
     .__match          = rEGBIT_SKIP_LOOKUP_NEIGHBOR() ++ " == 1 || " ++
                         rEGBIT_LOOKUP_NEIGHBOR_RESULT() ++ " == 1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LEARN_NEIGHBOR),
     .priority         = 90,
     .__match          = "arp",
     .actions          = "put_arp(inport, arp.spa, arp.sha); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LEARN_NEIGHBOR),
     .priority         = 90,
     .__match          = "arp",
     .actions          = "put_arp(inport, arp.spa, arp.sha); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LEARN_NEIGHBOR),
     .priority         = 90,
     .__match          = "nd_na",
     .actions          = "put_nd(inport, nd.target, nd.tll); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LEARN_NEIGHBOR),
     .priority         = 90,
     .__match          = "nd_ns",
     .actions          = "put_nd(inport, ip6.src, nd.sll); next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).

/* Check if we need to learn mac-binding from ARP requests. */
Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, LOOKUP_NEIGHBOR),
     .priority         = 100,
     .__match          = __match,
     .actions          = rEGBIT_LOOKUP_NEIGHBOR_RESULT() ++ " = " ++
                         "lookup_arp(inport, arp.spa, arp.sha); next;",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    rp in &RouterPort(.networks = networks, .router = router),
    var address = FlatMap(networks.ipv4_addrs),
    var is_l3dgw_port = match (router.l3dgw_port) {
        Some{l3dgw_lrp} -> l3dgw_lrp._uuid == rp.lrp._uuid,
        None -> false
    },
    var has_redirect_port = router.redirect_port_name != "",
    var __match = "inport == ${rp.json_name} && " ++
                  "arp.spa == ${address.network_s}/${address.plen} && " ++
                  "arp.op == 1" ++
                  if (is_l3dgw_port and has_redirect_port) {
                      " && is_chassis_resident(${router.redirect_port_name})"
                  } else { "" }.

/* Logical router ingress table IP_INPUT: IP Input. */
for (&Router(.lr = lr, .mcast_cfg = &mcast_cfg)) {
    /* L3 admission control: drop multicast and broadcast source, localhost
     * source or destination, and zero network source or destination
     * (priority 100). */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 100,
         .__match          = "ip4.src_mcast ||"
         "ip4.src == 255.255.255.255 || "
         "ip4.src == 127.0.0.0/8 || "
         "ip4.dst == 127.0.0.0/8 || "
         "ip4.src == 0.0.0.0/8 || "
         "ip4.dst == 0.0.0.0/8",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* Priority-90 flows reply to ARP requests and ND packets. */

   /* Drop ARP packets (priority 85). ARP request packets for router's own
    * IPs are handled with priority-90 flows.
    * Drop IPv6 ND packets (priority 85). ND NA packets for router's own
    * IPs are handled with priority-90 flows.
    */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 85,
         .__match          = "arp || nd",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* Allow IPv6 multicast traffic that's supposed to reach the
     * router pipeline (e.g., router solicitations).
     */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 84,
         .__match          = "nd_rs || nd_ra",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Drop other reserved multicast. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 83,
         .__match          = "ip6.mcast_rsvd",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* Allow other multicast if relay enabled (priority 82). */
    var mcast_action = { if (mcast_cfg.relay) { "next;" } else { "drop;" } } in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 82,
         .__match          = "ip4.mcast || ip6.mcast",
         .actions          = mcast_action,
         .external_ids     = map_empty());

    /* Drop Ethernet local broadcast.  By definition this traffic should
     * not be forwarded.*/
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 50,
         .__match          = "eth.bcast",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* TTL discard */
    Flow(
        .logical_datapath = lr._uuid,
        .stage            = router_stage(IN, IP_INPUT),
        .priority         = 30,
        .__match          = "ip4 && ip.ttl == {0, 1}",
        .actions          = "drop;",
        .external_ids     = map_empty());

    /* Pass other traffic not already handled to the next table for
     * routing. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function format_v4_networks(networks: lport_addresses, add_bcast: bool): string =
{
    var addrs: Vec<string> = vec_empty();
    for (addr in networks.ipv4_addrs) {
        vec_push(addrs, addr.addr_s);
        if (add_bcast) {
            vec_push(addrs, addr.bcast_s)
        } else ()
    };
    if (vec_len(addrs) == 64'd1) {
        string_join(addrs , ", ")
    } else {
        "{" ++ string_join(addrs , ", ") ++ "}"
    }
}

function format_v6_networks(networks: lport_addresses): string =
{
    var addrs: Vec<string> = vec_empty();
    for (addr in networks.ipv6_addrs) {
        vec_push(addrs, addr.addr_s)
    };
    if (vec_len(addrs) == 64'd1) {
        string_join(addrs , ", ")
    } else {
        "{" ++ string_join(addrs , ", ") ++ "}"
    }
}

/* The following relation is used in ARP reply flow generation to determine whether
 * the is_chassis_resident check must be added to the flow.
 */
relation AddChassisResidentCheck_(lrp: uuid, add_check: bool)

AddChassisResidentCheck_(lrp._uuid, res) :-
    &SwitchPort(.peer = Some{&RouterPort{.lrp = lrp, .router = &router, .is_redirect = is_redirect}},
                .sw = &Switch{.has_localnet_port = true}),
    is_some(router.l3dgw_port),
    var res = if (is_redirect) {
        /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
         * should only be sent from the "redirect-chassis", so that
         * upstream MAC learning points to the "redirect-chassis".
         * Also need to avoid generation of multiple ARP responses
         * from different chassis. */
        true
    } else {
        /* Check if the option 'reside-on-redirect-chassis'
         * is set to true on the router port. If set to true
         * and if peer's logical switch has a localnet port, it
         * means the router pipeline for the packets from
         * peer's logical switch is be run on the chassis
         * hosting the gateway port and it should reply to the
         * ARP requests for the router port IPs.
         */
        map_get_bool_def(lrp.options, "reside-on-redirect-chassis", false)
    }.


relation AddChassisResidentCheck(lrp: uuid, add_check: bool)

AddChassisResidentCheck(lrp, add_check) :-
    AddChassisResidentCheck_(lrp, add_check).

AddChassisResidentCheck(lrp, false) :-
    nb.Logical_Router_Port(._uuid = lrp),
    not AddChassisResidentCheck_(lrp, _).


function get_force_snat_ip(lr: nb.Logical_Router, key_type: string): Option<(string, v46_ip)> =
{
    match (map_get(lr.options, key_type ++ "_force_snat_ip")) {
        None -> None,
        Some{s} -> {
            match (ip46_parse(s)) {
                Some{ip} -> Some{(s, ip)},
                None -> None
            }
        }
    }
}

/* Logical router ingress table IP_INPUT: IP Input for IPv4. */
for (&RouterPort(.router = &router, .networks = networks, .lrp = lrp)
     if (not vec_is_empty(networks.ipv4_addrs)))
{
    /* L3 admission control: drop packets that originate from an
     * IPv4 address owned by the router or a broadcast address
     * known to the router (priority 100). */
    var __match = "ip4.src == "                                  ++
                   format_v4_networks(networks, true)            ++
                   " && ${rEGBIT_EGRESS_LOOPBACK()} == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 100,
         .__match          = __match,
         .actions          = "drop;",
         .external_ids     = stage_hint(lrp._uuid));

    /* ICMP echo reply.  These flows reply to ICMP echo requests
     * received for the router's IP address. Since packets only
     * get here as part of the logical router datapath, the inport
     * (i.e. the incoming locally attached net) does not matter.
     * The ip.ttl also does not matter (RFC1812 section 4.2.2.9) */
    var __match = "ip4.dst == "                                  ++
                  format_v4_networks(networks, false)            ++
                  " && icmp4.type == 8 && icmp4.code == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 90,
         .__match          = __match,
         .actions          = "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 0; "
                             "flags.loopback = 1; "
                             "next; ",
         .external_ids     = stage_hint(lrp._uuid))
}

/* ICMP time exceeded */
for (RouterPortNetworksIPv4Addr(.port = &RouterPort{.lrp = lrp,
                                                    .json_name = json_name,
                                                    .router = &router,
                                                    .networks = networks,
                                                    .is_redirect = is_redirect},
                                .addr = addr))
{
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 40,
         .__match          = "inport == ${json_name} && ip4 && "
                             "ip.ttl == {0, 1} && !ip.later_frag",
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "icmp4.type = 11; /* Time exceeded */ "
                             "icmp4.code = 0; /* TTL exceeded in transit */ "
                             "ip4.dst = ip4.src; "
                             "ip4.src = ${addr.addr_s}; "
                             "ip.ttl = 255; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    /* ARP reply.  These flows reply to ARP requests for the router's own
     * IP address. */
    for (AddChassisResidentCheck(lrp._uuid, add_chassis_resident_check)) {
        var __match =
            "inport == ${json_name} && arp.spa == ${addr.network_s}/${addr.plen} "
            "&& arp.tpa == ${addr.addr_s}"
            " && arp.op == 1" ++
            if (add_chassis_resident_check) {
                " && is_chassis_resident(${router.redirect_port_name})"
            } else "" in
        var actions =
            "eth.dst = eth.src; "
            "eth.src = ${networks.ea_s}; "
            "arp.op = 2; /* ARP reply */ "
            "arp.tha = arp.sha; "
            "arp.sha = ${networks.ea_s}; "
            "arp.tpa = arp.spa; "
            "arp.spa = ${addr.addr_s}; "
            "outport = ${json_name}; "
            "flags.loopback = 1; "
            "output;" in
        Flow(.logical_datapath = router.lr._uuid,
             .stage            = router_stage(IN, IP_INPUT),
             .priority         = 90,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lrp._uuid))
    }
}

for (&RouterPort(.lrp = lrp,
                 .router = router@&Router{.lr = lr},
                 .json_name = json_name,
                 .networks = networks,
                 .is_redirect = is_redirect))
{
    for (RouterLBVIP(.router = &Router{.lr = nb.Logical_Router{._uuid= lr._uuid}}, .vip = vip)) {
        Some{(var ip_address, _, var addr_family)} = ip_address_and_port_from_lb_key(vip) in
        var __match = if (addr_family == aF_INET()) {
               "inport == ${json_name} && arp.tpa == ${ip_address} && arp.op == 1"
            } else {
               "inport == ${json_name} && nd_ns && nd.target == ${ip_address}"
            } ++
            if (is_redirect) {
                " && is_chassis_resident(${router.redirect_port_name})"
            } else {
                ""
            } in
        var actions = if (addr_family == aF_INET()) {
            "eth.dst = eth.src; "
            "eth.src = ${networks.ea_s}; "
            "arp.op = 2; /* ARP reply */ "
            "arp.tha = arp.sha; "
            "arp.sha = ${networks.ea_s}; "
            "arp.tpa = arp.spa; "
            "arp.spa = ${ip_address}; "
            "outport = ${json_name}; "
            "flags.loopback = 1; "
            "output;"
        } else {
            "nd_na { "
            "eth.src = ${networks.ea_s}; "
            "ip6.src = ${ip_address}; "
            "nd.target = ${ip_address}; "
            "nd.tll = ${networks.ea_s}; "
            "outport = inport; "
            "flags.loopback = 1; "
            "output; "
            "};"
        } in
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, IP_INPUT),
             .priority         = 90,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lrp._uuid))
    };

    for (LogicalRouterNAT(lr._uuid, &nat) if nat.__type != "snat") {
        Some{var ip} = match (ip46_parse(nat.external_ip)) {
            Some{ip} -> { Some{ip} },
            None -> {
                warn("bad ip address ${nat.external_ip} in nat configuration "
                     "for router ${uuid2str(lr._uuid)}");
                None: Option<v46_ip>
            }
        } in
        /* ARP / ND handling for external IP addresses.
         *
         * DNAT IP addresses are external IP addresses that need ARP
         * handling. */
        var __match = "inport == ${json_name} && " ++ match (ip) {
            IPv4{ipv4} -> "arp.tpa == ${nat.external_ip} && arp.op == 1",
            IPv6{ipv6} -> {
                var sn_addr = in6_addr_solicited_node(ipv6);
                "nd_ns && ip6.dst == {${ipv6}, ${sn_addr}} && nd.target == ${ipv6}"
            }
        } in
        (var actions, var actions4) = match (ip) {
            IPv4{_} -> ("arp.op = 2; /* ARP reply */ arp.tha = arp.sha; ",
                        ""),
            IPv6{_} -> ("nd_na { ",
                        " };")
        } in
        var arp_sha = match (ip) {
            IPv4{_} -> "arp.sha",
            IPv6{_} -> "nd.tll"
        } in
        (var __match2, var actions2) = if is_redirect {
            match ((nat.external_mac, nat.logical_port)) {
                (Some{external_mac}, Some{logical_port}) -> {
                    match (eth_addr_from_string(external_mac)) {
                        Some{mac} -> {
                            /* distributed NAT case, use nat->external_mac */
                            /* Traffic with eth.src = nat->external_mac should only be
                             * sent from the chassis where nat->logical_port is
                             * resident, so that upstream MAC learning points to the
                             * correct chassis.  Also need to avoid generation of
                             * multiple ARP responses from different chassis. */
                            (" && is_chassis_resident(${json_string_escape(logical_port)})",
                             "eth.src = ${mac}; ${arp_sha} = ${mac}; ")
                        },
                        None -> {
                            ( " && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
                            , "eth.src = ${networks.ea_s}; ${arp_sha} = ${networks.ea_s}; ")
                        }
                    }
                },
                _ -> {
                    /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
                     * should only be sent from the "redirect-chassis", so that
                     * upstream MAC learning points to the "redirect-chassis".
                     * Also need to avoid generation of multiple ARP responses
                     * from different chassis. */
                    ( " && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
                    , "eth.src = ${networks.ea_s}; ${arp_sha} = ${networks.ea_s}; ")
                }
            }
        } else {
            ( ""
            , "eth.src = ${networks.ea_s}; ${arp_sha} = ${networks.ea_s}; ")
        } in
        var actions3 = match (ip) {
            IPv4{ipv4} -> "arp.tpa = arp.spa; "
                          "arp.spa = ${ip_fmt(ipv4)}; ",
            IPv6{ipv6} -> "ip6.src = ${ipv6}; "
                          "nd.target = ${ipv6}; "
        } in
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, IP_INPUT),
             .priority         = 90,
             .__match          = __match ++ __match2,
             .actions          = "eth.dst = eth.src; " ++
                                 actions ++ actions2 ++ actions3 ++
                                 "outport = ${json_name}; "
                                 "flags.loopback = 1; "
                                 "output;" ++
                                 actions4,
             .external_ids     = stage_hint(nat._uuid))
    }
}

for (RouterPortNetworksIPv4Addr(
        .port = &RouterPort{
            .router = &Router{.lr = lr,
                              .l3dgw_port = None,
                              .is_gateway = false},
            .lrp = lrp},
         .addr = addr))
{
    /* UDP/TCP port unreachable. */
    var __match = "ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag && udp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 80,
         .__match          = __match,
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 3; "
                             "icmp4.code = 3; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag && tcp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 80,
         .__match          = __match,
         .actions          = "tcp_reset {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 70,
         .__match          = __match,
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 3; "
                             "icmp4.code = 2; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid))
}


for (&RouterPort(.lrp = lrp,
                 .router = &Router{.lr = lr, .nats = nats},
                 .json_name = json_name,
                 .networks = networks))
{
    /* A gateway router can have 2 SNAT IP addresses to force DNATed and
     * LBed traffic respectively to be SNATed.  In addition, there can be
     * a number of SNAT rules in the NAT table. */
    var snat_ips: Set<v46_ip> = {
        var snat_ips: Set<v46_ip> = set_empty();
        for (nat in nats) {
            if (deref(nat).__type == "snat") {
                var ip = deref(nat).external_ip;
                match (ip46_parse(ip)) {
                    Some{snat_ip} -> set_insert(snat_ips, snat_ip),
                    None -> warn("bad ip address ${ip} in nat configuration "
                                 "for router ${uuid2str(lr._uuid)}")
                }
            } else ()
        };
        match (get_force_snat_ip(lr, "dnat")) {
            Some{(_, snat_ip)} -> set_insert(snat_ips, snat_ip),
            None -> ()
        };
        match (get_force_snat_ip(lr, "lb")) {
            Some{(_, snat_ip)} -> set_insert(snat_ips, snat_ip),
            None -> ()
        };
        snat_ips
    } in
    var ip4s = {
        var ip4s: Vec<string> = vec_empty();
        for (ip in networks.ipv4_addrs) {
            /* Packets to SNAT IPs should not be dropped. */
            if (not set_contains(snat_ips, IPv4{ip.addr})) {
                vec_push(ip4s, ip.addr_s)
            }
        };
        if (not vec_is_empty(ip4s)) {
            set_singleton("ip4.dst == {" ++ string_join(ip4s, ", ") ++ "}")
        } else {
            set_empty(): Set<string>
        }
    } in
    var ip6s = {
        var ip6s: Vec<string> = vec_empty();
        for (ip in networks.ipv6_addrs) {
            /* Packets to SNAT IPs should not be dropped. */
            if (not set_contains(snat_ips, IPv6{ip.addr})) {
                vec_push(ip6s, ip.addr_s)
            }
        };
        if (not vec_is_empty(ip6s)) {
            set_singleton("ip6.dst == {" ++ string_join(ip6s, ", ") ++ "}")
        } else {
            set_empty(): Set<string>
        }
    } in
    var ips = set_union(ip4s, ip6s) in
    if (not set_is_empty(ips)) {
        /* Drop IP traffic to this router. */
        var __match = string_join(set2vec(ips), " || ") in
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, IP_INPUT),
             .priority         = 60,
             .__match          = __match,
             .actions          = "drop;",
             .external_ids     = stage_hint(lrp._uuid))
    }
}

/* DHCPv6 reply handling */
Flow(.logical_datapath = rp.router.lr._uuid,
     .stage            = router_stage(IN, IP_INPUT),
     .priority         = 100,
     .__match          = "ip6.dst == ${ipv6_addr.addr_s} "
                         "&& udp.src == 547 && udp.dst == 546",
     .actions          = "reg0 = 0; handle_dhcpv6_reply;",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    rp in &RouterPort(),
    var ipv6_addr = FlatMap(rp.networks.ipv6_addrs).

/* Logical router ingress table IP_INPUT: IP Input for IPv6. */
for (&RouterPort(.router = &router, .networks = networks, .lrp = lrp)
     if (not vec_is_empty(networks.ipv6_addrs)))
{
    //if (op->derived) {
    //    /* No ingress packets are accepted on a chassisredirect
    //     * port, so no need to program flows for that port. */
    //    continue;
    //}

    /* ICMPv6 echo reply.  These flows reply to echo requests
     * received for the router's IP address. */
    var __match = "ip6.dst == "                   ++
                  format_v6_networks(networks)    ++
                  " && icmp6.type == 128 && icmp6.code == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 90,
         .__match          = __match,
         .actions          = "ip6.dst <-> ip6.src; "
         "ip.ttl = 255; "
         "icmp6.type = 129; "
         "flags.loopback = 1; "
         "next; ",
         .external_ids     = stage_hint(lrp._uuid))
}

/* ND reply.  These flows reply to ND solicitations for the
 * router's own IP address. */
for (RouterPortNetworksIPv6Addr(.port = &RouterPort{.lrp = lrp,
                                                    .is_redirect = is_redirect,
                                                    .router = &router,
                                                    .networks = networks,
                                                    .json_name = json_name},
                                .addr = addr))
{
    var __match =
        "inport == ${json_name} && nd_ns && ip6.dst == {${addr.addr_s}, ${addr.sn_addr_s}} "
        "&& nd.target == ${addr.addr_s}" ++
        if (is_redirect) {
            /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
             * should only be sent from the "redirect-chassis", so that
             * upstream MAC learning points to the "redirect-chassis".
             * Also need to avoid generation of multiple ND replies
             * from different chassis. */
            " && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
        } else { "" } in
    var actions = "nd_na_router { "
                  "eth.src = ${networks.ea_s}; "
                  "ip6.src = ${addr.addr_s}; "
                  "nd.target = ${addr.addr_s}; "
                  "nd.tll = ${networks.ea_s}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output; "
                  "};" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 90,
         .__match          = __match,
         .actions          = actions,
         .external_ids     = stage_hint(lrp._uuid))
}

/* UDP/TCP port unreachable */
for (RouterPortNetworksIPv6Addr(
        .port = &RouterPort{.router = &Router{.lr = lr,
                                              .l3dgw_port = None,
                                              .is_gateway = false},
                            .lrp = lrp,
                            .json_name = json_name},
        .addr = addr))
{
    var __match = "ip6 && ip6.dst == ${addr.addr_s} && !ip.later_frag && tcp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 80,
         .__match          = __match,
         .actions          = "tcp_reset {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip6 && ip6.dst == ${addr.addr_s} && !ip.later_frag && udp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 80,
         .__match          = __match,
         .actions          = "icmp6 {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "ip.ttl = 255; "
                             "icmp6.type = 1; "
                             "icmp6.code = 4; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip6 && ip6.dst == ${addr.addr_s} && !ip.later_frag" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 70,
         .__match          = __match,
         .actions          = "icmp6 {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "ip.ttl = 255; "
                             "icmp6.type = 1; "
                             "icmp6.code = 3; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid))
}

/* ICMPv6 time exceeded */
for (RouterPortNetworksIPv6Addr(.port = &RouterPort{.router = &router,
                                                    .lrp = lrp,
                                                    .json_name = json_name},
                                .addr = addr)
     /* skip link-local address */
     if (not in6_is_lla(addr.network)))
{
    var __match = "inport == ${json_name} && ip6 && "
                  "ip6.src == ${addr.network_s}/${addr.plen} && "
                  "ip.ttl == {0, 1} && !ip.later_frag" in
    var actions = "icmp6 {"
                  "eth.dst <-> eth.src; "
                  "ip6.dst = ip6.src; "
                  "ip6.src = ${addr.addr_s}; "
                  "ip.ttl = 255; "
                  "icmp6.type = 3; /* Time exceeded */ "
                  "icmp6.code = 0; /* TTL exceeded in transit */ "
                  "next; };" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = router_stage(IN, IP_INPUT),
         .priority         = 40,
         .__match          = __match,
         .actions          = actions,
         .external_ids     = stage_hint(lrp._uuid))
}

/* NAT, Defrag and load balancing. */

for (&Router(.lr = lr)) {
    /* Packets are allowed by default. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, DEFRAG),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, UNSNAT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(OUT, SNAT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, DNAT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(OUT, UNDNAT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(OUT, EGR_LOOP),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Send the IPv6 NS packets to next table. When ovn-controller
     * generates IPv6 NS (for the action - nd_ns{}), the injected
     * packet would go through conntrack - which is not required. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(OUT, SNAT),
         .priority         = 120,
         .__match          = "nd_ns",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function lrouter_nat_is_stateless(nat: nb.NAT): bool = {
    Some{"true"} == map_get(nat.options, "stateless")
}


/* NAT rules are only valid on Gateway routers and routers with
 * l3dgw_port (router has a port with "redirect-chassis"
 * specified). */
for (&Router(.lr = lr,
             .l3dgw_port = l3dgw_port,
             .redirect_port_name = redirect_port_name,
             .is_gateway = is_gateway)
     if is_some(l3dgw_port) or is_gateway)
{
    for (LogicalRouterNAT(.lr = lr._uuid, .nat = &nat)) {
        Some{var external_ip} = ip46_parse(nat.external_ip) in
        (var is_v6, var ipX, var xx) = match (external_ip) {
            IPv4{_} -> (false, "ip4", ""),
            IPv6{_} -> (true, "ip6", "xx")
        } in
        /* Check the validity of nat->logical_ip. 'logical_ip' can
         * be a subnet when the type is "snat". */
        Some{(_, var mask)} = ip46_parse_masked(nat.logical_ip) in
        true == match ((ip46_is_all_ones(mask), nat.__type)) {
            (_, "snat") -> true,
            (false, _) -> {
                warn("bad ip ${nat.logical_ip} for dnat in router ${uuid2str(lr._uuid)}");
                false
            },
            _ -> true
        } in
        /* For distributed router NAT, determine whether this NAT rule
         * satisfies the conditions for distributed NAT processing. */
        Some{var mac: Option<eth_addr>} =
            if (is_some(l3dgw_port) and nat.__type == "dnat_and_snat") {
                match ((nat.logical_port, nat.external_mac)) {
                    (Some{_}, Some{external_mac}) -> {
                        match (eth_addr_from_string(external_mac)) {
                            Some{mac} -> Some { Some{mac} },
                            None -> {
                                warn("bad mac ${external_mac} for dnat in router ${uuid2str(lr._uuid)}");
                                None
                            }
                        }
                    },
                    _ -> { Some{ None } }
                }
            } else { Some{ None } } in
        var stateless = (lrouter_nat_is_stateless(nat)
                         and nat.__type == "dnat_and_snat") in
        {
            /* Ingress UNSNAT table: It is for already established connections'
             * reverse traffic. i.e., SNAT has already been done in egress
             * pipeline and now the packet has entered the ingress pipeline as
             * part of a reply. We undo the SNAT here.
             *
             * Undoing SNAT has to happen before DNAT processing.  This is
             * because when the packet was DNATed in ingress pipeline, it did
             * not know about the possibility of eventual additional SNAT in
             * egress pipeline. */
            if (nat.__type == "snat" or nat.__type == "dnat_and_snat") {
                if (l3dgw_port == None) {
                    /* Gateway router. */
                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.logical_ip}; next;"
                    } else {
                        "ct_snat;"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(IN, UNSNAT),
                         .priority         = 90,
                         .__match          = "ip && ${ipX}.dst == ${nat.external_ip}",
                         .actions          = actions,
                         .external_ids     = stage_hint(nat._uuid))
                };
                Some{var gwport} = l3dgw_port in {
                    /* Distributed router. */

                    /* Traffic received on l3dgw_port is subject to NAT. */
                    var __match =
                        "ip && ${ipX}.dst == ${nat.external_ip}"
                        " && inport == ${json_string_escape(gwport.name)}" ++
                        if (mac == None) {
                            /* Flows for NAT rules that are centralized are only
                             * programmed on the "redirect-chassis". */
                            " && is_chassis_resident(${redirect_port_name})"
                        } else { "" } in
                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.logical_ip}; next;"
                    } else {
                        "ct_snat;"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(IN, UNSNAT),
                         .priority         = 100,
                         .__match          = __match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat._uuid))
                }
            };

            /* Ingress DNAT table: Packets enter the pipeline with destination
             * IP address that needs to be DNATted from a external IP address
             * to a logical IP address. */
            var ip_and_ports = "${nat.logical_ip}" ++
                               if (nat.external_port_range != "") {
                                   " ${nat.external_port_range}"
                               } else {
                                   ""
                               } in
            if (nat.__type == "dnat" or nat.__type == "dnat_and_snat") {
                if (l3dgw_port == None) {
                    /* Gateway router. */
                    /* Packet when it goes from the initiator to destination.
                     * We need to set flags.loopback because the router can
                     * send the packet back through the same interface. */
                    var flag_action =
                        if (is_some(get_force_snat_ip(lr, "dnat"))) {
                            /* Indicate to the future tables that a DNAT has taken
                             * place and a force SNAT needs to be done in the
                             * Egress SNAT table. */
                            "flags.force_snat_for_dnat = 1; "
                        } else { "" } in
                    var nat_actions = if (stateless) {
                        "${ipX}.dst=${nat.logical_ip}; next;"
                    } else {
                        "flags.loopback = 1; "
                        "ct_dnat(${ip_and_ports});"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(IN, DNAT),
                         .priority         = 100,
                         .__match          = "ip && ip4.dst == ${nat.external_ip}",
                         .actions          = flag_action ++ nat_actions,
                         .external_ids     = stage_hint(nat._uuid))
                };

                Some{var gwport} = l3dgw_port in {
                    /* Distributed router. */
                    /* Traffic received on l3dgw_port is subject to NAT. */
                    var __match =
                        "ip && ${ipX}.dst == ${nat.external_ip}"
                        " && inport == ${json_string_escape(gwport.name)}" ++
                        if (mac == None) {
                            /* Flows for NAT rules that are centralized are only
                             * programmed on the "redirect-chassis". */
                            " && is_chassis_resident(${redirect_port_name})"
                        } else { "" } in
                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.logical_ip}; next;"
                    } else {
                        "ct_dnat(${ip_and_ports});"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(IN, DNAT),
                         .priority         = 100,
                         .__match          = __match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat._uuid))
                };

                /* ARP resolve for NAT IPs. */
                Some{var gwport} = l3dgw_port in {
                var gwport_name = json_string_escape(gwport.name) in {
                    if (nat.__type == "snat") {
                        var __match = "inport == ${gwport_name} && "
                                      "${ipX}.src == ${nat.external_ip}" in
                        Flow(.logical_datapath = lr._uuid,
                             .stage            = router_stage(IN, IP_INPUT),
                             .priority         = 120,
                             .__match          = __match,
                             .actions          = "next;",
                             .external_ids     = stage_hint(nat._uuid))
                    };

                    var __match = "outport == ${gwport_name} && "
                                  "${xx}reg0 == ${nat.external_ip}" in
                    var dst_mac = match (mac) {
                        Some{value} -> "${value}",
                        None -> gwport.mac
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(IN, ARP_RESOLVE),
                         .priority         = 100,
                         .__match          = __match,
                         .actions          = "eth.dst = ${dst_mac}; next;",
                         .external_ids     = stage_hint(nat._uuid))
                    }
                }
            };

            /* Egress UNDNAT table: It is for already established connections'
             * reverse traffic. i.e., DNAT has already been done in ingress
             * pipeline and now the packet has entered the egress pipeline as
             * part of a reply. We undo the DNAT here.
             *
             * Note that this only applies for NAT on a distributed router.
             * Undo DNAT on a gateway router is done in the ingress DNAT
             * pipeline stage. */
            if ((nat.__type == "dnat" or nat.__type == "dnat_and_snat")) {
                Some{var gwport} = l3dgw_port in
                var __match =
                    "ip && ${ipX}.src == ${nat.logical_ip}"
                    " && outport == ${json_string_escape(gwport.name)}" ++
                    if (mac == None) {
                        /* Flows for NAT rules that are centralized are only
                         * programmed on the "redirect-chassis". */
                        " && is_chassis_resident(${redirect_port_name})"
                    } else { "" } in
                var actions =
                    match (mac) {
                        Some{mac_addr} -> "eth.src = ${mac_addr}; ",
                        None -> ""
                    } ++
                    if (stateless) {
                        "${ipX}.src=${nat.external_ip}; next;"
                    } else {
                        "ct_dnat;"
                    } in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = router_stage(OUT, UNDNAT),
                     .priority         = 100,
                     .__match          = __match,
                     .actions          = actions,
                     .external_ids     = stage_hint(nat._uuid))
            };

            /* Egress SNAT table: Packets enter the egress pipeline with
             * source ip address that needs to be SNATted to a external ip
             * address. */
            var ip_and_ports = "${nat.external_ip}" ++
                               if (nat.external_port_range != "") {
                                   " ${nat.external_port_range}"
                               } else {
                                   ""
                               } in
            if (nat.__type == "snat" or nat.__type == "dnat_and_snat") {
                if (l3dgw_port == None) {
                    /* Gateway router. */

                    /* The priority here is calculated such that the
                     * nat->logical_ip with the longest mask gets a higher
                     * priority. */
                    var actions = if (stateless) {
                        "${ipX}.src=${nat.external_ip}; next;"
                    } else {
                        "ct_snat(${ip_and_ports});"
                    } in
                    Some{var plen} = ip46_count_cidr_bits(mask) in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(OUT, SNAT),
                         .priority         = plen as bit<64> + 64'd1,
                         .__match          = "ip && ${ipX}.src == ${nat.logical_ip}",
                         .actions          = actions,
                         .external_ids     = stage_hint(nat._uuid))
                };

                Some{var gwport} = l3dgw_port in
                {
                    /* Distributed router. */
                    var __match =
                        "ip && ${ipX}.src == ${nat.logical_ip}"
                        " && outport == ${json_string_escape(gwport.name)}" ++
                        if (mac == None) {
                            /* Flows for NAT rules that are centralized are only
                             * programmed on the "redirect-chassis". */
                            " && is_chassis_resident(${redirect_port_name})"
                        } else { "" } in
                    var actions =
                        match (mac) {
                            Some{mac_addr} -> "eth.src = ${mac_addr}; ",
                            _ -> ""
                        } ++ if (stateless) {
                            "${ipX}.src=${nat.external_ip}; next;"
                        } else {
                            "ct_snat(${ip_and_ports});"
                        } in
                    /* The priority here is calculated such that the
                     * nat->logical_ip with the longest mask gets a higher
                     * priority. */
                    Some{var plen} = ip46_count_cidr_bits(mask) in
                    var priority = (plen as bit<64>) + 64'd1 in
                    var centralized_boost = if (mac == None) {64'd128} else {64'd0} in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = router_stage(OUT, SNAT),
                         .priority         = priority + centralized_boost,
                         .__match          = __match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat._uuid))
                }
            };

            /* Logical router ingress table ADMISSION:
             * For NAT on a distributed router, add rules allowing
             * ingress traffic with eth.dst matching nat->external_mac
             * on the l3dgw_port instance where nat->logical_port is
             * resident. */
            Some{var mac_addr} = mac in
            Some{var gwport} = l3dgw_port in
            Some{var logical_port} = nat.logical_port in
            var __match =
                "eth.dst == ${mac_addr} && inport == ${json_string_escape(gwport.name)}"
                " && is_chassis_resident(${json_string_escape(logical_port)})" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = router_stage(IN, ADMISSION),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(nat._uuid));

            /* Ingress Gateway Redirect Table: For NAT on a distributed
             * router, add flows that are specific to a NAT rule.  These
             * flows indicate the presence of an applicable NAT rule that
             * can be applied in a distributed manner. */
            Some{var mac_addr} = mac in
            Some{var gwport} = l3dgw_port in
            var __match =
                "${ipX}.src == ${nat.logical_ip} && outport == ${json_string_escape(gwport.name)}" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = router_stage(IN, GW_REDIRECT),
                 .priority         = 200,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(nat._uuid));

            /* Egress Loopback table: For NAT on a distributed router.
             * If packets in the egress pipeline on the distributed
             * gateway port have ip.dst matching a NAT external IP, then
             * loop a clone of the packet back to the beginning of the
             * ingress pipeline with inport = outport. */
            Some{var gwport} = l3dgw_port in
            /* Distributed router. */
            Some{var port} = match (mac) {
                Some{_} -> match (nat.logical_port) {
                               Some{name} -> Some{json_string_escape(name)},
                               None -> None: Option<string>
                           },
                None -> Some{redirect_port_name}
            } in
            var __match = "${ipX}.dst == ${nat.external_ip} && outport == ${json_string_escape(gwport.name)} && is_chassis_resident(${port})" in
            var regs = {
                var regs: Vec<string> = vec_empty();
                for (j in range(32'd0, mFF_N_LOG_REGS()-32'd1, 32'd1)) {
                    vec_push(regs, "reg${j} = 0; ")
                };
                regs
            } in
            var actions =
                "clone { ct_clear; "
                "inport = outport; outport = \"\"; "
                "flags = 0; flags.loopback = 1; "    ++
                string_join(regs, "")                ++
                "${rEGBIT_EGRESS_LOOPBACK()} = 1; "
                "next(pipeline=ingress, table=0); };" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = router_stage(OUT, EGR_LOOP),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(nat._uuid))
        }
    };

    /* Handle force SNAT options set in the gateway router. */
    Some{(_, var dnat_force_snat_ip)} = get_force_snat_ip(lr, "dnat") in
    if (l3dgw_port == None) {
        /* If a packet with destination IP address as that of the
         * gateway router (as set in options:dnat_force_snat_ip) is seen,
         * UNSNAT it. */
        var ipX = match (dnat_force_snat_ip) {
            IPv4{_} -> "ip4",
            IPv6{_} -> "ip6"
        } in
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, UNSNAT),
             .priority         = 110,
             .__match          = "ip && ${ipX}.dst == ${dnat_force_snat_ip}",
             .actions          = "ct_snat;",
             .external_ids     = map_empty());

        /* Higher priority rules to force SNAT with the IP addresses
         * configured in the Gateway router.  This only takes effect
         * when the packet has already been DNATed once. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(OUT, SNAT),
             .priority         = 100,
             .__match          = "flags.force_snat_for_dnat == 1 && ip",
             .actions          = "ct_snat(${dnat_force_snat_ip});",
             .external_ids     = map_empty())
    };

    Some{(_, var lb_force_snat_ip)} = get_force_snat_ip(lr, "lb") in
    if (l3dgw_port == None) {
        /* If a packet with destination IP address as that of the
         * gateway router (as set in options:lb_force_snat_ip) is seen,
         * UNSNAT it. */
        var ipX = match (lb_force_snat_ip) {
            IPv4{_} -> "ip4",
            IPv6{_} -> "ip6"
        } in
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, UNSNAT),
             .priority         = 100,
             .__match          = "ip && ${ipX}.dst == ${lb_force_snat_ip}",
             .actions          = "ct_snat;",
             .external_ids     = map_empty());

        /* Load balanced traffic will have flags.force_snat_for_lb set.
         * Force SNAT it. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(OUT, SNAT),
             .priority         = 100,
             .__match          = "flags.force_snat_for_lb == 1 && ip",
             .actions          = "ct_snat(${lb_force_snat_ip});",
             .external_ids     = map_empty())
    };

    if (l3dgw_port == None) {
        /* For gateway router, re-circulate every packet through
        * the DNAT zone.  This helps with the following.
        *
        * Any packet that needs to be unDNATed in the reverse
        * direction gets unDNATed. Ideally this could be done in
        * the egress pipeline. But since the gateway router
        * does not have any feature that depends on the source
        * ip address being external IP address for IP routing,
        * we can do it here, saving a future re-circulation. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, DNAT),
             .priority         = 50,
             .__match          = "ip",
             .actions          = "flags.loopback = 1; ct_dnat;",
             .external_ids     = map_empty())
    }
}

function nats_contain_vip(nats: Vec<Ref<nb.NAT>>, vip: string): bool {
    for (nat in nats) {
        if (nat.external_ip == vip) {
            return true
        }
    };
    return false
}

/* Load balancing and packet defrag are only valid on
 * Gateway routers or router with gateway port. */
for (RouterLBVIP(
        .router = &Router{.lr = lr,
                          .l3dgw_port = l3dgw_port,
                          .redirect_port_name = redirect_port_name,
                          .is_gateway = is_gateway,
                          .nats = nats},
        .lb = &lb,
        .vip = vip,
        .backends = backends)
     if is_some(l3dgw_port) or is_gateway)
{
    if (backends == "") {
        for (ControllerEventEn(true)) {
            for (HasEventElbMeter(has_elb_meter)) {
                Some {(var __match, var __action)} =
                    build_empty_lb_event_flow(vip, lb, has_elb_meter) in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = router_stage(IN, DNAT),
                     .priority         = 130,
                     .__match          = __match,
                     .actions          = __action,
                     .external_ids     = stage_hint(lb._uuid))
            }
        }
    };

    /* A set to hold all ips that need defragmentation and tracking. */

    /* vip contains IP:port or just IP. */
    Some{(var ip_address, var port, var addr_family)} = ip_address_and_port_from_lb_key(vip) in
    var ipX = if (addr_family == aF_INET()) {
        "ip4"
    } else {
        "ip6"
    } in
    var proto = match (lb.protocol) {
        Some{proto} -> proto,
        _ -> "tcp"
    } in {
        /* If there are any load balancing rules, we should send
         * the packet to conntrack for defragmentation and
         * tracking.  This helps with two things.
         *
         * 1. With tracking, we can send only new connections to
         *    pick a DNAT ip address from a group.
         * 2. If there are L4 ports in load balancing rules, we
         *    need the defragmentation to match on L4 ports. */
        var __match = "ip && ${ipX}.dst == ${ip_address}" in
        /* One of these flows must be created for each unique LB VIP address.
         * We create one for each VIP:port pair; flows with the same IP and
         * different port numbers will produce identical flows that will
         * get merged by DDlog. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(IN, DEFRAG),
             .priority         = 100,
             .__match          = __match,
             .actions          = "ct_next;",
             .external_ids     = stage_hint(lb._uuid));

        /* Higher priority rules are added for load-balancing in DNAT
         * table.  For every match (on a VIP[:port]), we add two flows
         * via add_router_lb_flow().  One flow is for specific matching
         * on ct.new with an action of "ct_lb($targets);".  The other
         * flow is for ct.est with an action of "ct_dnat;". */
        var match1 = "ip && ${ipX}.dst == ${ip_address}" in
        (var prio, var match2) =
            if (port != 0) {
                (120: integer, " && ${proto} && ${proto}.dst == ${port}")
            } else {
                (110: integer, "")
            } in
        var __match = match1 ++ match2 ++
            match (l3dgw_port) {
                Some{gwport} -> " && is_chassis_resident(${redirect_port_name})",
                _ -> ""
            } in
        var lb_force_snat_ip = get_force_snat_ip(lr, "lb") in
        {
            /* A match and actions for established connections. */
            var est_match = "ct.est && " ++ __match in
            var actions =
                match (lb_force_snat_ip) {
                    Some{snat_ip} -> "flags.force_snat_for_lb = 1; ct_dnat;",
                    None -> "ct_dnat;"
                } in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = router_stage(IN, DNAT),
                 .priority         = prio,
                 .__match          = est_match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lb._uuid));

            if (nats_contain_vip(nats, ip_address)) {
                /* The load balancer vip is also present in the NAT entries.
                 * So add a high priority lflow to advance the the packet
                 * destined to the vip (and the vip port if defined)
                 * in the S_ROUTER_IN_UNSNAT stage.
                 * There seems to be an issue with ovs-vswitchd. When the new
                 * connection packet destined for the lb vip is received,
                 * it is dnat'ed in the S_ROUTER_IN_DNAT stage in the dnat
                 * conntrack zone. For the next packet, if it goes through
                 * unsnat stage, the conntrack flags are not set properly, and
                 * it doesn't hit the established state flows in
                 * S_ROUTER_IN_DNAT stage. */
                var match3 = "${ipX} && ${ipX}.dst == ${ip_address} && ${proto}" ++
                             if (port != 0) { " && ${proto}.dst == ${port}" }
                             else { "" } in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = router_stage(IN, UNSNAT),
                     .priority         = 120,
                     .__match          = match3,
                     .actions          = "next;",
                     .external_ids     = stage_hint(lb._uuid))
            };

            Some{var gwport} = l3dgw_port in
            /* Add logical flows to UNDNAT the load balanced reverse traffic in
             * the router egress pipleine stage - S_ROUTER_OUT_UNDNAT if the logical
             * router has a gateway router port associated.
             */
            var conds = {
                var conds: Vec<string> = vec_empty();
                for (ip_str in string_split(backends, ",")) {
                    match (ip_address_and_port_from_lb_key(ip_str)) {
                        None -> () /* FIXME: put a break here */,
                        Some{(ip_address_, port_, addr_family_)} -> vec_push(conds,
                            "(${ipX}.src == ${ip_address_}" ++
                            if (port_ != 0) {
                                " && ${proto}.src == ${port_})"
                            } else {
                                ")"
                            })
                    }
                };
                conds
            } in
            not vec_is_empty(conds) in
            var undnat_match =
                if (addr_family == aF_INET()) { "ip4 && (" } else { "ip6 && (" }    ++
                string_join(conds, " || ")                                          ++
                ") && outport == ${json_string_escape(gwport.name)} && "
                "is_chassis_resident(${redirect_port_name})" in
            var action =
                match (lb_force_snat_ip) {
                    Some{snat_ip} -> "flags.force_snat_for_lb = 1; ct_dnat;",
                    None -> "ct_dnat;"
                } in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = router_stage(OUT, UNDNAT),
                 .priority         = 120,
                 .__match          = undnat_match,
                 .actions          = action,
                 .external_ids     = stage_hint(lb._uuid))
        }
    }
}

/* Higher priority rules are added for load-balancing in DNAT
 * table.  For every match (on a VIP[:port]), we add two flows
 * via add_router_lb_flow().  One flow is for specific matching
 * on ct.new with an action of "ct_lb($targets);".  The other
 * flow is for ct.est with an action of "ct_dnat;". */
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, DNAT),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    r in &Router(),
    is_some(r.l3dgw_port) or r.is_gateway,
    LBVIPBackend[lbvipbackend],
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(r.lr.load_balancer, lb._uuid),
    bs in &LBVIPBackendStatus(.port = lbvipbackend.port,
                              .ip = lbvipbackend.ip,
                              .protocol = default_protocol(lb.protocol),
                              .logical_port = svc_monitor.port_name),
    var bses = Aggregate((r, lbvip, lb), group2set(bs)),
    var __match
        = "ct.new && " ++
          get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lbvip.addr_family, lb.protocol, true) ++
          match (r.l3dgw_port) {
              Some{gwport} -> " && is_chassis_resident(${r.redirect_port_name})",
              _ -> ""
          },
    var priority = if (lbvip.vip_port != 0) { 64'd120 } else { 64'd110 },
    var up_backends = {
        var up_backends: Set<string> = set_empty();
        for (bs in bses) {
            if (bs.up) {
                set_insert(up_backends, "${bs.ip}:${bs.port}")
            }
        };
        up_backends
    },
    var actions = if (set_is_empty(up_backends)) {
        "drop;"
    } else {
        match (get_force_snat_ip(r.lr, "lb")) {
            Some{snat_ip} -> "flags.force_snat_for_lb = 1; ",
            _ -> ""
        } ++ ct_lb(string_join(set2vec(up_backends), ","), lb.selection_fields)
    }.
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, DNAT),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    r in &Router(),
    is_some(r.l3dgw_port) or r.is_gateway,
    LBVIPBackend[lbvipbackend],
    None = lbvipbackend.svc_monitor,
    var lbvip = lbvipbackend.lbvip,
    var lb = lbvip.lb,
    set_contains(r.lr.load_balancer, lb._uuid),
    var __match
        = "ct.new && " ++
          get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lbvip.addr_family, lb.protocol, true) ++
          match (r.l3dgw_port) {
              Some{gwport} -> " && is_chassis_resident(${r.redirect_port_name})",
              _ -> ""
          },
    var priority = if (lbvip.vip_port != 0) { 64'd120 } else { 64'd110 },
    var actions = ct_lb(lbvip.backend_ips, lb.selection_fields).


/* Defaults based on MaxRtrInterval and MinRtrInterval from RFC 4861 section
 * 6.2.1
 */
function nD_RA_MAX_INTERVAL_DEFAULT(): integer = 600

function nd_ra_min_interval_default(max: integer): integer =
{
    if (max >= 9) { max / 3 } else { max * 3 / 4 }
}

function nD_RA_MAX_INTERVAL_MAX(): integer = 1800
function nD_RA_MAX_INTERVAL_MIN(): integer = 4

function nD_RA_MIN_INTERVAL_MAX(max: integer): integer = ((max * 3) / 4)
function nD_RA_MIN_INTERVAL_MIN(): integer = 3

function nD_MTU_DEFAULT(): integer = 0

function copy_ra_to_sb(port: RouterPort, address_mode: string): Map<string, string> =
{
    var options = port.sb_options;

    map_insert(options, "ipv6_ra_send_periodic", "true");
    map_insert(options, "ipv6_ra_address_mode", address_mode);

    var max_interval = map_get_int_def(port.lrp.ipv6_ra_configs, "max_interval",
            nD_RA_MAX_INTERVAL_DEFAULT());

    if (max_interval > nD_RA_MAX_INTERVAL_MAX()) {
        max_interval = nD_RA_MAX_INTERVAL_MAX()
    } else ();

    if (max_interval < nD_RA_MAX_INTERVAL_MIN()) {
        max_interval = nD_RA_MAX_INTERVAL_MIN()
    } else ();

    map_insert(options, "ipv6_ra_max_interval", "${max_interval}");

    var min_interval = map_get_int_def(port.lrp.ipv6_ra_configs,
            "min_interval", nd_ra_min_interval_default(max_interval));

    if (min_interval > nD_RA_MIN_INTERVAL_MAX(max_interval)) {
        min_interval = nD_RA_MIN_INTERVAL_MAX(max_interval)
    } else ();

    if (min_interval < nD_RA_MIN_INTERVAL_MIN()) {
        min_interval = nD_RA_MIN_INTERVAL_MIN()
    } else ();

    map_insert(options, "ipv6_ra_min_interval", "${min_interval}");

    var mtu = map_get_int_def(port.lrp.ipv6_ra_configs, "mtu", nD_MTU_DEFAULT());

    /* RFC 2460 requires the MTU for IPv6 to be at least 1280 */
    if (mtu != 0 and mtu >= 1280) {
        map_insert(options, "ipv6_ra_mtu", "${mtu}")
    } else ();

    var prefixes: Vec<string> = vec_empty();
    for (addrs in port.networks.ipv6_addrs) {
        if (in6_is_lla(addrs.network)) {
            map_insert(options, "ipv6_ra_src_addr", addrs.addr_s)
        } else {
            vec_push(prefixes, "${addrs.network_s}/${addrs.plen}")
        }
    };
    match (map_get(port.sb_options, "ipv6_ra_pd_list")) {
        Some{value} -> vec_push(prefixes, value),
        _ -> ()
    };
    map_insert(options, "ipv6_ra_prefixes", string_join(prefixes, " "));

    match (map_get(port.lrp.ipv6_ra_configs, "rdnss")) {
        Some{value} -> map_insert(options, "ipv6_ra_rdnss", value),
        _ -> ()
    };

    match (map_get(port.lrp.ipv6_ra_configs, "dnssl")) {
        Some{value} -> map_insert(options, "ipv6_ra_dnssl", value),
        _ -> ()
    };

    map_insert(options, "ipv6_ra_src_eth", port.networks.ea_s);

    var prf = match (map_get(port.lrp.ipv6_ra_configs, "router_preference")) {
        Some{prf} -> if (prf == "HIGH" or prf == "LOW") prf else "MEDIUM",
        _ -> "MEDIUM"
    };
    map_insert(options, "ipv6_ra_prf", prf);

    match (map_get(port.lrp.ipv6_ra_configs, "route_info")) {
        Some{s} -> map_insert(options, "ipv6_ra_route_info", s),
        _ -> ()
    };

    options
}

/* Logical router ingress table ND_RA_OPTIONS and ND_RA_RESPONSE: IPv6 Router
 * Adv (RA) options and response. */
// FIXME: do these rules apply to derived ports?
for (&RouterPort[port@RouterPort{.lrp = lrp@nb.Logical_Router_Port{.peer = None},
                                 .router = &router,
                                 .json_name = json_name,
                                 .networks = networks,
                                 .peer = PeerSwitch{}}]
     if (not vec_is_empty(networks.ipv6_addrs)))
{
    Some{var address_mode} = map_get(lrp.ipv6_ra_configs, "address_mode") in
    /* FIXME: we need a nicer wat to write this */
    true ==
        if ((address_mode != "slaac") and
            (address_mode != "dhcpv6_stateful") and
            (address_mode != "dhcpv6_stateless")) {
            warn("Invalid address mode [${address_mode}] defined");
            false
        } else { true } in
    {
        if (map_get_bool_def(lrp.ipv6_ra_configs, "send_periodic", false)) {
            RouterPortRAOptions(lrp._uuid, copy_ra_to_sb(port, address_mode))
        };

        (true, var prefix) =
            {
                var add_rs_response_flow = false;
                var prefix = "";
                for (addr in networks.ipv6_addrs) {
                    if (not in6_is_lla(addr.network)) {
                        prefix = prefix ++ ", prefix = ${addr.network_s}/${addr.plen}";
                        add_rs_response_flow = true
                    } else ()
                };
                (add_rs_response_flow, prefix)
            } in
        {
            var __match = "inport == ${json_name} && ip6.dst == ff02::2 && nd_rs" in
            /* As per RFC 2460, 1280 is minimum IPv6 MTU. */
            var mtu: integer = match(map_get(lrp.ipv6_ra_configs, "mtu")) {
                    Some{mtu_s} -> {
                        match (str_to_int(mtu_s, 10)) {
                            None -> 0,
                            Some{mtu} -> if (mtu >= 64'd1280) mtu else 0
                        }
                    },
                    None -> 0
                } in
            var actions0 =
                "${rEGBIT_ND_RA_OPTS_RESULT()} = put_nd_ra_opts("
                "addr_mode = ${json_string_escape(address_mode)}, "
                "slla = ${networks.ea_s}" ++
                if (mtu > 0) { ", mtu = ${mtu}" } else { "" } in
            var actions = actions0 ++ prefix ++ "); next;" in
            Flow(.logical_datapath = router.lr._uuid,
                 .stage            = router_stage(IN, ND_RA_OPTIONS),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lrp._uuid));

            var __match = "inport == ${json_name} && ip6.dst == ff02::2 && "
                          "nd_ra && ${rEGBIT_ND_RA_OPTS_RESULT()}" in
            var ip6_str = ipv6_string_mapped(in6_generate_lla(networks.ea)) in
            var actions = "eth.dst = eth.src; eth.src = ${networks.ea_s}; "
                          "ip6.dst = ip6.src; ip6.src = ${ip6_str}; "
                          "outport = inport; flags.loopback = 1; "
                          "output;" in
            Flow(.logical_datapath = router.lr._uuid,
                 .stage            = router_stage(IN, ND_RA_RESPONSE),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lrp._uuid))
        }
    }
}


/* Logical router ingress table ND_RA_OPTIONS, ND_RA_RESPONSE: RS responder, by
 * default goto next.  (priority 0)*/
for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ND_RA_OPTIONS),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ND_RA_RESPONSE),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Logical router ingress table IP_ROUTING - IP routing for distributed
 * logical router
 */
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, IP_ROUTING),
     .priority         = 32'd0 ++ dROUTE_PRIO(),
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(nat._uuid)) :-
    r in &Router(.l3dgw_port = Some{l3dgw_port}),
    var nat = FlatMap(r.nats),
    nat.__type == "dnat_and_snat",
    Some{var external_mac} = nat.external_mac,
    Some{var logical_port} = nat.logical_port,
    (var ipx, var xx) = match (string_contains(nat.logical_ip, ".")) {
        true -> ("ip4", ""),
        false -> ("ip6", "xx")
    },
    var __match = "${ipx}.src == ${nat.logical_ip} && "
                  "is_chassis_resident(${json_string_escape(logical_port)})",
    var actions = "outport = ${json_string_escape(l3dgw_port.name)}; "
                  "eth.src = ${external_mac}; "
                  "${xx}reg0 = ${ipx}.dst; "
                  "${xx}reg1 = ${nat.external_ip}; "
                  "next;".

/* Proxy table that stores per-port routes.
 * There routes get converted into logical flows by
 * the following rule.
 */
relation Route(key:         route_key,       // matching criteria
               port:        Ref<RouterPort>, // output port
               src_ip:      v46_ip,          // source IP address for output
               gateway:     Option<v46_ip>) // next hop (unless being delivered)

function build_route_match(key: route_key) : (string, bit<32>) =
{
    (var ipx) = match (key.ip_prefix) {
        IPv4{_} -> "ip4",
        IPv6{_} -> "ip6"
    };

    (var dir, var priority) = match (key.policy) {
        SrcIp -> ("src", key.plen * 32'd2),
        DstIp -> ("dst", (key.plen * 32'd2) + 32'd1)
    };

    var network = ip46_get_network(key.ip_prefix, key.plen);
    var __match = "${ipx}.${dir} == ${network}/${key.plen}";

    (__match, priority)
}
for (Route(.port        = port,
           .key         = key,
           .src_ip      = src_ip,
           .gateway     = gateway))
{
    (var ipx, var xx) = match (key.ip_prefix) {
        IPv4{_} -> ("ip4", ""),
        IPv6{_} -> ("ip6", "xx")
    } in
    /* IPv6 link-local addresses must be scoped to the local router port. */
    var inport_match = match (key.ip_prefix) {
        IPv6{prefix} -> if (in6_is_lla(prefix)) {
                            "inport == ${port.json_name} && "
                        } else "",
        _ -> ""
    } in
    (var ip_match, var priority) = build_route_match(key) in
    /* traffic for internal IPs of logical switch ports must be sent to
     * the gw controller through the overlay tunnels
     */
    var dprio_bonus = if (set_is_empty(port.lrp.gateway_chassis)) {
        dROUTE_PRIO()
    } else {
        32'd0
    } in
    var __match = inport_match ++ ip_match in
    var nexthop = match (gateway) {
        Some{gw} -> "${gw}",
        None     -> "${ipx}.dst"
    } in
    var actions =
        "ip.ttl--; "
        "${rEG_ECMP_GROUP_ID()} = 0; "
        "${xx}reg0 = ${nexthop}; "
        "${xx}reg1 = ${src_ip}; "
        "eth.src = ${port.networks.ea_s}; "
        "outport = ${port.json_name}; "
        "flags.loopback = 1; "
        "next;" in
    /* The priority here is calculated to implement longest-prefix-match
     * routing. */
    Flow(.logical_datapath = port.router.lr._uuid,
         .stage            = router_stage(IN, IP_ROUTING),
         .priority         = 32'd0 ++ (priority + dprio_bonus),
         .__match          = __match,
         .actions          = actions,
         .external_ids     = stage_hint(port.lrp._uuid))
}

/* Logical router ingress table IP_ROUTING & IP_ROUTING_ECMP: IP Routing.
 *
 * A packet that arrives at this table is an IP packet that should be
 * routed to the address in 'ip[46].dst'.
 *
 * For regular routes without ECMP, table IP_ROUTING sets outport to the
 * correct output port, eth.src to the output port's MAC address, and
 * '[xx]reg0' to the next-hop IP address (leaving 'ip[46].dst', the
 * packets final destination, unchanged), and advances to the next table.
 *
 * For ECMP routes, i.e. multiple routes with same policy and prefix, table
 * IP_ROUTING remembers ECMP group id and selects a member id, and advances
 * to table IP_ROUTING_ECMP, which sets outport, eth.src and '[xx]reg0' for
 * the selected ECMP member.
 * */
Route(key, port, src_ip, None) :-
    RouterPortNetworksIPv4Addr(.port = port, .addr = addr),
    var key = RouteKey{DstIp, IPv4{addr.addr}, addr.plen},
    var src_ip = IPv4{addr.addr}.

Route(key, port, src_ip, None) :-
    RouterPortNetworksIPv6Addr(.port = port, .addr = addr),
    var key = RouteKey{DstIp, IPv6{addr.addr}, addr.plen},
    var src_ip = IPv6{addr.addr}.

Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, IP_ROUTING_ECMP),
     .priority         = 150,
     .__match          = "${rEG_ECMP_GROUP_ID()} == 0",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    r in &Router().

/* Convert the static routes to flows. */
Route(key, dst.port, dst.src_ip, Some{dst.nexthop}) :-
    RouterStaticRoute(.router = &router, .key = key, .dsts = dsts),
    set_size(dsts) == 64'd1,
    Some{var dst} = set_nth(dsts, 0).

/* Return a vector of pairs (1, set[0]), ... (n, set[n - 1]). */
function numbered_vec(set: Set<'A>) : Vec<(bit<16>, 'A)> = {
    var vec: Vec<(bit<16>, 'A)> = vec_with_capacity(set_size(set));
    var i = 16'd1;
    for (x in set) {
        vec_push(vec, (i, x));
        i = i + 1
    };
    vec
}

relation EcmpGroup(
    group_id: bit<16>,
    router: Ref<Router>,
    key: route_key,
    dsts: Set<route_dst>)

EcmpGroup(group_id, router, key, dsts) :-
    RouterStaticRoute(.router = router, .key = key, .dsts = dsts),
    set_size(dsts) > 64'd1,
    var groups = Aggregate((), group2set((router, key, dsts))),
    var group_id_and_group = FlatMap(numbered_vec(groups)),
    (var group_id, (var router, var key, var dsts)) = group_id_and_group.

Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, IP_ROUTING),
     .priority         = priority as integer,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    EcmpGroup(group_id, router, key, dsts),
    (var __match, var priority) = build_route_match(key),
    var all_member_ids = {
        var member_ids: Vec<string> = vec_with_capacity(set_size(dsts));
        for (i in range(64'd1, set_size(dsts), 64'd1)) {
            vec_push(member_ids, "${i}")
        };
        string_join(member_ids, ", ")
    },
    var actions =
        "ip.ttl--; "
        "flags.loopback = 1; "
        "${rEG_ECMP_GROUP_ID()} = ${group_id}; " /* XXX */
        "${rEG_ECMP_MEMBER_ID()} = select(${all_member_ids});".

Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, IP_ROUTING_ECMP),
     .priority         = 100,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    EcmpGroup(group_id, router, key, dsts),
    var member_id_and_dst = FlatMap(numbered_vec(dsts)),
    (var member_id, var dst) = member_id_and_dst,
    var xx = match (dst.nexthop) { IPv4{_} -> "", IPv6{_} -> "xx" },
    var __match = "${rEG_ECMP_GROUP_ID()} == ${group_id} && "
                  "${rEG_ECMP_MEMBER_ID()} == ${member_id}",
    var actions = "${xx}reg0 = ${dst.nexthop}; "
                  "${xx}reg1 = ${dst.src_ip}; "
                  "eth.src = ${dst.port.networks.ea_s}; "
                  "outport = ${dst.port.json_name}; "
                  "next;".


/* IP Multicast lookup. Here we set the output port, adjust TTL and advance
 * to next table (priority 500).
 */
/* Drop IPv6 multicast traffic that shouldn't be forwarded,
 * i.e., router solicitation and router advertisement.
 */
Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, IP_ROUTING),
     .priority         = 550,
     .__match          = "nd_rs || nd_ra",
     .actions          = "drop;",
     .external_ids     = map_empty()) :-
    router in &Router().

for (IgmpRouterMulticastGroup(address, &rtr, ports)) {
    for (RouterMcastFloodPorts(&rtr, flood_ports) if rtr.mcast_cfg.relay) {
        var flood_static = not set_is_empty(flood_ports) in
        var mc_static = json_string_escape(mC_STATIC().0) in
        var static_act = {
            if (flood_static) {
                "clone { "
                    "outport = ${mc_static}; "
                    "ip.ttl--; "
                    "next; "
                "};"
            } else {
                ""
            }
        } in
        var ipX = match (ipv6_parse(address)) {
            Some{ipv6} -> "ip6",
            _ -> "ip4"
        } in
        Flow(.logical_datapath = rtr.lr._uuid,
             .stage            = router_stage(IN, IP_ROUTING),
             .priority         = 500,
             .__match          = "${ipX} && ${ipX}.dst == ${address}",
             .actions          =
                "${static_act} outport = ${json_string_escape(address)}; "
                "ip.ttl--; next;",
             .external_ids     = map_empty())
    }
}

/* If needed, flood unregistered multicast on statically configured ports.
 * Priority 450. Otherwise drop any multicast traffic.
 */
for (RouterMcastFloodPorts(&rtr, flood_ports) if rtr.mcast_cfg.relay) {
    var mc_static = json_string_escape(mC_STATIC().0) in
    var flood_static = not set_is_empty(flood_ports) in
    var actions = if (flood_static) {
        "clone { "
            "outport = ${mc_static}; "
            "ip.ttl--; "
            "next; "
        "};"
    } else {
        "drop;"
    } in
    Flow(.logical_datapath = rtr.lr._uuid,
         .stage            = router_stage(IN, IP_ROUTING),
         .priority         = 450,
         .__match          = "ip4.mcast || ip6.mcast",
         .actions          = actions,
         .external_ids     = map_empty())
}

/* Logical router ingress table POLICY: Policy.
 *
 * A packet that arrives at this table is an IP packet that should be
 * permitted/denied/rerouted to the address in the rule's nexthop.
 * This table sets outport to the correct out_port,
 * eth.src to the output port's MAC address,
 * and '[xx]reg0' to the next-hop IP address (leaving
 * 'ip[46].dst', the packets final destination, unchanged), and
 * advances to the next table for ARP/ND resolution. */
for (&Router(.lr = lr)) {
    /* This is a catch-all rule. It has the lowest priority (0)
     * does a match-all("1") and pass-through (next) */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, POLICY),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function stage_hint(_uuid: uuid): Map<string,string> = {
    map_singleton("stage-hint", "${hex(_uuid[127:96])}")
}


/* Convert routing policies to flows. */
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, POLICY),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = actions,
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb.Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "reroute",
    out_port in &RouterPort(.router = r),
    Some{var nexthop_s} = policy.nexthop,
    Some{var nexthop} = ip46_parse(nexthop_s),
    Some{var src_ip} = find_lrp_member_ip(out_port.networks, nexthop),
    /*
    None:
    VLOG_WARN_RL(&rl, "lrp_addr not found for routing policy "
                 " priority %"PRId64" nexthop %s",
                 rule->priority, rule->nexthop);
    */
    var xx = match (src_ip) { IPv4{_} -> "", IPv6{_} -> "xx" },
    var actions = ("${xx}reg0 = ${nexthop}; "
                   "${xx}reg1 = ${src_ip}; "
                   "eth.src = ${out_port.networks.ea_s}; "
                   "outport = ${out_port.json_name}; "
                   "next;").
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, POLICY),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = "drop;",
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb.Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "drop".
Flow(.logical_datapath = r.lr._uuid,
     .stage            = router_stage(IN, POLICY),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = "next;",
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb.Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "allow".

/* XXX destination unreachable */

/* Local router ingress table ARP_RESOLVE: ARP Resolution.
 *
 * Multicast packets already have the outport set so just advance to next
 * table (priority 500).
 */
for (&Router(.lr = lr)) {
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_RESOLVE),
         .priority         = 500,
         .__match          = "ip4.mcast || ip6.mcast",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Local router ingress table ARP_RESOLVE: ARP Resolution.
 *
 * Any packet that reaches this table is an IP packet whose next-hop IP
 * address is in reg0. (ip4.dst is the final destination.) This table
 * resolves the IP address in reg0 into an output port in outport and an
 * Ethernet address in eth.dst. */
// FIXME: does this apply to redirect ports?
for (rp in &RouterPort(.peer = PeerRouter{peer_port, _},
                       .router = &router,
                       .networks = networks))
{
    for (&RouterPort(.lrp = nb.Logical_Router_Port{._uuid = peer_port},
                     .json_name = peer_json_name,
                     .router = &peer_router))
    {
        /* This is a logical router port. If next-hop IP address in
         * '[xx]reg0' matches IP address of this router port, then
         * the packet is intended to eventually be sent to this
         * logical port. Set the destination mac address using this
         * port's mac address.
         *
         * The packet is still in peer's logical pipeline. So the match
         * should be on peer's outport. */
        if (not vec_is_empty(networks.ipv4_addrs)) {
            var __match = "outport == ${peer_json_name} && reg0 == " ++
                          format_v4_networks(networks, false) in
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = router_stage(IN, ARP_RESOLVE),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = "eth.dst = ${networks.ea_s}; next;",
                 .external_ids     = stage_hint(rp.lrp._uuid))
        };

        if (not vec_is_empty(networks.ipv6_addrs)) {
            var __match = "outport == ${peer_json_name} && xxreg0 == " ++
                          format_v6_networks(networks) in
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = router_stage(IN, ARP_RESOLVE),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = "eth.dst = ${networks.ea_s}; next;",
                 .external_ids     = stage_hint(rp.lrp._uuid))
        }
    }
}

/* Packet is on a non gateway chassis and
 * has an unresolved ARP on a network behind gateway
 * chassis attached router port. Since, redirect type
 * is "bridged", instead of calling "get_arp"
 * on this node, we will redirect the packet to gateway
 * chassis, by setting destination mac router port mac.*/
Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, ARP_RESOLVE),
     .priority         = 50,
     .__match          = "outport == ${rp.json_name} && "
                         "!is_chassis_resident(${router.redirect_port_name})",
     .actions          = "eth.dst = ${rp.networks.ea_s}; next;",
     .external_ids     = stage_hint(lrp._uuid)) :-
    rp in &RouterPort(.lrp = lrp, .router = router),
    router.redirect_port_name != "",
    Some{"bridged"} = map_get(lrp.options, "redirect-type").


/* This is a logical switch port that backs a VM or a container.
 * Extract its addresses. For each of the address, go through all
 * the router ports attached to the switch (to which this port
 * connects) and if the address in question is reachable from the
 * router port, add an ARP/ND entry in that router's pipeline. */
for (SwitchPortIPv4Address(
        .port = &SwitchPort{.lsp = lsp, .sw = &sw},
        .ea_s = ea_s,
        .addr = addr)
     if lsp.__type != "router" and lsp.__type != "virtual" and is_enabled(lsp.enabled))
{
    for (&SwitchPort(.sw = &Switch{.ls = nb.Logical_Switch{._uuid = sw.ls._uuid}},
                     .peer = Some{&peer@RouterPort{.router = &peer_router}}))
    {
        Some{_} = find_lrp_member_ip(peer.networks, IPv4{addr.addr}) in
        Flow(.logical_datapath = peer_router.lr._uuid,
             .stage            = router_stage(IN, ARP_RESOLVE),
             .priority         = 100,
             .__match          = "outport == ${peer.json_name} && reg0 == ${addr.addr_s}",
             .actions          = "eth.dst = ${ea_s}; next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

for (SwitchPortIPv6Address(
        .port = &SwitchPort{.lsp = lsp, .sw = &sw},
        .ea_s = ea_s,
        .addr = addr)
     if lsp.__type != "router" and lsp.__type != "virtual" and is_enabled(lsp.enabled))
{
    for (&SwitchPort(.sw = &Switch{.ls = nb.Logical_Switch{._uuid = sw.ls._uuid}},
                     .peer = Some{&peer@RouterPort{.router = &peer_router}}))
    {
        Some{_} = find_lrp_member_ip(peer.networks, IPv6{addr.addr}) in
        Flow(.logical_datapath = peer_router.lr._uuid,
             .stage            = router_stage(IN, ARP_RESOLVE),
             .priority         = 100,
             .__match          = "outport == ${peer.json_name} && xxreg0 == ${addr.addr_s}",
             .actions          = "eth.dst = ${ea_s}; next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/* True if 's' is an empty set or a set that contains just an empty string,
 * false otherwise.
 *
 * This is meant for sets of 0 or 1 elements, like the OVSDB integration
 * with DDlog uses. */
function is_empty_set_or_string(s: Option<string>): bool = {
    match (s) {
        None -> true,
        Some{""} -> true,
        _ -> false
    }
}

/* This is a virtual port. Add ARP replies for the virtual ip with
 * the mac of the present active virtual parent.
 * If the logical port doesn't have virtual parent set in
 * Port_Binding table, then add the flow to set eth.dst to
 * 00:00:00:00:00:00 and advance to next table so that ARP is
 * resolved by router pipeline using the arp{} action.
 * The MAC_Binding entry for the virtual ip might be invalid. */
Flow(.logical_datapath = peer.router.lr._uuid,
     .stage            = router_stage(IN, ARP_RESOLVE),
     .priority         = 100,
     .__match          = "outport == ${peer.json_name} && reg0 == ${ip_fmt(virtual_ip)}",
     .actions          = "eth.dst = 00:00:00:00:00:00; next;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb.Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip_s} = map_get(lsp.options, "virtual-ip"),
    Some{var virtual_parents} = map_get(lsp.options, "virtual-parents"),
    Some{var virtual_ip} = ip_parse(virtual_ip_s),
    pb in sb.Port_Binding(.logical_port = sp.lsp.name),
    is_empty_set_or_string(pb.virtual_parent) or is_none(pb.chassis),
    sp2 in &SwitchPort(.sw = sp.sw, .peer = Some{peer}),
    Some{_} = find_lrp_member_ip(peer.networks, IPv4{virtual_ip}).
Flow(.logical_datapath = peer.router.lr._uuid,
     .stage            = router_stage(IN, ARP_RESOLVE),
     .priority         = 100,
     .__match          = "outport == ${peer.json_name} && reg0 == ${ip_fmt(virtual_ip)}",
     .actions          = "eth.dst = ${address.ea_s}; next;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb.Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip_s} = map_get(lsp.options, "virtual-ip"),
    Some{var virtual_parents} = map_get(lsp.options, "virtual-parents"),
    Some{var virtual_ip} = ip_parse(virtual_ip_s),
    pb in sb.Port_Binding(.logical_port = sp.lsp.name),
    not (is_empty_set_or_string(pb.virtual_parent) or is_none(pb.chassis)),
    Some{var virtual_parent} = pb.virtual_parent,
    vp in &SwitchPort(.lsp = nb.Logical_Switch_Port{.name = virtual_parent}),
    var address = FlatMap(vp.static_addresses),
    sp2 in &SwitchPort(.sw = sp.sw, .peer = Some{peer}),
    Some{_} = find_lrp_member_ip(peer.networks, IPv4{virtual_ip}).

/* This is a logical switch port that connects to a router. */

/* The peer of this switch port is the router port for which
 * we need to add logical flows such that it can resolve
 * ARP entries for all the other router ports connected to
 * the switch in question. */
for (&SwitchPort(.lsp = lsp1,
                 .peer = Some{&peer1@RouterPort{.router = &peer_router}},
                 .sw = &sw)
     if is_enabled(lsp1.enabled))
{
    for (&SwitchPort(.lsp = lsp2, .peer = Some{&peer2},
                     .sw = &Switch{.ls = nb.Logical_Switch{._uuid = sw.ls._uuid}})
         /* Skip the router port under consideration. */
         if peer2.lrp._uuid != peer1.lrp._uuid)
    {
        if (not vec_is_empty(peer2.networks.ipv4_addrs)) {
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = router_stage(IN, ARP_RESOLVE),
                 .priority         = 100,
                 .__match          = "outport == ${peer1.json_name} && reg0 == ${format_v4_networks(peer2.networks, false)}",
                 .actions          = "eth.dst = ${peer2.networks.ea_s}; next;",
                 .external_ids     = stage_hint(lsp1._uuid))
        };

        if (not vec_is_empty(peer2.networks.ipv6_addrs)) {
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = router_stage(IN, ARP_RESOLVE),
                 .priority         = 100,
                 .__match          = "outport == ${peer1.json_name} && xxreg0 == ${format_v6_networks(peer2.networks)}",
                 .actions          = "eth.dst = ${peer2.networks.ea_s}; next;",
                 .external_ids     = stage_hint(lsp1._uuid))
        }
    }
}

for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_RESOLVE),
         .priority         = 0,
         .__match          = "ip4",
         .actions          = "get_arp(outport, reg0); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_RESOLVE),
         .priority         = 0,
         .__match          = "ip6",
         .actions          = "get_nd(outport, xxreg0); next;",
         .external_ids     = map_empty())
}

/* Local router ingress table CHK_PKT_LEN: Check packet length.
 *
 * Any IPv4 packet with outport set to the distributed gateway
 * router port, check the packet length and store the result in the
 * 'REGBIT_PKT_LARGER' register bit.
 *
 * Local router ingress table LARGER_PKTS: Handle larger packets.
 *
 * Any IPv4 packet with outport set to the distributed gateway
 * router port and the 'REGBIT_PKT_LARGER' register bit is set,
 * generate ICMPv4 packet with type 3 (Destination Unreachable) and
 * code 4 (Fragmentation needed).
 * */
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, CHK_PKT_LEN),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LARGER_PKTS),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, CHK_PKT_LEN),
     .priority         = 50,
     .__match          = "outport == ${l3dgw_port_json_name} && ip4",
     .actions          = "${rEGBIT_PKT_LARGER()} = check_pkt_larger(${gw_mtu}); "
                         "next;",
     .external_ids     = stage_hint(l3dgw_port._uuid)) :-
    r in &Router(.lr = lr),
    Some{var l3dgw_port} = r.l3dgw_port,
    var l3dgw_port_json_name = json_string_escape(l3dgw_port.name),
    r.redirect_port_name != "",
    var gw_mtu = map_get_int_def(l3dgw_port.options, "gateway_mtu", 0),
    gw_mtu > 0.
Flow(.logical_datapath = lr._uuid,
     .stage            = router_stage(IN, LARGER_PKTS),
     .priority         = 50,
     .__match          = "inport == ${rp.json_name} && outport == ${l3dgw_port_json_name} && "
                         "ip4 && ${rEGBIT_PKT_LARGER()}",
     .actions          = "icmp4_error {"
                         "${rEGBIT_EGRESS_LOOPBACK()} = 1; "
                         "eth.dst = ${rp.networks.ea_s}; "
                         "ip4.dst = ip4.src; "
                         "ip4.src = ${first_ipv4.addr_s}; "
                         "ip.ttl = 255; "
                         "icmp4.type = 3; /* Destination Unreachable. */ "
                         "icmp4.code = 4; /* Frag Needed and DF was Set. */ "
                         "icmp4.frag_mtu = ${gw_mtu - 64'd18}; "
                         "next(pipeline=ingress, table=0); "
                         "};",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    r in &Router(.lr = lr),
    Some{var l3dgw_port} = r.l3dgw_port,
    var l3dgw_port_json_name = json_string_escape(l3dgw_port.name),
    r.redirect_port_name != "",
    var gw_mtu = map_get_int_def(l3dgw_port.options, "gateway_mtu", 0),
    gw_mtu > 0,
    rp in &RouterPort(.router = r),
    rp.lrp != l3dgw_port,
    Some{var first_ipv4} = vec_nth(rp.networks.ipv4_addrs, 0).

/* Logical router ingress table GW_REDIRECT: Gateway redirect.
 *
 * For traffic with outport equal to the l3dgw_port
 * on a distributed router, this table redirects a subset
 * of the traffic to the l3redirect_port which represents
 * the central instance of the l3dgw_port.
 */
for (&Router(.lr = lr,
             .l3dgw_port = l3dgw_port,
             .redirect_port_name = redirect_port_name))
{
    /* For traffic with outport == l3dgw_port, if the
     * packet did not match any higher priority redirect
     * rule, then the traffic is redirected to the central
     * instance of the l3dgw_port. */
    Some{var gwport} = l3dgw_port in
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, GW_REDIRECT),
         .priority         = 50,
         .__match          = "outport == ${json_string_escape(gwport.name)}",
         .actions          = "outport = ${redirect_port_name}; next;",
         .external_ids     = stage_hint(gwport._uuid));

    /* Packets are allowed by default. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, GW_REDIRECT),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Local router ingress table ARP_REQUEST: ARP request.
 *
 * In the common case where the Ethernet destination has been resolved,
 * this table outputs the packet (priority 0).  Otherwise, it composes
 * and sends an ARP/IPv6 NA request (priority 100). */
Flow(.logical_datapath = router.lr._uuid,
     .stage            = router_stage(IN, ARP_REQUEST),
     .priority         = 200,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    rsr in RouterStaticRoute(.router = &router),
    var dst = FlatMap(rsr.dsts),
    IPv6{var gw_ip6} = dst.nexthop,
    var __match = "eth.dst == 00:00:00:00:00:00 && "
                  "ip6 && xxreg0 == ${dst.nexthop}",
    var sn_addr = in6_addr_solicited_node(gw_ip6),
    var eth_dst = ipv6_multicast_to_ethernet(sn_addr),
    var sn_addr_s = ipv6_string_mapped(sn_addr),
    var actions = "nd_ns { "
                  "eth.dst = ${eth_dst}; "
                  "ip6.dst = ${sn_addr_s}; "
                  "nd.target = ${dst.nexthop}; "
                  "output; "
                  "};".

for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_REQUEST),
         .priority         = 100,
         .__match          = "eth.dst == 00:00:00:00:00:00 && ip4",
         .actions          = "arp { "
                             "eth.dst = ff:ff:ff:ff:ff:ff; "
                             "arp.spa = reg1; "
                             "arp.tpa = reg0; "
                             "arp.op = 1; " /* ARP request */
                             "output; "
                             "};",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_REQUEST),
         .priority         = 100,
         .__match          = "eth.dst == 00:00:00:00:00:00 && ip6",
         .actions          = "nd_ns { "
                             "nd.target = xxreg0; "
                             "output; "
                             "};",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(IN, ARP_REQUEST),
         .priority         = 0,
         .__match          = "1",
         .actions          = "output;",
         .external_ids     = map_empty())
}


/* Logical router egress table DELIVERY: Delivery (priority 100).
 *
 * Priority 100 rules deliver packets to enabled logical ports. */
for (&RouterPort(.lrp = lrp,
                 .json_name = json_name,
                 .networks = lrp_networks,
                 .router = &Router{.lr = lr, .mcast_cfg = &mcast_cfg})
     /* Drop packets to disabled logical ports (since logical flow
      * tables are default-drop). */
     if is_enabled(lrp.enabled))
{
    /* If multicast relay is enabled then also adjust source mac for IP
     * multicast traffic.
     */
    if (mcast_cfg.relay) {
        Flow(.logical_datapath = lr._uuid,
             .stage            = router_stage(OUT, DELIVERY),
             .priority         = 110,
             .__match          = "(ip4.mcast || ip6.mcast) && "
                                 "outport == ${json_name}",
             .actions          = "eth.src = ${lrp_networks.ea_s}; output;",
             .external_ids     = stage_hint(lrp._uuid))
    };
    /* No egress packets should be processed in the context of
     * a chassisredirect port.  The chassisredirect port should
     * be replaced by the l3dgw port in the local output
     * pipeline stage before egress processing. */

    Flow(.logical_datapath = lr._uuid,
         .stage            = router_stage(OUT, DELIVERY),
         .priority         = 100,
         .__match          = "outport == ${json_name}",
         .actions          = "output;",
         .external_ids     = stage_hint(lrp._uuid))
}

/*
 * Datapath tunnel key allocation:
 *
 * Allocates a globally unique tunnel id in the range 1...2**24-1 for
 * each Logical_Switch and Logical_Router.
 */

function get_dp_tunkey(map: Map<string,string>, key: string): Option<integer> {
    match (map_get(map, key)) {
        Some{value} -> match (str_to_int(value, 10)) {
                           Some{x} -> if (x > 0 and x < (2<<24)) {
                                          Some{x}
                                      } else {
                                          None
                                      },
                           _ -> None
                       },
        _ -> None
    }
}

// Tunnel keys requested by datapaths.
relation RequestedTunKey(datapath: uuid, tunkey: integer)
RequestedTunKey(uuid, tunkey) :-
    ls in nb.Logical_Switch(._uuid = uuid),
    Some{var tunkey} = get_dp_tunkey(ls.other_config, "requested-tnl-key").
RequestedTunKey(uuid, tunkey) :-
    lr in nb.Logical_Router(._uuid = uuid),
    Some{var tunkey} = get_dp_tunkey(lr.options, "requested-tnl-key").
Warning[message] :-
    RequestedTunKey(datapath, tunkey),
    var count = Aggregate((tunkey), group_count(datapath)),
    count > 1,
    var message = "${count} logical switches or routers request "
                  "datapath tunnel key ${tunkey}".

// Assign tunnel keys:
// - First priority to requested tunnel keys.
// - Second priority to already assigned tunnel keys.
// In either case, make an arbitrary choice in case of conflicts within a
// priority level.
relation AssignedTunKey(datapath: uuid, tunkey: integer)
AssignedTunKey(datapath, tunkey) :-
    RequestedTunKey(datapath, tunkey),
    var datapath = Aggregate((tunkey), group_first(datapath)).
AssignedTunKey(datapath, tunkey) :-
    sb.Datapath_Binding(._uuid = datapath, .tunnel_key = tunkey),
    not RequestedTunKey(_, tunkey),
    not RequestedTunKey(datapath, _),
    var datapath = Aggregate((tunkey), group_first(datapath)).

// all tunnel keys already in use in the Realized table
relation AllocatedTunKeys(keys: Set<integer>)
AllocatedTunKeys(keys) :-
    AssignedTunKey(.tunkey = tunkey),
    var keys = Aggregate((), group2set(tunkey)).

// Datapath_Binding's not yet in the Realized table
relation NotYetAllocatedTunKeys(datapaths: Vec<uuid>)

NotYetAllocatedTunKeys(datapaths) :-
    OutProxy_Datapath_Binding(._uuid = datapath),
    not AssignedTunKey(datapath, _),
    var datapaths = Aggregate((), group2vec(datapath)).

// Perform the allocation
relation TunKeyAllocation(datapath: uuid, tunkey: integer)

TunKeyAllocation(datapath, tunkey) :- AssignedTunKey(datapath, tunkey).

// Case 1: AllocatedTunKeys relation is not empty (i.e., contains
// a single record that stores a set of allocated keys)
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    AllocatedTunKeys(allocated),
    var allocation = FlatMap(allocate(allocated, unallocated, 64'h1, 64'hfffffffff)),
    (var datapath, var tunkey) = allocation.

// Case 2: AllocatedTunKeys relation is empty
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    not AllocatedTunKeys(_),
    var allocation = FlatMap(allocate(set_empty():Set<bit<64>>, unallocated, 64'h1, 64'hfffffffff)),
    (var datapath, var tunkey) = allocation.

/*
 * Port id allocation:
 *
 * Port IDs in a per-datapath space in the range 1...2**15-1
 */

function get_port_tunkey(map: Map<string,string>, key: string): Option<integer> {
    match (map_get(map, key)) {
        Some{value} -> match (str_to_int(value, 10)) {
                           Some{x} -> if (x > 0 and x < (2<<15)) {
                                          Some{x}
                                      } else {
                                          None
                                      },
                           _ -> None
                       },
        _ -> None
    }
}

// Tunnel keys requested by port bindings.
relation RequestedPortTunKey(datapath: uuid, port: uuid, tunkey: integer)
RequestedPortTunKey(datapath, port, tunkey) :-
    sp in &SwitchPort(),
    var datapath = sp.sw.ls._uuid,
    var port = sp.lsp._uuid,
    Some{var tunkey} = get_port_tunkey(sp.lsp.options, "requested-tnl-key").
RequestedPortTunKey(datapath, port, tunkey) :-
    rp in &RouterPort(),
    var datapath = rp.router.lr._uuid,
    var port = rp.lrp._uuid,
    Some{var tunkey} = get_port_tunkey(rp.lrp.options, "requested-tnl-key").
Warning[message] :-
    RequestedPortTunKey(datapath, port, tunkey),
    var count = Aggregate((datapath, tunkey), group_count(port)),
    count > 1,
    var message = "${count} logical ports in the same datapath "
                  "request port tunnel key ${tunkey}".

// Assign tunnel keys:
// - First priority to requested tunnel keys.
// - Second priority to already assigned tunnel keys.
// In either case, make an arbitrary choice in case of conflicts within a
// priority level.
relation AssignedPortTunKey(datapath: uuid, port: uuid, tunkey: integer)
AssignedPortTunKey(datapath, port, tunkey) :-
    RequestedPortTunKey(datapath, port, tunkey),
    var port = Aggregate((datapath, tunkey), group_first(port)).
AssignedPortTunKey(datapath, port, tunkey) :-
    sb.Port_Binding(._uuid = port_uuid,
                    .datapath = datapath,
                    .tunnel_key = tunkey),
    not RequestedPortTunKey(datapath, _, tunkey),
    not RequestedPortTunKey(datapath, port_uuid, _),
    var port = Aggregate((datapath, tunkey), group_first(port_uuid)).

// all tunnel keys already in use in the Realized table
relation AllocatedPortTunKeys(datapath: uuid, keys: Set<integer>)

AllocatedPortTunKeys(datapath, keys) :-
    AssignedPortTunKey(datapath, port, tunkey),
    var keys = Aggregate((datapath), group2set(tunkey)).

// Port_Binding's not yet in the Realized table
relation NotYetAllocatedPortTunKeys(datapath: uuid, all_logical_ids: Vec<uuid>)

NotYetAllocatedPortTunKeys(datapath, all_names) :-
    OutProxy_Port_Binding(._uuid = port_uuid, .datapath = datapath),
    not AssignedPortTunKey(datapath, port_uuid, _),
    var all_names = Aggregate((datapath), group2vec(port_uuid)).

// Perform the allocation.
relation PortTunKeyAllocation(port: uuid, tunkey: integer)

// Transfer existing allocations from the realized table.
PortTunKeyAllocation(port, tunkey) :- AssignedPortTunKey(_, port, tunkey).

// Case 1: AllocatedPortTunKeys(datapath) is not empty (i.e., contains
// a single record that stores a set of allocated keys).
PortTunKeyAllocation(port, tunkey) :-
    AllocatedPortTunKeys(datapath, allocated),
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    var allocation = FlatMap(allocate(allocated, unallocated, 64'h1, 64'hffff)),
    (var port, var tunkey) = allocation.

// Case 2: PortAllocatedTunKeys(datapath) relation is empty
PortTunKeyAllocation(port, tunkey) :-
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    not AllocatedPortTunKeys(datapath, _),
    var allocation = FlatMap(allocate(set_empty(): Set<bit<64>>, unallocated, 64'h1, 64'hffff)),
    (var port, var tunkey) = allocation.

/*
 * Multicast group tunnel_key allocation:
 *
 * Tunnel-keys in a per-datapath space in the range 32770...65535
 */

// All tunnel keys already in use in the Realized table.
relation AllocatedMulticastGroupTunKeys(datapath_uuid: uuid, keys: Set<integer>)

AllocatedMulticastGroupTunKeys(datapath_uuid, keys) :-
    sb.Multicast_Group(.datapath = datapath_uuid, .tunnel_key = tunkey),
    //sb.UUIDMap_Datapath_Binding(datapath, Left{datapath_uuid}),
    var keys = Aggregate((datapath_uuid), group2set(tunkey)).

// Multicast_Group's not yet in the Realized table.
relation NotYetAllocatedMulticastGroupTunKeys(datapath_uuid: uuid,
                                              all_logical_ids: Vec<string>)

NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, all_names) :-
    OutProxy_Multicast_Group(.name = name, .datapath = datapath_uuid),
    not sb.Multicast_Group(.name = name, .datapath = datapath_uuid),
    var all_names = Aggregate((datapath_uuid), group2vec(name)).

// Perform the allocation
relation MulticastGroupTunKeyAllocation(datapath_uuid: uuid, group: string, tunkey: integer)

// transfer existing allocations from the realized table
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    //sb.UUIDMap_Datapath_Binding(_, datapath_uuid),
    sb.Multicast_Group(.name = group,
                       .datapath = datapath_uuid,
                       .tunnel_key = tunkey).

// Case 1: AllocatedMulticastGroupTunKeys(datapath) is not empty (i.e.,
// contains a single record that stores a set of allocated keys)
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    AllocatedMulticastGroupTunKeys(datapath_uuid, allocated),
    NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, unallocated),
    (_, var min_key) = mC_IP_MCAST_MIN(),
    (_, var max_key) = mC_IP_MCAST_MAX(),
    var allocation = FlatMap(allocate(allocated, unallocated,
                                      min_key, max_key)),
    (var group, var tunkey) = allocation.

// Case 2: AllocatedMulticastGroupTunKeys(datapath) relation is empty
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, unallocated),
    not AllocatedMulticastGroupTunKeys(datapath_uuid, _),
    (_, var min_key) = mC_IP_MCAST_MIN(),
    (_, var max_key) = mC_IP_MCAST_MAX(),
    var allocation = FlatMap(allocate(set_empty(): Set<bit<64>>, unallocated,
                                      min_key, max_key)),
    (var group, var tunkey) = allocation.

/*
 * Queue ID allocation
 *
 * Queue IDs on a chassis, for routers that have QoS enabled, in a per-chassis
 * space in the range 1...0xf000.  It looks to me like there'd only be a small
 * number of these per chassis, and probably a small number overall, in case it
 * matters.
 *
 * Queue ID may also need to be deallocated if port loses QoS attributes
 *
 * This logic applies mainly to sb.Port_Binding records bound to a chassis
 * (i.e. with the chassis column nonempty) but "localnet" ports can also
 * have a queue ID.  For those we use the port's own UUID as the chassis UUID.
 */

function port_has_qos_params(opts: Map<string, string>): bool = {
    map_contains_key(opts, "qos_max_rate") or
    map_contains_key(opts, "qos_burst")
}


// ports in Out_Port_Binding that require queue ID on chassis
relation PortRequiresQID(port: uuid, chassis: uuid)

PortRequiresQID(pb._uuid, chassis) :-
    pb in OutProxy_Port_Binding(),
    pb.__type != "localnet",
    port_has_qos_params(pb.options),
    sb.Port_Binding(._uuid = pb._uuid, .chassis = chassis_set),
    Some{var chassis} = chassis_set.
PortRequiresQID(pb._uuid, pb._uuid) :-
    pb in OutProxy_Port_Binding(),
    pb.__type == "localnet",
    port_has_qos_params(pb.options),
    sb.Port_Binding(._uuid = pb._uuid).

relation AggPortRequiresQID(chassis: uuid, ports: Vec<uuid>)

AggPortRequiresQID(chassis, ports) :-
    PortRequiresQID(port, chassis),
    var ports = Aggregate((chassis), group2vec(port)).

relation AllocatedQIDs(chassis: uuid, allocated_ids: Map<uuid, integer>)

AllocatedQIDs(chassis, allocated_ids) :-
    pb in sb.Port_Binding(),
    pb.__type != "localnet",
    Some{var chassis} = pb.chassis,
    Some{var qid_str} = map_get(pb.options, "qdisc_queue_id"),
    Some{var qid: bit<64>} = parse_dec_u64(qid_str),
    var allocated_ids = Aggregate((chassis), group2map((pb._uuid, qid))).
AllocatedQIDs(chassis, allocated_ids) :-
    pb in sb.Port_Binding(),
    pb.__type == "localnet",
    var chassis = pb._uuid,
    Some{var qid_str} = map_get(pb.options, "qdisc_queue_id"),
    Some{var qid: bit<64>} = parse_dec_u64(qid_str),
    var allocated_ids = Aggregate((chassis), group2map((pb._uuid, qid))).

// allocate queue IDs to ports
relation QueueIDAllocation(port: uuid, qids: Option<integer>)

// None for ports that do not require a queue
QueueIDAllocation(port, None) :-
    OutProxy_Port_Binding(._uuid = port),
    not PortRequiresQID(port, _).

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    AllocatedQIDs(chassis, allocated_ids),
    var allocations = FlatMap(adjust_allocation(allocated_ids, ports, 64'h1, 64'hf000)),
    (var port, var qid) = allocations.

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    not AllocatedQIDs(chassis, _),
    var allocations = FlatMap(adjust_allocation(map_empty(): Map<uuid, integer>, ports, 64'h1, 64'hf000)),
    (var port, var qid) = allocations.

/*
 * This allows ovn-northd to preserve options:ipv6_ra_pd_list, which is set by
 * ovn-controller.
 */
relation PreserveIPv6RAPDList(lrp_uuid: uuid, ipv6_ra_pd_list: Option<string>)
PreserveIPv6RAPDList(lrp_uuid, ipv6_ra_pd_list) :-
    sb.Port_Binding(._uuid = lrp_uuid, .options = options),
    var ipv6_ra_pd_list = map_get(options, "ipv6_ra_pd_list").
PreserveIPv6RAPDList(lrp_uuid, None) :-
    nb.Logical_Router_Port(._uuid = lrp_uuid),
    not sb.Port_Binding(._uuid = lrp_uuid).

/*
 * Tag allocation for nested containers.
 */

/* Reserved tags for each parent port, including:
 * 1. For ports that need a dynamically allocated tag, existing tag, if any,
 * 2. For ports that have a statically assigned tag (via `tag_request`), the
 *    `tag_request` value.
 * 3. For ports that do not have a tag_request, but have a tag statically assigned
 *    by directly setting the `tag` field, use this value.
 */
relation SwitchPortReservedTag(parent_name: string, tags: integer)

SwitchPortReservedTag(parent_name, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = needs_dynamic_tag, .parent_name = Some{parent_name}),
    Some{var tag} = if (needs_dynamic_tag) {
        lsp.tag
    } else {
        match (lsp.tag_request) {
            Some{req} -> Some{req},
            None      -> lsp.tag
        }
    }.

relation SwitchPortReservedTags(parent_name: string, tags: Set<integer>)

SwitchPortReservedTags(parent_name, tags) :-
    SwitchPortReservedTag(parent_name, tag),
    var tags = Aggregate((parent_name), group2set(tag)).

SwitchPortReservedTags(parent_name, set_empty()) :-
    nb.Logical_Switch_Port(.name = parent_name),
    not SwitchPortReservedTag(.parent_name = parent_name).

/* Allocate tags for ports that require dynamically allocated tags and do not
 * have any yet.
 */
relation SwitchPortAllocatedTags(lsp_uuid: uuid, tag: Option<integer>)

SwitchPortAllocatedTags(lsp_uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true, .parent_name = Some{parent_name}),
    is_none(lsp.tag),
    var lsps_need_tag = Aggregate((parent_name), group2vec(lsp._uuid)),
    SwitchPortReservedTags(parent_name, reserved),
    var dyn_tags = allocate_opt(reserved,
                                lsps_need_tag,
                                1: integer, /* Tag 0 is invalid for nested containers. */
                                4095: integer),
    var lsp_tag = FlatMap(dyn_tags),
    (var lsp_uuid, var tag) = lsp_tag.

/* New tag-to-port assignment:
 * Case 1. Statically reserved tag (via `tag_request`), if any.
 * Case 2. Existing tag for ports that require a dynamically allocated tag and already have one.
 * Case 3. Use newly allocated tags (from `SwitchPortAllocatedTags`) for all other ports.
 */
relation SwitchPortNewDynamicTag(port: uuid, tag: Option<integer>)

/* Case 1 */
SwitchPortNewDynamicTag(lsp._uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = false),
    var tag: Option<integer> = match (lsp.tag_request) {
        Some{0} -> None,
        treq    -> treq
    }.

/* Case 2 */
SwitchPortNewDynamicTag(lsp._uuid, Some{tag}) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true),
    Some{var tag} = lsp.tag.

/* Case 3 */
SwitchPortNewDynamicTag(lsp._uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true),
    is_none(lsp.tag),
    SwitchPortAllocatedTags(lsp._uuid, tag).

/* IP_Multicast table (only applicable for Switches). */
sb.Out_IP_Multicast(._uuid = cfg.datapath,
                    .datapath = cfg.datapath,
                    .enabled = Some{cfg.enabled},
                    .querier = Some{cfg.querier},
                    .eth_src = cfg.eth_src,
                    .ip4_src = cfg.ip4_src,
                    .ip6_src = cfg.ip6_src,
                    .table_size = Some{cfg.table_size},
                    .idle_timeout = Some{cfg.idle_timeout},
                    .query_interval = Some{cfg.query_interval},
                    .query_max_resp = Some{cfg.query_max_resp}) :-
    &McastSwitchCfg[cfg].


relation PortExists(name: string)
PortExists(name) :- nb.Logical_Switch_Port(.name = name).
PortExists(name) :- nb.Logical_Router_Port(.name = name).

sb.Out_Service_Monitor(._uuid = hash128((svc_monitor.port_name, lbvipbackend.ip, lbvipbackend.port, protocol)),
                       .ip = lbvipbackend.ip,
                       .protocol = Some{protocol},
                       .port = lbvipbackend.port as integer,
                       .logical_port = svc_monitor.port_name,
                       .src_mac = eth_addr2string(svc_monitor_mac),
                       .src_ip = svc_monitor.src_ip,
                       .options = lbhc.options,
                       .external_ids = map_empty()) :-
    SvcMonitorMac(svc_monitor_mac),
    LBVIPBackend[lbvipbackend],
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    LoadBalancerHealthCheckRef[lbhc],
    PortExists(svc_monitor.port_name),
    set_contains(lbvipbackend.lbvip.lb.health_check, lbhc._uuid),
    lbhc.vip == lbvipbackend.lbvip.vip_key,
    var protocol = default_protocol(lbvipbackend.lbvip.lb.protocol),
    protocol != "sctp".

Warning["SCTP load balancers do not currently support "
        "health checks. Not creating health checks for "
        "load balancer ${uuid2str(lbvipbackend.lbvip.lb._uuid)}"] :-
    LBVIPBackend[lbvipbackend],
    default_protocol(lbvipbackend.lbvip.lb.protocol) == "sctp",
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    LoadBalancerHealthCheckRef[lbhc],
    set_contains(lbvipbackend.lbvip.lb.health_check, lbhc._uuid),
    lbhc.vip == lbvipbackend.lbvip.vip_key.
